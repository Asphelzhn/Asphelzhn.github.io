<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Deep learning,科研 - 学习," />










<meta name="description" content="一.TF serving实现 TF serving托管模型流程包括4个步骤：训练模型，导出模型，发布模型，更新线上模型服务。 TF serving官方文档 1.ServablesServables 是 TensorFlow Serving 中最核心的抽象，是服务器端提供计算和查询服务的的实例对象。Servables 的大小和力度是灵活的，单个 Servable 可能包含从一个查找表的单个分片，到一">
<meta name="keywords" content="Deep learning,科研 - 学习">
<meta property="og:type" content="article">
<meta property="og:title" content="Tensorflow内核学习">
<meta property="og:url" content="http://yoursite.com/2019/01/16/tensor_02_serving/index.html">
<meta property="og:site_name" content="Edward">
<meta property="og:description" content="一.TF serving实现 TF serving托管模型流程包括4个步骤：训练模型，导出模型，发布模型，更新线上模型服务。 TF serving官方文档 1.ServablesServables 是 TensorFlow Serving 中最核心的抽象，是服务器端提供计算和查询服务的的实例对象。Servables 的大小和力度是灵活的，单个 Servable 可能包含从一个查找表的单个分片，到一">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://yoursite.com/images/tensor_02/1.png">
<meta property="og:image" content="http://yoursite.com/images/tensor_02/2.png">
<meta property="og:image" content="http://yoursite.com/images/tensor_02/3.png">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-81063f1d5864c79bd422b7a42199a079_hd.jpg">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=W_%7Bt%2B1%7D+%3D+W_%7Bt%7D+-+%5Calpha+%5Cnabla+F%28W_t%29">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Cnabla+F%28W%29">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=v_%7Bt%2B1%7D+%3D+%5Crho+v_t+%2B+%5Cnabla+F%28W_t%29%5C%5C+W_%7Bt%2B1%7D+%3D+W_%7Bt%7D+-+%5Calpha+v_%7Bt%2B1%7D">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-f4d6bb11679be2251e12dad4f2cc56f9_hd.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-f05c13bb2fd8eecc0bd7b6e4d3d3148d_hd.jpg">
<meta property="og:image" content="https://img-blog.csdn.net/20171126122158007?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemp1Y29y/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center">
<meta property="og:image" content="https://img-blog.csdn.net/20170405213708608?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvU2V2ZW5feWVhcl9Qcm9taXNl/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center">
<meta property="og:image" content="https://img-blog.csdn.net/20170405213726978?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvU2V2ZW5feWVhcl9Qcm9taXNl/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center">
<meta property="og:image" content="https://img-blog.csdn.net/20170405213826979?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvU2V2ZW5feWVhcl9Qcm9taXNl/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center">
<meta property="og:image" content="https://img-blog.csdn.net/20170405213946417?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvU2V2ZW5feWVhcl9Qcm9taXNl/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center">
<meta property="og:updated_time" content="2019-01-16T15:23:53.061Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Tensorflow内核学习">
<meta name="twitter:description" content="一.TF serving实现 TF serving托管模型流程包括4个步骤：训练模型，导出模型，发布模型，更新线上模型服务。 TF serving官方文档 1.ServablesServables 是 TensorFlow Serving 中最核心的抽象，是服务器端提供计算和查询服务的的实例对象。Servables 的大小和力度是灵活的，单个 Servable 可能包含从一个查找表的单个分片，到一">
<meta name="twitter:image" content="http://yoursite.com/images/tensor_02/1.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/01/16/tensor_02_serving/"/>





  <title>Tensorflow内核学习 | Edward</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Edward</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Edward's Blog</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/01/16/tensor_02_serving/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1545151264345&di=3142133106fdfdce70d9b3866056d52c&imgtype=0&src=http%3A%2F%2Fimg4q.duitang.com%2Fuploads%2Fitem%2F201209%2F10%2F20120910083757_PdTei.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Edward">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Tensorflow内核学习</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-16T22:30:00+08:00">
                2019-01-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Tensorflow/" itemprop="url" rel="index">
                    <span itemprop="name">Tensorflow</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/01/16/tensor_02_serving/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/01/16/tensor_02_serving/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="一-TF-serving实现"><a href="#一-TF-serving实现" class="headerlink" title="一.TF serving实现"></a>一.TF serving实现</h1><p><img src="/images/tensor_02/1.png" alt=""></p>
<p>TF serving托管模型流程包括4个步骤：训练模型，导出模型，发布模型，更新线上模型服务。</p>
<p><a href="https://tensorflow.google.cn/serving/" target="_blank" rel="noopener">TF serving官方文档</a></p>
<h2 id="1-Servables"><a href="#1-Servables" class="headerlink" title="1.Servables"></a>1.Servables</h2><p><strong>Servables</strong> 是 TensorFlow Serving 中最核心的抽象，是服务器端提供计算和查询服务的的实例对象。Servables 的大小和力度是灵活的，单个 Servable 可能包含从一个查找表的单个分片，到一个单独的模型，或是推理模型的元组。一套TF serving支持同时运行多个服务。</p>
<p>Servables 并不管理自身的生命周期。</p>
<p>典型的 Servables 包括：</p>
<ul>
<li>一个 TensorFlow 的 SavedModelBundle (<code>tensorflow::Session</code>)</li>
<li>一个用于 Embedding 的查找表或词汇表</li>
</ul>
<p><strong>Servables Streams</strong></p>
<p>一个 <strong>Servables Stream</strong> 是多个版本的 Servable 的序列，其按照版本号的递增排序。</p>
<h2 id="2-Models"><a href="#2-Models" class="headerlink" title="2.Models"></a>2.Models</h2><p>TensorFlow Serving 将一个 <strong>模型 (model)</strong> 表示为一个或多个 Servables。一个机器学习模型可能包括一个或多个算法 (包括学习到的权重) 和查找表。</p>
<p>可以将一个 <strong>复合模型 (composite model)</strong> 表示成如下形式：</p>
<ul>
<li>多个独立的 Servables</li>
<li>一个组合的 Servables</li>
</ul>
<p>一个 Servable 也可能是一个模型的一部分，例如，一个大的查找表可能被分割到多个不同的 TensorFlow Serving 实例中。</p>
<h2 id="3-Loaders"><a href="#3-Loaders" class="headerlink" title="3.Loaders"></a>3.Loaders</h2><p><strong>Loaders</strong> 管理一个 Servable 的生命周期。Loaders 将一个 Servable 的加载和卸载的 API 进行了标准化，并且提供评估系统资源是否足够加载Servable的接口。</p>
<h2 id="4-Sources"><a href="#4-Sources" class="headerlink" title="4.Sources"></a>4.Sources</h2><p>Sources 是数据处理器抽象，负责监控和处理Servable加载的数据，比如文件系统指定路径下的查找表文件或模型文件。TensorFlow Serving 中 Sources 的接口可以从任意的存储系统中发现 Servables，TesorFlow Serving 包含了 Source 实现的通用引用。例如：Sources 可以利用 RPC 等机制，并可以轮训文件系统。Sources 可以维护多个 Servables 或 不同版本分片中的状态，这将有助于 Servables 在不同版本之间进行 Delta (diff) 更新。</p>
<h2 id="5-Managers"><a href="#5-Managers" class="headerlink" title="5.Managers"></a>5.Managers</h2><p><strong>Managers</strong> 维护 Servables 的整个生命周期，包括：</p>
<ul>
<li>加载 Servables</li>
<li>为 Servables 提供服务</li>
<li>卸载 Servables</li>
</ul>
<p>Managers 从 Sources 获取信息并跟踪所有的 Versions。Manager 尽可能的满足 Sources 的请求，但当所需的资源不存在时，会拒绝载入一个 Aspired Versions。Manager 也可能延迟触发一个卸载 (unload)，例如：基于要确保任意时点都要至少有一个 Version 被加载的策略，Manager 需要等待一个新的 Version 完成加载后再卸载之前的 Version。</p>
<h2 id="6-SavedModel"><a href="#6-SavedModel" class="headerlink" title="6.SavedModel"></a>6.SavedModel</h2><p>是TF模型持久化存储的通用序列化格式，是打通从模型训练到服务发布流程的关键。在训练阶段，我们可能使用输入流水线和超参数优化操作。当模型发布为服务时，需要删除或替换这些操作，否则会出现推理准确率低，输入队列阻塞的情况。</p>
<p>为了提升服务发布后的准确率或其他评价指标，我们需要保存多分不同的数据流图进行测试。<strong>SavedModel支持用一份saved_model.pb文件来保存多幅不同的数据流图，这些数据流图可以共享模型参数和资源。</strong></p>
<h2 id="7-ServableHandle"><a href="#7-ServableHandle" class="headerlink" title="7.ServableHandle"></a>7.ServableHandle</h2><p>是响应gPRC客户端访问请求的服务句柄，ServableHandle与已加载的Servable一一对应。客户端请求TF serving服务时，服务端ServableHandle会调用相应的Servable服务接口，并将相应返回给客户端。如果服务尚未加载，则向客户端返回错误信息。</p>
<h2 id="8-Batch"><a href="#8-Batch" class="headerlink" title="8.Batch"></a>8.Batch</h2><p><a href="https://github.com/tensorflow/serving/blob/master/tensorflow_serving/batching/README.md" target="_blank" rel="noopener">batch文档</a></p>
<p>将多个请求批处理为单个请求可以显著降低推理的成本，特别是在有 GPU 等加速器的情况下。TensorFlow Serving 包含了一个用于批处理请求的小工具，它允许客户端可以轻松的将请求中特定类型的推断合成一个批处理请求，以便系统能够更有效的处理。</p>
<p>在提供TensorFlow模型时，将单个模型推理请求一起批处理对于性能非常重要。特别是，批处理对于解锁GPU等硬件加速器所承诺的高吞吐量是必要的。这是一个用于批处理请求和调度批处理的库。该库本身并不依赖于GPU，并且可以用于串联处理小任务组的任何情况。 它提供了特定的TensorFlow会话API，以及可用于在其他粒度批处理的低级API。</p>
<p>该库目前分为:（1）core / kernels / batching_util（核心API和实现）（2）tensorflow_serving / batching（更高级别和实验代码）。</p>
<h3 id="BatchingSession"><a href="#BatchingSession" class="headerlink" title="BatchingSession"></a>BatchingSession</h3><p>BatchingSession将批处理添加到标准tensorflow :: Session，并允许您使用单个（非批处理）张量调用Session :: Run（），同时获得批量处理“隐藏”的好处。请求线程使得在等待其他组调用阻塞的Session :: Run（），调用进入同一个批处理。要使用此同步API实现良好的吞吐量，建议将客户端线程数设置为最大批量大小的两倍。</p>
<p>使用BatchingSession的最简单方法是通过CreateRetryingBasicBatchingSession（），它使用下面的BasicBatchSchedule提供了一个tensorflow :: Session对象，并且还处理溢出调度程序队列的重试请求。</p>
<p>Batch大小可以设置为1-1024。</p>
<h3 id="BasicBatchScheduler"><a href="#BasicBatchScheduler" class="headerlink" title="BasicBatchScheduler"></a>BasicBatchScheduler</h3><p>BasicBatchScheduler是一个比BatchingSession更低级的抽象，它与张量/ TensorFlow本身无关。它适用于处理同类请求的服务器。BasicBatchScheduler提供了一个异步API，称为BatchScheduler，该API由BatchTask类进行模板化，该类封装了要批处理的工作单元。 非阻塞Schedule（）方法用于将任务排入队列以进行处理。 准备好处理一批任务后，将在单独的线程上调用回调来处理批处理</p>
<h3 id="Mixed-CPU-GPU-IO-Workloads"><a href="#Mixed-CPU-GPU-IO-Workloads" class="headerlink" title="Mixed CPU/GPU/IO Workloads"></a>Mixed CPU/GPU/IO Workloads</h3><p>除了主要的GPU工作之外，一些模型还执行非常重要的CPU工作。虽然核心矩阵操作可以在GPU上良好运行，但是外围操作可以在CPU上进行，例如，嵌入查找，词汇查找，量化/反量化。根据GPU的管理方式，将整个CPU和GPU步骤序列作为一个单元进行批处理可能无法充分利用GPU。</p>
<p>可以在请求线程中执行非GPU预处理和后处理，批处理调度程序仅用于工作的GPU部分。</p>
<p>或者，非GPU工作可以在批处理线程中完成，在批处理调度程序调用的回调中。要允许回调在完全形成批处理之前对任务执行非批处理工作，可以使用StreamingBatchScheduler。它专为非常精确控制延迟的服务器而设计，需要对流水线的每个阶段进行精细控制。</p>
<p>如果调度程序当前没有处理能力，StreamingBatchScheduler将拒绝任务。如果要自动重试因此原因而被拒绝的任务，可以在批处理调度程序之上对BatchSchedulerRetrier进行分层。有一个便利功能，用于创建与调度程序相结合的流调度程序：<code>CreateRetryingStreamingBatchScheduler（）</code>。</p>
<p>将模型推理逻辑拆分为多个不同阶段以优化延迟或利用率时，请记住，对于给定请求，每个阶段都应使用相同版本的模型。确保此属性的一个好方法是协调跨线程在每个阶段使用哪个ServableHandle对象。</p>
<p>最后，I / O密集的推理阶段，例如查找磁盘或远程服务器可能会受益于批处理以隐藏其延迟。您可以使用两个批处理调度程序实例：一个用于批处理这些查找，另一个用于批处理GPU工作。</p>
<h1 id="二-TF-serving流程"><a href="#二-TF-serving流程" class="headerlink" title="二. TF serving流程"></a>二. TF serving流程</h1><h2 id="1-训练和导出模型"><a href="#1-训练和导出模型" class="headerlink" title="1.训练和导出模型"></a>1.训练和导出模型</h2><p>TF服务器端组件只负责模型服务的发布和更新，模型导出由TF原生的tensorflow.saved_model.builder.SavedModelBuilder模块实现。SavedModelBuilder定期向文件系统中的目标路径导出模型快照，模型快照的格式为SavedModel序列化格式。对于 SavedModel 格式的详细信息，参见 SavedModel <a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/README.md" target="_blank" rel="noopener">REAMDE.md</a> 文档，如下代码片段说明了将模型保存至硬盘的一般流程。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">export_path_base = sys.argv[-1]</span><br><span class="line">export_path = os.path.join(</span><br><span class="line">      compat.as_bytes(export_path_base),</span><br><span class="line">      compat.as_bytes(str(FLAGS.model_version)))</span><br><span class="line">print &apos;Exporting trained model to&apos;, export_path</span><br><span class="line">builder = tf.saved_model.builder.SavedModelBuilder(export_path)</span><br><span class="line">builder.add_meta_graph_and_variables(</span><br><span class="line">      sess, [tag_constants.SERVING],</span><br><span class="line">      signature_def_map=&#123;</span><br><span class="line">           &apos;predict_images&apos;:</span><br><span class="line">               prediction_signature,</span><br><span class="line">           signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:</span><br><span class="line">               classification_signature,</span><br><span class="line">      &#125;,</span><br><span class="line">      main_op=main_op)</span><br><span class="line">builder.save()</span><br></pre></td></tr></table></figure>
<p>每个版本子目录中包含如下文件：</p>
<ul>
<li><code>saved_model.pb</code> 是序列化的 <code>tensorflow::SavedModel</code> 文件。其包含一个或多个计算图的定义，同时也包含模型的一些元信息，例如 Signatures。</li>
<li><code>variables</code> 为一系列包含了计算图中的变量的序列化文件。</li>
</ul>
<p>谷歌推荐的保存模型的方式是保存模型为 PB 文件，它具有语言独立性，可独立运行，封闭的序列化格式，任何语言都可以解析它，它允许其他语言和深度学习框架读取、继续训练和迁移 TensorFlow 的模型。它的主要使用场景是实现<strong>创建模型与使用模型的解耦</strong>， 使得前向推导 inference的代码统一。另外的好处是保存为 PB 文件时候，模型的变量都会变成固定的，导致模型的大小会大大减小，适合在手机端运行。</p>
<h2 id="2-定义模型服务的参数和配置"><a href="#2-定义模型服务的参数和配置" class="headerlink" title="2.定义模型服务的参数和配置"></a>2.定义模型服务的参数和配置</h2><p>使用SavedModelBuilder导出模型分为以下3步：</p>
<ol>
<li>构造SavedModelBuilder实例，并设置模型的导出路径</li>
<li>定义模型服务的SignatureDef</li>
<li>使用SavedModelBuilder实例导出模型</li>
</ol>
<p>创建SavedModelBuilder实例后，调用它的add_meta_graph_and_variables成员方法，添加期望导出的数据流图和模型参数。add_meta_graph_and_variables发放的主要输入参数包括：</p>
<ul>
<li><code>sess</code> 为包含需要导出的训练好的模型的 TensorFlow 会话。</li>
<li><code>tags</code> 数据流图的类型标签，可以选的取值包括SERVING，TRAINING和GPU。分别表示该数据流图用于提供服务，训练模型，以及使用GPU设备。</li>
<li><code>signature_def_map</code> 指定了用于添加到 Meta Graph 中的从用户提供的键到 <code>tensorflow::SignatureDef</code> 之间的映射。Signature 指定了导出模型的类型，以及在进行推理阶段所绑定的输入和输出张量。</li>
</ul>
<h3 id="predict-signature签名配置（包括回归，分类，推理）"><a href="#predict-signature签名配置（包括回归，分类，推理）" class="headerlink" title="predict_signature签名配置（包括回归，分类，推理）"></a>predict_signature签名配置（包括回归，分类，推理）</h3><p>作为一个 <code>predict_signature</code> 定义的示例，工具函数接受如下参数：</p>
<ul>
<li><code>inputs={&#39;images&#39;: tensor_info_x}</code> 指定输入张量的信息。</li>
<li><code>outputs={&#39;scores&#39;: tensor_info_y}</code> 指定输出评分张量的信息。</li>
<li><code>method_name</code> 表示用于推理的方法。对于预测请求，其应被设置为 <code>tensorflow/serving/predict</code>，对于其他方法名称，参见 <a href="https://www.tensorflow.org/api_docs/python/tf/saved_model/signature_constants" target="_blank" rel="noopener">TensorFlow API 文档</a>。</li>
</ul>
<h2 id="3-Serving-with-Docker-using-GPU"><a href="#3-Serving-with-Docker-using-GPU" class="headerlink" title="3.Serving with Docker using GPU"></a>3.Serving with Docker using GPU</h2><h3 id="（1）Install-nvidia-docker-下载"><a href="#（1）Install-nvidia-docker-下载" class="headerlink" title="（1）Install nvidia-docker (下载)"></a>（1）Install nvidia-docker <a href="https://tensorflow.google.cn/serving/docker?hl=zh-CN#install_nvidia_docker" target="_blank" rel="noopener">(下载)</a></h3><p>Before serving with a GPU, in addition to <a href="https://tensorflow.google.cn/serving/docker?hl=zh-CN#installing_docker" target="_blank" rel="noopener">installing Docker</a>, you will need:</p>
<ul>
<li>Up-to-date <a href="http://www.nvidia.com/drivers" target="_blank" rel="noopener">NVIDIA drivers</a> for your system</li>
<li><code>nvidia-docker</code>: You can follow the <a href="https://github.com/NVIDIA/nvidia-docker#quick-start" target="_blank" rel="noopener">installation instructions here</a></li>
</ul>
<h3 id="（2）Running-a-GPU-serving-image"><a href="#（2）Running-a-GPU-serving-image" class="headerlink" title="（2）Running a GPU serving image"></a>（2）Running a GPU serving image</h3><p>Running a GPU serving image is identical to running a CPU image. For more details, see <a href="https://tensorflow.google.cn/serving/docker?hl=zh-CN#running_a_serving_image" target="_blank" rel="noopener">running a serving image</a>.</p>
<h3 id="（3）Serving-GPU-docker-image"><a href="#（3）Serving-GPU-docker-image" class="headerlink" title="（3）Serving GPU docker image"></a>（3）Serving GPU docker image</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull tensorflow/serving:latest-gpu</span><br></pre></td></tr></table></figure>
<h3 id="（4）指定GPU-Docker加载模型"><a href="#（4）指定GPU-Docker加载模型" class="headerlink" title="（4）指定GPU Docker加载模型"></a>（4）指定GPU Docker加载模型</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker run --runtime=nvidia -p 8501:8501 \</span><br><span class="line">  --mount type=bind,\</span><br><span class="line">  source=/home/asphel/Desktop/models/official/resnet/savedmodel,\</span><br><span class="line">  target=/models/resnet \</span><br><span class="line">  -e MODEL_NAME=resnet -t tensorflow/serving:latest-gpu &amp;</span><br></pre></td></tr></table></figure>
<h3 id="（5）服务运行在指定端口，通过网络请求调用服务"><a href="#（5）服务运行在指定端口，通过网络请求调用服务" class="headerlink" title="（5）服务运行在指定端口，通过网络请求调用服务"></a>（5）服务运行在指定端口，通过网络请求调用服务</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2019-01-11 00:07:20.773693: I tensorflow_serving/model_servers/main.cc:333]</span><br><span class="line">Exporting HTTP/REST API at:localhost:8501 ...</span><br></pre></td></tr></table></figure>
<p>发送请求，调用服务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> curl -d <span class="string">'&#123;"instances": [1.0, 2.0, 5.0]&#125;'</span> \</span></span><br><span class="line">  -X POST http://localhost:8501/v1/models/resnet</span><br></pre></td></tr></table></figure>
<h1 id="三-实验"><a href="#三-实验" class="headerlink" title="三.实验"></a>三.实验</h1><h3 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a>实验环境</h3><p>core i3 4核心 3.1GHZ</p>
<p>GTX 1050 4G显存</p>
<p>内存 4GB</p>
<h3 id="测量参数"><a href="#测量参数" class="headerlink" title="测量参数"></a>测量参数</h3><p>1.CPU利用率，CPU负载</p>
<p>2.内存占用</p>
<p>3.GPU显存占用，GPU利用率</p>
<h2 id="1-多用户依次请求"><a href="#1-多用户依次请求" class="headerlink" title="1. 多用户依次请求"></a>1. 多用户依次请求</h2><p>10000个用户请求陆续到达，服务器依次响应每个用户请求。</p>
<h3 id="用户请求相同"><a href="#用户请求相同" class="headerlink" title="用户请求相同"></a>用户请求相同</h3><p>每次用户请求的模型和输入数据都相同</p>
<h3 id="用户请求不同"><a href="#用户请求不同" class="headerlink" title="用户请求不同"></a>用户请求不同</h3><p>每次用户请求的模型和输入数据都相同</p>
<h2 id="2-多用户按批次请求"><a href="#2-多用户按批次请求" class="headerlink" title="2. 多用户按批次请求"></a>2. 多用户按批次请求</h2><p>10000个用户请求按批次加载到服务器，服务器按批次执行用户请求。</p>
<p>Batching can be turned on by providing proper <code>SessionBundleConfig</code> when creating the <code>SavedModelBundleSourceAdapter</code>. In this case we set the <code>BatchingParameters</code> with pretty much default values. Batching can be fine-tuned by setting custom timeout, batch_size, etc. values. For details, please refer to <code>BatchingParameters</code>.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">SessionBundleConfig session_bundle_config;</span><br><span class="line">// Batching config</span><br><span class="line">if (enable_batching) &#123;</span><br><span class="line">  BatchingParameters* batching_parameters =</span><br><span class="line">      session_bundle_config.mutable_batching_parameters();</span><br><span class="line">  batching_parameters-&gt;mutable_thread_pool_name()-&gt;set_value(</span><br><span class="line">      &quot;model_server_batch_threads&quot;);</span><br><span class="line">&#125;</span><br><span class="line">*saved_model_bundle_source_adapter_config.mutable_legacy_config() =</span><br><span class="line">    session_bundle_config;</span><br></pre></td></tr></table></figure>
<p>在到达完整批处理时，推理请求在内部合并为单个大请求（张量），并调用tensorflow :: Session :: Run（）（这是GPU上实际效率增益的来源）</p>
<h2 id="3-模型训练（对比）"><a href="#3-模型训练（对比）" class="headerlink" title="3.模型训练（对比）"></a>3.模型训练（对比）</h2><p>10000个epochs训练过程</p>
<p><img src="/images/tensor_02/2.png" alt=""></p>
<p><img src="/images/tensor_02/3.png" alt=""></p>
<h1 id="四-模型分析"><a href="#四-模型分析" class="headerlink" title="四.模型分析"></a>四.模型分析</h1><p><a href="https://blog.csdn.net/lien0906/article/details/78863118" target="_blank" rel="noopener">模型分析方法</a></p>
<h2 id="1-神经网络显存占用"><a href="#1-神经网络显存占用" class="headerlink" title="1. 神经网络显存占用"></a><strong>1. 神经网络显存占用</strong></h2><p>神经网络模型占用的显存包括：</p>
<ul>
<li>模型自身的参数</li>
<li>模型的输出</li>
</ul>
<p>举例来说，对于如下图所示的一个全连接网络(不考虑偏置项b)</p>
<p><img src="https://pic2.zhimg.com/80/v2-81063f1d5864c79bd422b7a42199a079_hd.jpg" alt="img"></p>
<p>模型的显存占用包括：</p>
<p>参数：二维数组 W<br>模型的输出： 二维数组 Y<br>输入X可以看成是上一层的输出，因此把它的显存占用归于上一层。</p>
<h2 id="1-2-参数的显存占用"><a href="#1-2-参数的显存占用" class="headerlink" title="1.2 参数的显存占用"></a>1.2 参数的显存占用</h2><p>只有有参数的层，才会有显存占用。这部份的显存占用和<strong>输入无关</strong>，模型加载完成之后就会占用。</p>
<p><strong>有参数的层主要包括：</strong></p>
<ul>
<li>卷积</li>
<li>全连接</li>
<li>BatchNorm</li>
<li>Embedding层</li>
<li>… …</li>
</ul>
<p><strong>无参数的层</strong>：</p>
<ul>
<li>多数的激活层(Sigmoid/ReLU)</li>
<li>池化层</li>
<li>Dropout</li>
<li>… …</li>
</ul>
<p>更具体的来说，模型的参数数目(这里均不考虑偏置项b)为：</p>
<ul>
<li>Linear(M-&gt;N): 参数数目：M×N</li>
<li>Conv2d(Cin, Cout, K): 参数数目：Cin × Cout × K × K</li>
<li>BatchNorm(N): 参数数目： 2N</li>
<li>Embedding(N,W): 参数数目： N × W</li>
</ul>
<p>参数占用显存 = 参数数目×n</p>
<p>n = 4 ：float32</p>
<p>n = 2 : float16</p>
<p>n = 8 : double64</p>
<p>在PyTorch中，当你执行完model=MyGreatModel().cuda()之后就会占用相应的显存，占用的显存大小基本与上述分析的显存差不多（会稍大一些，因为其它开销）。</p>
<h2 id="1-3-梯度与动量的显存占用"><a href="#1-3-梯度与动量的显存占用" class="headerlink" title="1.3 梯度与动量的显存占用"></a>1.3 梯度与动量的显存占用</h2><p>举例来说， 优化器如果是SGD：</p>
<p><img src="https://www.zhihu.com/equation?tex=W_%7Bt%2B1%7D+%3D+W_%7Bt%7D+-+%5Calpha+%5Cnabla+F%28W_t%29" alt="W_{t+1} = W_{t} - \alpha \nabla F(W_t)"></p>
<p>可以看出来，除了保存W之外还要保存对应的梯度 <img src="https://www.zhihu.com/equation?tex=%5Cnabla+F%28W%29" alt="\nabla F(W)"> ，因此显存占用等于参数占用的显存x2,</p>
<p>如果是带Momentum-SGD</p>
<p><img src="https://www.zhihu.com/equation?tex=v_%7Bt%2B1%7D+%3D+%5Crho+v_t+%2B+%5Cnabla+F%28W_t%29%5C%5C+W_%7Bt%2B1%7D+%3D+W_%7Bt%7D+-+%5Calpha+v_%7Bt%2B1%7D" alt="v_{t+1} = \rho v_t + \nabla F(W_t)\\ W_{t+1} = W_{t} - \alpha v_{t+1}"></p>
<p>这时候还需要保存动量， 因此显存x3</p>
<p>如果是Adam优化器，动量占用的显存更多，显存x4</p>
<p>总结一下，模型中<strong>与输入无关的显存占用</strong>包括：</p>
<ul>
<li>参数 <strong>W</strong></li>
<li>梯度 <strong>dW</strong>（一般与参数一样）</li>
<li>优化器的<strong>动量</strong>（普通SGD没有动量，momentum-SGD动量与梯度一样，Adam优化器动量的数量是梯度的两倍）</li>
</ul>
<h2 id="1-4-输入输出的显存占用"><a href="#1-4-输入输出的显存占用" class="headerlink" title="1.4 输入输出的显存占用"></a>1.4 输入输出的显存占用</h2><p>这部份的显存主要看输出的feature map 的形状。</p>
<p><img src="https://pic2.zhimg.com/80/v2-f4d6bb11679be2251e12dad4f2cc56f9_hd.jpg" alt="img">feature map</p>
<p>比如卷积的输入输出满足以下关系：</p>
<p><img src="https://pic2.zhimg.com/80/v2-f05c13bb2fd8eecc0bd7b6e4d3d3148d_hd.jpg" alt="img"></p>
<p>据此可以计算出每一层输出的Tensor的形状，然后就能计算出相应的显存占用。</p>
<p>模型输出的显存占用，总结如下：</p>
<ul>
<li>需要计算每一层的feature map的形状（多维数组的形状）</li>
<li>需要保存输出对应的梯度用以反向传播（链式法则）</li>
<li><strong>显存占用与 batch size 成正比</strong></li>
<li>模型输出不需要存储相应的动量信息。</li>
</ul>
<p>深度学习中神经网络的显存占用，我们可以得到如下公式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">显存占用 = 模型显存占用 + batch_size × 每个样本的显存占用</span><br></pre></td></tr></table></figure>
<p>可以看出显存不是和batch-size简单的成正比，尤其是模型自身比较复杂的情况下：比如全连接很大，Embedding层很大</p>
<p>另外需要注意：</p>
<ul>
<li>输入（数据，图片）一般不需要计算梯度</li>
<li>神经网络的每一层输入输出都需要保存下来，用来反向传播，但是在某些特殊的情况下，我们可以不要保存输入。比如ReLU，在PyTorch中，使用<code>nn.ReLU(inplace = True)</code> 能将激活函数ReLU的输出直接覆盖保存于模型的输入之中，节省不少显存。</li>
</ul>
<p><img src="https://img-blog.csdn.net/20171126122158007?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemp1Y29y/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="img"></p>
<p><img src="https://img-blog.csdn.net/20170405213708608?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvU2V2ZW5feWVhcl9Qcm9taXNl/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="img"></p>
<p><img src="https://img-blog.csdn.net/20170405213726978?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvU2V2ZW5feWVhcl9Qcm9taXNl/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="img"></p>
<p><img src="https://img-blog.csdn.net/20170405213826979?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvU2V2ZW5feWVhcl9Qcm9taXNl/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="img"></p>
<p><img src="https://img-blog.csdn.net/20170405213946417?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvU2V2ZW5feWVhcl9Qcm9taXNl/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="img"></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Deep-learning/" rel="tag"><i class="fa fa-tag"></i> Deep learning</a>
          
            <a href="/tags/科研-学习/" rel="tag"><i class="fa fa-tag"></i> 科研 - 学习</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/01/12/Linux_07_性能监控/" rel="next" title="linux性能监测工具（深度学习资源监控）">
                <i class="fa fa-chevron-left"></i> linux性能监测工具（深度学习资源监控）
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/02/17/java_01_Eclipse常用操作/" rel="prev" title="Eclipse常用操作">
                Eclipse常用操作 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1545151264345&di=3142133106fdfdce70d9b3866056d52c&imgtype=0&src=http%3A%2F%2Fimg4q.duitang.com%2Fuploads%2Fitem%2F201209%2F10%2F20120910083757_PdTei.png"
                alt="" />
            
              <p class="site-author-name" itemprop="name"></p>
              <p class="site-description motion-element" itemprop="description">Stay hungry！Stay foolish！</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">36</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">15</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/Asphelzhn" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://plus.google.com/asphel96" target="_blank" title="Google">
                      
                        <i class="fa fa-fw fa-google"></i>Google</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#一-TF-serving实现"><span class="nav-number">1.</span> <span class="nav-text">一.TF serving实现</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-Servables"><span class="nav-number">1.1.</span> <span class="nav-text">1.Servables</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-Models"><span class="nav-number">1.2.</span> <span class="nav-text">2.Models</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-Loaders"><span class="nav-number">1.3.</span> <span class="nav-text">3.Loaders</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-Sources"><span class="nav-number">1.4.</span> <span class="nav-text">4.Sources</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-Managers"><span class="nav-number">1.5.</span> <span class="nav-text">5.Managers</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-SavedModel"><span class="nav-number">1.6.</span> <span class="nav-text">6.SavedModel</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-ServableHandle"><span class="nav-number">1.7.</span> <span class="nav-text">7.ServableHandle</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-Batch"><span class="nav-number">1.8.</span> <span class="nav-text">8.Batch</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#BatchingSession"><span class="nav-number">1.8.1.</span> <span class="nav-text">BatchingSession</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#BasicBatchScheduler"><span class="nav-number">1.8.2.</span> <span class="nav-text">BasicBatchScheduler</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Mixed-CPU-GPU-IO-Workloads"><span class="nav-number">1.8.3.</span> <span class="nav-text">Mixed CPU/GPU/IO Workloads</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#二-TF-serving流程"><span class="nav-number">2.</span> <span class="nav-text">二. TF serving流程</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-训练和导出模型"><span class="nav-number">2.1.</span> <span class="nav-text">1.训练和导出模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-定义模型服务的参数和配置"><span class="nav-number">2.2.</span> <span class="nav-text">2.定义模型服务的参数和配置</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#predict-signature签名配置（包括回归，分类，推理）"><span class="nav-number">2.2.1.</span> <span class="nav-text">predict_signature签名配置（包括回归，分类，推理）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-Serving-with-Docker-using-GPU"><span class="nav-number">2.3.</span> <span class="nav-text">3.Serving with Docker using GPU</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#（1）Install-nvidia-docker-下载"><span class="nav-number">2.3.1.</span> <span class="nav-text">（1）Install nvidia-docker (下载)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#（2）Running-a-GPU-serving-image"><span class="nav-number">2.3.2.</span> <span class="nav-text">（2）Running a GPU serving image</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#（3）Serving-GPU-docker-image"><span class="nav-number">2.3.3.</span> <span class="nav-text">（3）Serving GPU docker image</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#（4）指定GPU-Docker加载模型"><span class="nav-number">2.3.4.</span> <span class="nav-text">（4）指定GPU Docker加载模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#（5）服务运行在指定端口，通过网络请求调用服务"><span class="nav-number">2.3.5.</span> <span class="nav-text">（5）服务运行在指定端口，通过网络请求调用服务</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#三-实验"><span class="nav-number">3.</span> <span class="nav-text">三.实验</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#实验环境"><span class="nav-number">3.0.1.</span> <span class="nav-text">实验环境</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#测量参数"><span class="nav-number">3.0.2.</span> <span class="nav-text">测量参数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-多用户依次请求"><span class="nav-number">3.1.</span> <span class="nav-text">1. 多用户依次请求</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#用户请求相同"><span class="nav-number">3.1.1.</span> <span class="nav-text">用户请求相同</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#用户请求不同"><span class="nav-number">3.1.2.</span> <span class="nav-text">用户请求不同</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-多用户按批次请求"><span class="nav-number">3.2.</span> <span class="nav-text">2. 多用户按批次请求</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-模型训练（对比）"><span class="nav-number">3.3.</span> <span class="nav-text">3.模型训练（对比）</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#四-模型分析"><span class="nav-number">4.</span> <span class="nav-text">四.模型分析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-神经网络显存占用"><span class="nav-number">4.1.</span> <span class="nav-text">1. 神经网络显存占用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-2-参数的显存占用"><span class="nav-number">4.2.</span> <span class="nav-text">1.2 参数的显存占用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-3-梯度与动量的显存占用"><span class="nav-number">4.3.</span> <span class="nav-text">1.3 梯度与动量的显存占用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-4-输入输出的显存占用"><span class="nav-number">4.4.</span> <span class="nav-text">1.4 输入输出的显存占用</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder"></span>

  
</div>

    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">本站访客数<span id="busuanzi_value_site_uv"></span>人</span>







        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://Edward.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://yoursite.com/2019/01/16/tensor_02_serving/';
          this.page.identifier = '2019/01/16/tensor_02_serving/';
          this.page.title = 'Tensorflow内核学习';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://Edward.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  





  

  

  

  
  

  

  

  

</body>
</html>
<script type="text/javascript" src="/js/src/clicklove.js"></script>