<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[NVIDIA MPS总结]]></title>
    <url>%2F2019%2F04%2F14%2Ftensor_09_MPS%2F</url>
    <content type="text"><![CDATA[1.NVIDIA MPS介绍MPS多进程服务（Multi-Process Scheduling）是CUDA应用程序编程接口（API）的替代二进制兼容实现。从Kepler的GP10架构开始，NVIDIA就引入了MPS（基于软件的多进程服务），这种技术在当时实际上是称为HyperQ ，允许多个 流（stream）或者CPU的进程同时向GPU发射Kernel函数，结合为一个单一应用程序的上下文在GPU上运行，从而实现更好的GPU利用率。在单个进程的任务处理，对GPU利用率不高的情况下是非常有用的。实际上，在Pascal架构出现之后的MPS可以认为是HyperQ的一种实现方式。 最近需要使用到MPS，但是发现网上资料不多，而且很杂乱，所以在此总结一下。官方文档链接 MPS作用：多容器共享GPU会引发资源竞争和浪费的问题，不仅GPU利用率不高，也无法保证QoS。当使用NVIDIA MPS时，MPS Sever会通过一个CUDA Context管理GPU硬件资源，多个MPS Clients会将它们的任务通过MPS Server传入GPU，从而越过了硬件时间分片调度的限制，使得它们的CUDA kernels实现真正意义上的并行。特别地，Volta MPS可以兼容docker容器，并且支持执行资源配置（即每个Client context只能获取一定比例的threads），提高了多容器共享GPU的QoS。 增加GPU的利用率； 减少多个CUDA进程在GPU上的上下文空间。该空间主要是用于存储和调度资源； 减少GPU的上下文的切换。 但MPS实际上也是有一些使用限制的，比方它现在仅支持Linux操作系统，还要求GPU的运算能力必须大于3.5。 MPS实例 假设在CPU端有A、B、C三个进程，每个进程都要发射CUDA Kernel的任务到GPU上去，并且假设它们每一个独立的任务对GPU利用率都不高。 在不使用MPS服务的情况下，A、B、C三个进程实际上也可以同时把CUDA任务发射到GPU上去，但是默认采用时间片轮转调度的方式。首先第一个时间片，A任务被执行，接着第二个时间片，执行B任务，第三个时间片， C任务将被执行。时间片是依次进行轮转调度的，分别执行A、B、C中的任务。 可以直观地看到， 在GPU中，每一个时刻只有一个任务在执行。这种情况下，CPU中的process（进程）发射的CUDA任务对GPU的利用率很低。 2.Pascal架构和Volta架构我们常用的GTX 1080 ti和GP100是Pascal架构的，NVIDIA基于深度学习的任务特点推出了Volta架构的Tesla V100数据中心级显卡。我们简单低看一下两种架构的GPU区别。 上图是Pascal SM 架构图，可以看到一个 GP100 SM 分成两个处理块，每块有32768 个 32 位寄存器 + 32 个单精度 CUDA 核心 + 16 个双精度 CUDA 核心 + 8 个特殊功能单元（SFU） + 8 个存取单元 + 一个指令缓冲区 + 一个 warp 调度器 + 两个分发单元。LD/ST加载存储单元，SFU为特殊功能单元，用来执行超越函数指令，如正弦函数。 上图是Volta SM架构图，每个 SM 有 64 个 FP32 核、64 个 INT32 核、32 个 FP64 核与 8 个全新的 Tensor Core。新的 Tensor Core 是 Volta GV100 最重要的特征，有助于提高训练神经网络所需的性能。Tesla V100 的 Tensor Core 能够为训练、推理应用的提供 120 Tensor TFLOPS。相比于在 P100 FP 32 上，在 Tesla V100 上进行深度学习训练有 12 倍的峰值 TFLOPS 提升。而在深度学习推理能力上，相比于 P100 FP16 运算，有了 6 倍的提升。与前一代 Pascal GP100 GPU 类似，GV100 GPU 由多个图形处理集群（Graphics Processing Cluster，GPC）、纹理处理集群（Texture Processing Cluster，TPC）、流式多处理器（Streaming Multiprocessor，SM）以及内存控制器组成。一个完整的 GV100 GPU 由 6 个 GPC、84 个 Volta SM、42 个 TPC（每个 TPC 包含了 2 个 SM）和 8 个 512 位的内存控制器（共 4096 位）。 3.不同架构上的MPS实现 上图是基于Pascal架构的MPS服务对任务的处理情况。可以看到A、B、C三个进程分别提交各自的任务到MPS的服务端，并在服务端整合为一个统一的上下文，并将三个任务同时发射到GPU中执行，这就有效地提升了GPU的利用率。在Pascal架构下，MPS是最多可以支持16个进程或者说16个用户同时提交任务。 上图是Volta架构MPS的执行情况，Volta架构对MPS的实现做了改进，主要是基于硬件加速的方式来实现。此时不同的进程是可以直接穿过MPS服务器，提交任务到GPU的硬件，并且每个进程客户端有隔离的地址空间，这样可以进一步减少Launch（发射进程）时带来的延迟，也可以通过限制执行资源配置来提升服务质量。这里所说提升服务质量是指怎么样平衡多个process（进程）发射任务对计算和存储资源的占用情况。比如我们现在可以去设定每一个process上下文，最多可以使用多少个资源。Volta下的MPS服务最多可以允许同时48个Client（客户端）。 4.MPS基准测试 官方给出的一个benchmark（基准）测试。我们知道，对于单个任务占用GPU资源比较少的情形，MPS服务是非常有用的，比如在深度学习中做Inference（推理）应用。相比Training（训练），Inference对于计算和存储资源的要求比较小，这个时候会出现我们之前看到的情况，单一的Kernel任务是没法有效利用GPU的。从上面的benchmark可以看到图中最左侧灰色的柱状图，在不使用MPS的情况下，Inference的吞吐性能很小；而中间绿色的柱状图，使用MPS允许多个Client同时发射计算任务到GPU，此时GPU吞吐性能直接提升了七倍；最后一个柱状图表示，如果我们使用MPS，并结合Batching操作，吞吐性能还能继续再提升60%左右。由此可见，对于像Deep Learning的Inference这样的应用，MPS技术是可以有效地帮助我们优化GPU利用率以及程序的吞吐性能。 5.MPS的使用MPS组成MPS主要包括控制守护进程（MPS Control Daemo）、客户端运行时（Client Runtime）和服务进程（Server Process）。CUDA contexts可以通过MPS Server提交作业，这样就越过了硬件的时间切片调度的限制，实现多个进程在同一个GPU上并行执行。如果没有MPS，多个进程只是在同一个GPU上并发执行，即每个进程在一个时间分片里独享GPU。 默认情况下，GPU是没有开启MPS的，每个CUDA程序会创建自己的CUDA Context来管理GPU资源，并以时间分片的方式共享GPU。开启MPS后，在需要的时候，MPS control daemon会启动一个MPS Server，监听任务请求。 开启与关闭MPS启动 mps-control 1234567export CUDA_VISIBLE_DEVICES=0export CUDA_MPS_PIPE_DIRECTORY=/tmp/nvidia-mpsexport CUDA_MPS_LOG_DIRECTORY=/tmp/nvidia-log nvidia-cuda-mps-control -d 关闭mps-control 1echo quit | nvidia-cuda-mps-control 注意以上两个命令需要管理员权限。 Volta MPS资源配置执行资源配置的方法如下： 123nvidia-cuda-mps-controlset_default_active_thread_percentage 10 命令为每个MPS Client限制10%的threads。不是为每个Client预留专用资源，而是限制它们可以最多使用多少threads。默认情况下，每个Client可以获取所有threads（即100%）。 公平性关闭MPS，多任务通过时间分片的调度方式共享GPU；开启MPS，多任务共享Server的CUDA Context。无论哪种情况，在所有任务所占显存总容量不超出GPU容量时，每个任务都能公平地获得GPU的threads。 参考资料 https://cloud.tencent.com/developer/article/1081424 https://cloud.tencent.com/developer/article/1117712 https://blog.csdn.net/kkk584520/article/details/53814067 https://www.cnblogs.com/xingzifei/p/6136095.html https://blog.csdn.net/beckham999221/article/details/86644970 https://blog.csdn.net/beckham999221/article/details/85257137]]></content>
      <categories>
        <category>Deep learning</category>
      </categories>
      <tags>
        <tag>Deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Boostrap笔记]]></title>
    <url>%2F2019%2F04%2F09%2Ffront_04_BootStrap%2F</url>
    <content type="text"><![CDATA[Bootstrap：1. 概念： 一个前端开发的框架，Bootstrap，来自 Twitter，是目前很受欢迎的前端框架。Bootstrap 是基于 HTML、CSS、JavaScript 的，它简洁灵活，使得 Web 开发更加快捷。 * 框架:一个半成品软件，开发人员可以在框架基础上，在进行开发，简化编码。 * 好处： 1. 定义了很多的css样式和js插件。我们开发人员直接可以使用这些样式和插件得到丰富的页面效果。 2. 响应式布局。 * 同一套页面可以兼容不同分辨率的设备。 2. 快速入门 1. 下载Bootstrap 2. 在项目中将这三个文件夹复制 3. 创建html页面，引入必要的资源文件 1234567891011121314151617181920&lt;!DOCTYPE html&gt; &lt;html lang="zh-CN"&gt; &lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1"&gt; &lt;!-- 上述3个meta标签*必须*放在最前面，任何其他内容都*必须*跟随其后！ --&gt; &lt;title&gt;Bootstrap HelloWorld&lt;/title&gt; &lt;!-- Bootstrap --&gt; &lt;link href="css/bootstrap.min.css" rel="stylesheet"&gt; &lt;!-- jQuery (Bootstrap 的所有 JavaScript 插件都依赖 jQuery，所以必须放在前边) --&gt; &lt;script src="js/jquery-3.2.1.min.js"&gt;&lt;/script&gt; &lt;!-- 加载 Bootstrap 的所有 JavaScript 插件。你也可以根据需要只加载单个插件。 --&gt; &lt;script src="js/bootstrap.min.js"&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;你好，世界！&lt;/h1&gt; &lt;/body&gt; &lt;/html&gt; 响应式布局* 同一套页面可以兼容不同分辨率的设备。 * 实现：依赖于栅格系统：将一行平均分成12个格子，可以指定元素占几个格子 * 步骤： 1. 定义容器。相当于之前的table、 * 容器分类： 1. container：两边留白 2. container-fluid：每一种设备都是100%宽度 2. 定义行。相当于之前的tr 样式：row 3. 定义元素。指定该元素在不同的设备上，所占的格子数目。样式：col-设备代号-格子数目 * 设备代号： 1. xs：超小屏幕 手机 (&lt;768px)：col-xs-12 2. sm：小屏幕 平板 (≥768px) 3. md：中等屏幕 桌面显示器 (≥992px) 4. lg：大屏幕 大桌面显示器 (≥1200px) * 注意： 1. 一行中如果格子数目超过12，则超出部分自动换行。 2. 栅格类属性可以向上兼容。栅格类适用于与屏幕宽度大于或等于分界点大小的设备。 3. 如果真实设备宽度小于了设置栅格类属性的设备代码的最小值，会一个元素沾满一整行。 CSS样式和JS插件1. 全局CSS样式： * 按钮：class=&quot;btn btn-default&quot; * 图片： * class=&quot;img-responsive&quot;：图片在任意尺寸都占100% * 图片形状 * &lt;img src=&quot;...&quot; alt=&quot;...&quot; class=&quot;img-rounded&quot;&gt;：方形 * &lt;img src=&quot;...&quot; alt=&quot;...&quot; class=&quot;img-circle&quot;&gt; ： 圆形 * &lt;img src=&quot;...&quot; alt=&quot;...&quot; class=&quot;img-thumbnail&quot;&gt; ：相框 * 表格 * table * table-bordered * table-hover * 表单 * 给表单项添加：class=&quot;form-control&quot; 2. 组件： * 导航条 * 分页条 3. 插件： * 轮播图 案例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;!-- HTML头 --&gt;&lt;!DOCTYPE html&gt;&lt;html lang=&quot;zh-CN&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1&quot;&gt; &lt;!-- 上述3个meta标签*必须*放在最前面，任何其他内容都*必须*跟随其后！ --&gt; &lt;title&gt;Bootstrap HelloWorld&lt;/title&gt; &lt;!-- Bootstrap --&gt; &lt;link href=&quot;css/bootstrap.min.css&quot; rel=&quot;stylesheet&quot;&gt;​ &lt;!-- jQuery (Bootstrap 的所有 JavaScript 插件都依赖 jQuery，所以必须放在前边) --&gt;​ &lt;script src=&quot;js/jquery-3.2.1.min.js&quot;&gt;&lt;/script&gt;​ &lt;!-- 加载 Bootstrap 的所有 JavaScript 插件。你也可以根据需要只加载单个插件。 --&gt;​ &lt;script src=&quot;js/bootstrap.min.js&quot;&gt;&lt;/script&gt;​ &lt;style&gt;​ .paddtop&#123;​ padding-top: 10px;​ &#125;​ .search-btn&#123;​ float: left;​ border:1px solid #ffc900;​ width: 90px;​ height: 35px;​ background-color:#ffc900 ;​ text-align: center;​ line-height: 35px;​ margin-top: 15px;​ &#125;​ .search-input&#123;​ float: left;​ border:2px solid #ffc900;​ width: 400px;​ height: 35px;​ padding-left: 5px;​ margin-top: 15px;​ &#125;​ .jx&#123;​ border-bottom: 2px solid #ffc900;​ padding: 5px;​ &#125;​ .company&#123;​ height: 40px;​ background-color: #ffc900;​ text-align: center;​ line-height:40px ;​ font-size: 8px;​ &#125;​ &lt;/style&gt;​ &lt;/head&gt;​ &lt;body&gt; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586 &lt;!-- 1.页眉部分--&gt; &lt;header class=&quot;container-fluid&quot;&gt; &lt;div class=&quot;row&quot;&gt; &lt;img src=&quot;img/top_banner.jpg&quot; class=&quot;img-responsive&quot;&gt; &lt;/div&gt; &lt;div class=&quot;row paddtop&quot;&gt; &lt;div class=&quot;col-md-3&quot;&gt; &lt;img src=&quot;img/logo.jpg&quot; class=&quot;img-responsive&quot;&gt; &lt;/div&gt; &lt;div class=&quot;col-md-5&quot;&gt; &lt;input class=&quot;search-input&quot; placeholder=&quot;请输入线路名称&quot;&gt; &lt;a class=&quot;search-btn&quot; href=&quot;#&quot;&gt;搜索&lt;/a&gt; &lt;/div&gt; &lt;div class=&quot;col-md-4&quot;&gt; &lt;img src=&quot;img/hotel_tel.png&quot; class=&quot;img-responsive&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;!--导航栏--&gt; &lt;div class=&quot;row&quot;&gt; &lt;nav class=&quot;navbar navbar-default&quot;&gt; &lt;div class=&quot;container-fluid&quot;&gt; &lt;!-- Brand and toggle get grouped for better mobile display --&gt; &lt;div class=&quot;navbar-header&quot;&gt; &lt;!-- 定义汉堡按钮 --&gt; &lt;button type=&quot;button&quot; class=&quot;navbar-toggle collapsed&quot; data-toggle=&quot;collapse&quot; data-target=&quot;#bs-example-navbar-collapse-1&quot; aria-expanded=&quot;false&quot;&gt; &lt;span class=&quot;sr-only&quot;&gt;Toggle navigation&lt;/span&gt; &lt;span class=&quot;icon-bar&quot;&gt;&lt;/span&gt; &lt;span class=&quot;icon-bar&quot;&gt;&lt;/span&gt; &lt;span class=&quot;icon-bar&quot;&gt;&lt;/span&gt; &lt;/button&gt; &lt;a class=&quot;navbar-brand&quot; href=&quot;#&quot;&gt;首页&lt;/a&gt; &lt;/div&gt; &lt;!-- Collect the nav links, forms, and other content for toggling --&gt; &lt;div class=&quot;collapse navbar-collapse&quot; id=&quot;bs-example-navbar-collapse-1&quot;&gt; &lt;ul class=&quot;nav navbar-nav&quot;&gt; &lt;li class=&quot;active&quot;&gt;&lt;a href=&quot;#&quot;&gt;Link &lt;span class=&quot;sr-only&quot;&gt;(current)&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#&quot;&gt;Link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#&quot;&gt;Link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#&quot;&gt;Link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#&quot;&gt;Link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#&quot;&gt;Link&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;!-- /.navbar-collapse --&gt; &lt;/div&gt;&lt;!-- /.container-fluid --&gt; &lt;/nav&gt; &lt;/div&gt; &lt;!--轮播图--&gt; &lt;div class=&quot;row&quot;&gt; &lt;div id=&quot;carousel-example-generic&quot; class=&quot;carousel slide&quot; data-ride=&quot;carousel&quot;&gt; &lt;!-- Indicators --&gt; &lt;ol class=&quot;carousel-indicators&quot;&gt; &lt;li data-target=&quot;#carousel-example-generic&quot; data-slide-to=&quot;0&quot; class=&quot;active&quot;&gt;&lt;/li&gt; &lt;li data-target=&quot;#carousel-example-generic&quot; data-slide-to=&quot;1&quot;&gt;&lt;/li&gt; &lt;li data-target=&quot;#carousel-example-generic&quot; data-slide-to=&quot;2&quot;&gt;&lt;/li&gt; &lt;/ol&gt; &lt;!-- Wrapper for slides --&gt; &lt;div class=&quot;carousel-inner&quot; role=&quot;listbox&quot;&gt; &lt;div class=&quot;item active&quot;&gt; &lt;img src=&quot;img/banner_1.jpg&quot; alt=&quot;...&quot;&gt; &lt;/div&gt; &lt;div class=&quot;item&quot;&gt; &lt;img src=&quot;img/banner_2.jpg&quot; alt=&quot;...&quot;&gt; &lt;/div&gt; &lt;div class=&quot;item&quot;&gt; &lt;img src=&quot;img/banner_3.jpg&quot; alt=&quot;...&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;!-- Controls --&gt; &lt;a class=&quot;left carousel-control&quot; href=&quot;#carousel-example-generic&quot; role=&quot;button&quot; data-slide=&quot;prev&quot;&gt; &lt;span class=&quot;glyphicon glyphicon-chevron-left&quot; aria-hidden=&quot;true&quot;&gt;&lt;/span&gt; &lt;span class=&quot;sr-only&quot;&gt;Previous&lt;/span&gt; &lt;/a&gt; &lt;a class=&quot;right carousel-control&quot; href=&quot;#carousel-example-generic&quot; role=&quot;button&quot; data-slide=&quot;next&quot;&gt; &lt;span class=&quot;glyphicon glyphicon-chevron-right&quot; aria-hidden=&quot;true&quot;&gt;&lt;/span&gt; &lt;span class=&quot;sr-only&quot;&gt;Next&lt;/span&gt; &lt;/a&gt; &lt;/div&gt;​ &lt;/div&gt;​ &lt;/header&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111 &lt;!-- 2.主体部分--&gt;​ &lt;div class=&quot;container&quot;&gt;​ &lt;div class=&quot;row jx&quot;&gt;​ &lt;img src=&quot;img/icon_5.jpg&quot;&gt;​ &lt;span&gt;黑马精选&lt;/span&gt;​ &lt;/div&gt;​ ​ &lt;div class=&quot;row paddtop&quot;&gt;​ &lt;div class=&quot;col-md-3&quot;&gt;​ &lt;div class=&quot;thumbnail&quot;&gt;​ &lt;img src=&quot;img/jiangxuan_3.jpg&quot; alt=&quot;&quot;&gt;​ &lt;p&gt;上海直飞三亚5天4晚自由行(春节预售+亲子/蜜月/休闲游首选+豪华酒店任选+接送机)&lt;/p&gt;​ &lt;font color=&quot;red&quot;&gt;&amp;yen; 699&lt;/font&gt;​ &lt;/div&gt;​ &lt;/div&gt;​ &lt;div class=&quot;col-md-3&quot;&gt;​ &lt;div class=&quot;thumbnail&quot;&gt;​ &lt;img src=&quot;img/jiangxuan_3.jpg&quot; alt=&quot;&quot;&gt;​ &lt;p&gt;上海直飞三亚5天4晚自由行(春节预售+亲子/蜜月/休闲游首选+豪华酒店任选+接送机)&lt;/p&gt;​ &lt;font color=&quot;red&quot;&gt;&amp;yen; 699&lt;/font&gt;​ &lt;/div&gt;​ &lt;/div&gt; &lt;div class=&quot;col-md-3&quot;&gt; &lt;div class=&quot;thumbnail&quot;&gt; &lt;img src=&quot;img/jiangxuan_3.jpg&quot; alt=&quot;&quot;&gt; &lt;p&gt;上海直飞三亚5天4晚自由行(春节预售+亲子/蜜月/休闲游首选+豪华酒店任选+接送机)&lt;/p&gt; &lt;font color=&quot;red&quot;&gt;&amp;yen; 699&lt;/font&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;col-md-3&quot;&gt; &lt;div class=&quot;thumbnail&quot;&gt; &lt;img src=&quot;img/jiangxuan_3.jpg&quot; alt=&quot;&quot;&gt; &lt;p&gt;上海直飞三亚5天4晚自由行(春节预售+亲子/蜜月/休闲游首选+豪华酒店任选+接送机)&lt;/p&gt; &lt;font color=&quot;red&quot;&gt;&amp;yen; 699&lt;/font&gt; &lt;/div&gt; &lt;/div&gt;​ ​ &lt;/div&gt;​ &lt;div class=&quot;row jx&quot;&gt;​ &lt;img src=&quot;img/icon_6.jpg&quot;&gt;​ &lt;span&gt;国内游&lt;/span&gt;​ &lt;/div&gt;​ &lt;div class=&quot;row paddtop&quot;&gt;​ &lt;div class=&quot;col-md-4&quot;&gt;​ &lt;img src=&quot;img/guonei_1.jpg&quot;&gt;​ &lt;/div&gt;​ &lt;div class=&quot;col-md-8&quot;&gt;​ &lt;div class=&quot;row&quot;&gt;​ &lt;div class=&quot;col-md-4&quot;&gt;​ &lt;div class=&quot;thumbnail&quot;&gt;​ &lt;img src=&quot;img/jiangxuan_3.jpg&quot; alt=&quot;&quot;&gt;​ &lt;p&gt;上海直飞三亚5天4晚自由行(春节预售+亲子/蜜月/休闲游首选+豪华酒店任选+接送机)&lt;/p&gt;​ &lt;font color=&quot;red&quot;&gt;&amp;yen; 699&lt;/font&gt;​ &lt;/div&gt;​ &lt;/div&gt;​ &lt;div class=&quot;col-md-4&quot;&gt;​ &lt;div class=&quot;thumbnail&quot;&gt;​ &lt;img src=&quot;img/jiangxuan_3.jpg&quot; alt=&quot;&quot;&gt;​ &lt;p&gt;上海直飞三亚5天4晚自由行(春节预售+亲子/蜜月/休闲游首选+豪华酒店任选+接送机)&lt;/p&gt;​ &lt;font color=&quot;red&quot;&gt;&amp;yen; 699&lt;/font&gt;​ &lt;/div&gt;​ ​ &lt;/div&gt;​ &lt;div class=&quot;col-md-4&quot;&gt;​ ​ &lt;div class=&quot;thumbnail&quot;&gt;​ &lt;img src=&quot;img/jiangxuan_3.jpg&quot; alt=&quot;&quot;&gt;​ &lt;p&gt;上海直飞三亚5天4晚自由行(春节预售+亲子/蜜月/休闲游首选+豪华酒店任选+接送机)&lt;/p&gt;​ &lt;font color=&quot;red&quot;&gt;&amp;yen; 699&lt;/font&gt;​ &lt;/div&gt;​ &lt;/div&gt;​ &lt;/div&gt; &lt;div class=&quot;row&quot;&gt; &lt;div class=&quot;col-md-4&quot;&gt; &lt;div class=&quot;thumbnail&quot;&gt; &lt;img src=&quot;img/jiangxuan_3.jpg&quot; alt=&quot;&quot;&gt; &lt;p&gt;上海直飞三亚5天4晚自由行(春节预售+亲子/蜜月/休闲游首选+豪华酒店任选+接送机)&lt;/p&gt; &lt;font color=&quot;red&quot;&gt;&amp;yen; 699&lt;/font&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;col-md-4&quot;&gt; &lt;div class=&quot;thumbnail&quot;&gt; &lt;img src=&quot;img/jiangxuan_3.jpg&quot; alt=&quot;&quot;&gt; &lt;p&gt;上海直飞三亚5天4晚自由行(春节预售+亲子/蜜月/休闲游首选+豪华酒店任选+接送机)&lt;/p&gt; &lt;font color=&quot;red&quot;&gt;&amp;yen; 699&lt;/font&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;col-md-4&quot;&gt; &lt;div class=&quot;thumbnail&quot;&gt; &lt;img src=&quot;img/jiangxuan_3.jpg&quot; alt=&quot;&quot;&gt; &lt;p&gt;上海直飞三亚5天4晚自由行(春节预售+亲子/蜜月/休闲游首选+豪华酒店任选+接送机)&lt;/p&gt; &lt;font color=&quot;red&quot;&gt;&amp;yen; 699&lt;/font&gt; &lt;/div&gt; &lt;/div&gt;​ ​ &lt;/div&gt;​ ​ &lt;/div&gt;​ ​ &lt;/div&gt;​ &lt;/div&gt; 123456789101112131415 &lt;!-- 3.页脚部分--&gt;​ &lt;footer class=&quot;container-fluid&quot;&gt;​ &lt;div class=&quot;row&quot;&gt;​ &lt;img src=&quot;img/footer_service.png&quot; class=&quot;img-responsive&quot;&gt;​ &lt;/div&gt;​ &lt;div class=&quot;row company&quot;&gt;​ 江苏传智播客教育科技股份有限公司 版权所有Copyright 2006-2018, All Rights Reserved 苏ICP备16007882​ &lt;/div&gt;​ &lt;/footer&gt;​ ​ &lt;/body&gt;​ &lt;/html&gt;]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Boostrap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java异常总结]]></title>
    <url>%2F2019%2F04%2F08%2FJava_08_%20exception%2F</url>
    <content type="text"><![CDATA[知识点 能够辨别程序中异常和错误的区别 说出异常的分类 说出虚拟机处理异常的方式 列举出常见的三个运行期异常 能够使用try…catch关键字处理异常 能够使用throws关键字处理异常 能够自定义异常类 能够处理自定义异常类 说出进程的概念 说出线程的概念 能够理解并发与并行的区别 能够开启新线程 第一章 异常1.1 异常概念异常，就是不正常的意思。在生活中:医生说,你的身体某个部位有异常,该部位和正常相比有点不同,该部位的功能将受影响.在程序中的意思就是： 异常 ：指的是程序在执行过程中，出现的非正常的情况，最终会导致JVM的非正常停止。 在Java等面向对象的编程语言中，异常本身是一个类，产生异常就是创建异常对象并抛出了一个异常对象。Java处理异常的方式是中断处理。 异常指的并不是语法错误,语法错了,编译不通过,不会产生字节码文件,根本不能运行. 1.2 异常体系异常机制其实是帮助我们找到程序中的问题，异常的根类是java.lang.Throwable，其下有两个子类：java.lang.Error与java.lang.Exception，平常所说的异常指java.lang.Exception。 Throwable体系： Error:严重错误Error，无法通过处理的错误，只能事先避免，好比绝症。 Exception:表示异常，异常产生后程序员可以通过代码的方式纠正，使程序继续运行，是必须要处理的。好比感冒、阑尾炎。 Throwable中的常用方法： public void printStackTrace():打印异常的详细信息。 包含了异常的类型,异常的原因,还包括异常出现的位置,在开发和调试阶段,都得使用printStackTrace。 public String getMessage():获取发生异常的原因。 提示给用户的时候,就提示错误原因。 public String toString():获取异常的类型和异常描述信息(不用)。 出现异常,不要紧张,把异常的简单类名,拷贝到API中去查。 1.3 异常分类我们平常说的异常就是指Exception，因为这类异常一旦出现，我们就要对代码进行更正，修复程序。 异常(Exception)的分类:根据在编译时期还是运行时期去检查异常? 编译时期异常:checked异常。在编译时期,就会检查,如果没有处理异常,则编译失败。(如日期格式化异常) 运行时期异常:runtime异常。在运行时期,检查异常.在编译时期,运行异常不会编译器检测(不报错)。(如数学异常) ​ 1.4 异常的产生过程解析先运行下面的程序，程序会产生一个数组索引越界异常ArrayIndexOfBoundsException。我们通过图解来解析下异常产生的过程。 工具类 1234567public class ArrayTools &#123; // 对给定的数组通过给定的角标获取元素。 public static int getElement(int[] arr, int index) &#123; int element = arr[index]; return element; &#125;&#125; 测试类 12345678public class ExceptionDemo &#123; public static void main(String[] args) &#123; int[] arr = &#123; 34, 12, 67 &#125;; intnum = ArrayTools.getElement(arr, 4) System.out.println("num=" + num); System.out.println("over"); &#125;&#125; 上述程序执行过程图解： 第二章 异常的处理Java异常处理的五个关键字：try、catch、finally、throw、throws 2.1 抛出异常throw在编写程序时，我们必须要考虑程序出现问题的情况。比如，在定义方法时，方法需要接受参数。那么，当调用方法使用接受到的参数时，首先需要先对参数数据进行合法的判断，数据若不合法，就应该告诉调用者，传递合法的数据进来。这时需要使用抛出异常的方式来告诉调用者。 在java中，提供了一个throw关键字，它用来抛出一个指定的异常对象。那么，抛出一个异常具体如何操作呢？ 创建一个异常对象。封装一些提示信息(信息可以自己编写)。 需要将这个异常对象告知给调用者。怎么告知呢？怎么将这个异常对象传递到调用者处呢？通过关键字throw就可以完成。throw 异常对象。 throw用在方法内，用来抛出一个异常对象，将这个异常对象传递到调用者处，并结束当前方法的执行。 使用格式： 1throw new 异常类名(参数); 例如： 123throw new NullPointerException("要访问的arr数组不存在");throw new ArrayIndexOutOfBoundsException("该索引在数组中不存在，已超出范围"); 学习完抛出异常的格式后，我们通过下面程序演示下throw的使用。 123456789101112131415161718192021222324252627public class ThrowDemo &#123; public static void main(String[] args) &#123; //创建一个数组 int[] arr = &#123;2,4,52,2&#125;; //根据索引找对应的元素 int index = 4; int element = getElement(arr, index); System.out.println(element); System.out.println("over"); &#125; /* * 根据 索引找到数组中对应的元素 */ public static int getElement(int[] arr,int index)&#123; //判断 索引是否越界 if(index&lt;0 || index&gt;arr.length-1)&#123; /* 判断条件如果满足，当执行完throw抛出异常对象后，方法已经无法继续运算。 这时就会结束当前方法的执行，并将异常告知给调用者。这时就需要通过异常来解决。 */ throw new ArrayIndexOutOfBoundsException("哥们，角标越界了~~~"); &#125; int element = arr[index]; return element; &#125;&#125; 注意：如果产生了问题，我们就会throw将问题描述类即异常进行抛出，也就是将问题返回给该方法的调用者。 那么对于调用者来说，该怎么处理呢？一种是进行捕获处理，另一种就是继续讲问题声明出去，使用throws声明处理。 2.2 Objects非空判断还记得我们学习过一个类Objects吗，曾经提到过它由一些静态的实用方法组成，这些方法是null-save（空指针安全的）或null-tolerant（容忍空指针的），那么在它的源码中，对对象为null的值进行了抛出异常操作。 public static &lt;T&gt; T requireNonNull(T obj):查看指定引用对象不是null。 查看源码发现这里对为null的进行了抛出异常操作： 12345public static &lt;T&gt; T requireNonNull(T obj) &#123; if (obj == null) throw new NullPointerException(); return obj;&#125; 2.3 声明异常throws声明异常：将问题标识出来，报告给调用者。如果方法内通过throw抛出了编译时异常，而没有捕获处理（稍后讲解该方式），那么必须通过throws进行声明，让调用者去处理。 关键字throws运用于方法声明之上,用于表示当前方法不处理异常,而是提醒该方法的调用者来处理异常(抛出异常). 声明异常格式： 1修饰符 返回值类型 方法名(参数) throws 异常类名1,异常类名2…&#123; &#125; 声明异常的代码演示： 12345678910111213public class ThrowsDemo &#123; public static void main(String[] args) throws FileNotFoundException &#123; read("a.txt"); &#125; // 如果定义功能时有问题发生需要报告给调用者。可以通过在方法上使用throws关键字进行声明 public static void read(String path) throws FileNotFoundException &#123; if (!path.equals("a.txt")) &#123;//如果不是 a.txt这个文件 // 我假设 如果不是 a.txt 认为 该文件不存在 是一个错误 也就是异常 throw throw new FileNotFoundException("文件不存在"); &#125; &#125;&#125; throws用于进行异常类的声明，若该方法可能有多种异常情况产生，那么在throws后面可以写多个异常类，用逗号隔开。 123456789101112131415public class ThrowsDemo2 &#123; public static void main(String[] args) throws IOException &#123; read("a.txt"); &#125; public static void read(String path)throws FileNotFoundException, IOException &#123; if (!path.equals("a.txt")) &#123;//如果不是 a.txt这个文件 // 我假设 如果不是 a.txt 认为 该文件不存在 是一个错误 也就是异常 throw throw new FileNotFoundException("文件不存在"); &#125; if (!path.equals("b.txt")) &#123; throw new IOException(); &#125; &#125;&#125; 2.4 捕获异常try…catch如果异常出现的话,会立刻终止程序,所以我们得处理异常: 该方法不处理,而是声明抛出,由该方法的调用者来处理(throws)。 在方法中使用try-catch的语句块来处理异常。 try-catch的方式就是捕获异常。 捕获异常：Java中对异常有针对性的语句进行捕获，可以对出现的异常进行指定方式的处理。 捕获异常语法如下： 123456try&#123; 编写可能会出现异常的代码&#125;catch(异常类型 e)&#123; 处理异常的代码 //记录日志/打印异常信息/继续抛出异常&#125; try：该代码块中编写可能产生异常的代码。 catch：用来进行某种异常的捕获，实现对捕获到的异常进行处理。 注意:try和catch都不能单独使用,必须连用。 演示如下： 123456789101112131415161718192021public class TryCatchDemo &#123; public static void main(String[] args) &#123; try &#123;// 当产生异常时，必须有处理方式。要么捕获，要么声明。 read("b.txt"); &#125; catch (FileNotFoundException e) &#123;// 括号中需要定义什么呢？ //try中抛出的是什么异常，在括号中就定义什么异常类型 System.out.println(e); &#125; System.out.println("over"); &#125; /* * * 我们 当前的这个方法中 有异常 有编译期异常 */ public static void read(String path) throws FileNotFoundException &#123; if (!path.equals("a.txt")) &#123;//如果不是 a.txt这个文件 // 我假设 如果不是 a.txt 认为 该文件不存在 是一个错误 也就是异常 throw throw new FileNotFoundException("文件不存在"); &#125; &#125;&#125; 如何获取异常信息： Throwable类中定义了一些查看方法: public String getMessage():获取异常的描述信息,原因(提示给用户的时候,就提示错误原因。 public String toString():获取异常的类型和异常描述信息(不用)。 public void printStackTrace():打印异常的跟踪栈信息并输出到控制台。 ​ 包含了异常的类型,异常的原因,还包括异常出现的位置,在开发和调试阶段,都得使用printStackTrace。 2.4 finally 代码块finally：有一些特定的代码无论异常是否发生，都需要执行。另外，因为异常会引发程序跳转，导致有些语句执行不到。而finally就是解决这个问题的，在finally代码块中存放的代码都是一定会被执行的。 什么时候的代码必须最终执行？ 当我们在try语句块中打开了一些物理资源(磁盘文件/网络连接/数据库连接等),我们都得在使用完之后,最终关闭打开的资源。 finally的语法: try…catch….finally:自身需要处理异常,最终还得关闭资源。 注意:finally不能单独使用。 比如在我们之后学习的IO流中，当打开了一个关联文件的资源，最后程序不管结果如何，都需要把这个资源关闭掉。 finally代码参考如下： 1234567891011121314151617181920212223public class TryCatchDemo4 &#123; public static void main(String[] args) &#123; try &#123; read("a.txt"); &#125; catch (FileNotFoundException e) &#123; //抓取到的是编译期异常 抛出去的是运行期 throw new RuntimeException(e); &#125; finally &#123; System.out.println("不管程序怎样，这里都将会被执行。"); &#125; System.out.println("over"); &#125; /* * * 我们 当前的这个方法中 有异常 有编译期异常 */ public static void read(String path) throws FileNotFoundException &#123; if (!path.equals("a.txt")) &#123;//如果不是 a.txt这个文件 // 我假设 如果不是 a.txt 认为 该文件不存在 是一个错误 也就是异常 throw throw new FileNotFoundException("文件不存在"); &#125; &#125;&#125; 当只有在try或者catch中调用退出JVM的相关方法,此时finally才不会执行,否则finally永远会执行。 2.5 异常注意事项 多个异常使用捕获又该如何处理呢？ 多个异常分别处理。 多个异常一次捕获，多次处理。 多个异常一次捕获一次处理。 一般我们是使用一次捕获多次处理方式，格式如下： 123456789try&#123; 编写可能会出现异常的代码&#125;catch(异常类型A e)&#123; 当try中出现A类型异常,就用该catch来捕获. 处理异常的代码 //记录日志/打印异常信息/继续抛出异常&#125;catch(异常类型B e)&#123; 当try中出现B类型异常,就用该catch来捕获. 处理异常的代码 //记录日志/打印异常信息/继续抛出异常&#125; 注意:这种异常处理方式，要求多个catch中的异常不能相同，并且若catch中的多个异常之间有子父类异常的关系，那么子类异常要求在上面的catch处理，父类异常在下面的catch处理。 运行时异常被抛出可以不处理。即不捕获也不声明抛出。 如果finally有return语句,永远返回finally中的结果,避免该情况. 如果父类抛出了多个异常,子类重写父类方法时,抛出和父类相同的异常或者是父类异常的子类或者不抛出异常。 父类方法没有抛出异常，子类重写父类该方法时也不可抛出异常。此时子类产生该异常，只能捕获处理，不能声明抛出 第三章 自定义异常3.1 概述为什么需要自定义异常类: 我们说了Java中不同的异常类,分别表示着某一种具体的异常情况,那么在开发中总是有些异常情况是SUN没有定义好的,此时我们根据自己业务的异常情况来定义异常类。例如年龄负数问题,考试成绩负数问题等等。 在上述代码中，发现这些异常都是JDK内部定义好的，但是实际开发中也会出现很多异常,这些异常很可能在JDK中没有定义过,例如年龄负数问题,考试成绩负数问题.那么能不能自己定义异常呢？ 什么是自定义异常类: 在开发中根据自己业务的异常情况来定义异常类. 自定义一个业务逻辑异常: RegisterException。一个注册异常类。 异常类如何定义: 自定义一个编译期异常: 自定义类 并继承于java.lang.Exception。 自定义一个运行时期的异常类:自定义类 并继承于java.lang.RuntimeException。 3.2 自定义异常的练习要求：我们模拟注册操作，如果用户名已存在，则抛出异常并提示：亲，该用户名已经被注册。 首先定义一个登陆异常类RegisterException： 12345678910111213141516// 业务逻辑异常public class RegisterException extends Exception &#123; /** * 空参构造 */ public RegisterException() &#123; &#125; /** * * @param message 表示异常提示 */ public RegisterException(String message) &#123; super(message); &#125;&#125; 模拟登陆操作，使用数组模拟数据库中存储的数据，并提供当前注册账号是否存在方法用于判断。 123456789101112131415161718192021222324252627public class Demo &#123; // 模拟数据库中已存在账号 private static String[] names = &#123;"bill","hill","jill"&#125;; public static void main(String[] args) &#123; //调用方法 try&#123; // 可能出现异常的代码 checkUsername("nill"); System.out.println("注册成功");//如果没有异常就是注册成功 &#125;catch(RegisterException e)&#123; //处理异常 e.printStackTrace(); &#125; &#125; //判断当前注册账号是否存在 //因为是编译期异常，又想调用者去处理 所以声明该异常 public static boolean checkUsername(String uname) throws LoginException&#123; for (String name : names) &#123; if(name.equals(uname))&#123;//如果名字在这里面 就抛出登陆异常 throw new RegisterException("亲"+name+"已经被注册了！"); &#125; &#125; return true; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java异常</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java多线程总结]]></title>
    <url>%2F2019%2F04%2F07%2FJava_09_%20thread%2F</url>
    <content type="text"><![CDATA[多线程我们在之前，学习的程序在没有跳转语句的前提下，都是由上至下依次执行，那现在想要设计一个程序，边打游戏边听歌，怎么设计？ 要解决上述问题,咱们得使用多进程或者多线程来解决. 1.1 并发与并行 并发：指两个或多个事件在同一个时间段内发生。 并行：指两个或多个事件在同一时刻发生（同时发生）。 在操作系统中，安装了多个程序，并发指的是在一段时间内宏观上有多个程序同时运行，这在单 CPU 系统中，每一时刻只能有一道程序执行，即微观上这些程序是分时的交替运行，只不过是给人的感觉是同时运行，那是因为分时交替运行的时间是非常短的。 而在多个 CPU 系统中，则这些可以并发执行的程序便可以分配到多个处理器上（CPU），实现多任务并行执行，即利用每个处理器来处理一个可以并发执行的程序，这样多个程序便可以同时执行。目前电脑市场上说的多核 CPU，便是多核处理器，核 越多，并行处理的程序越多，能大大的提高电脑运行的效率。 注意：单核处理器的计算机肯定是不能并行的处理多个任务的，只能是多个任务在单个CPU上并发运行。同理,线程也是一样的，从宏观角度上理解线程是并行运行的，但是从微观角度上分析却是串行运行的，即一个线程一个线程的去运行，当系统只有一个CPU时，线程会以某种顺序执行多个线程，我们把这种情况称之为线程调度。 1.2 线程与进程 进程：是指一个内存中运行的应用程序，每个进程都有一个独立的内存空间，一个应用程序可以同时运行多个进程；进程也是程序的一次执行过程，是系统运行程序的基本单位；系统运行一个程序即是一个进程从创建、运行到消亡的过程。 线程：线程是进程中的一个执行单元，负责当前进程中程序的执行，一个进程中至少有一个线程。一个进程中是可以有多个线程的，这个应用程序也可以称之为多线程程序。 简而言之：一个程序运行后至少有一个进程，一个进程中可以包含多个线程 我们可以再电脑底部任务栏，右键—–&gt;打开任务管理器,可以查看当前任务的进程： 进程 线程 线程调度: 分时调度 所有线程轮流使用 CPU 的使用权，平均分配每个线程占用 CPU 的时间。 抢占式调度 优先让优先级高的线程使用 CPU，如果线程的优先级相同，那么会随机选择一个(线程随机性)，Java使用的为抢占式调度。 设置线程的优先级 抢占式调度详解 大部分操作系统都支持多进程并发运行，现在的操作系统几乎都支持同时运行多个程序。比如：现在我们上课一边使用编辑器，一边使用录屏软件，同时还开着画图板，dos窗口等软件。此时，这些程序是在同时运行，”感觉这些软件好像在同一时刻运行着“。 实际上，CPU(中央处理器)使用抢占式调度模式在多个线程间进行着高速的切换。对于CPU的一个核而言，某个时刻，只能执行一个线程，而 CPU的在多个线程间切换速度相对我们的感觉要快，看上去就是在同一时刻运行。其实，多线程程序并不能提高程序的运行速度，但能够提高程序运行效率，让CPU的使用率更高。 1.3 创建线程类Java使用java.lang.Thread类代表线程，所有的线程对象都必须是Thread类或其子类的实例。每个线程的作用是完成一定的任务，实际上就是执行一段程序流即一段顺序执行的代码。Java使用线程执行体来代表这段程序流。Java中通过继承Thread类来创建并启动多线程的步骤如下： 定义Thread类的子类，并重写该类的run()方法，该run()方法的方法体就代表了线程需要完成的任务,因此把run()方法称为线程执行体。 创建Thread子类的实例，即创建了线程对象 调用线程对象的start()方法来启动该线程 代码如下： 测试类： 123456789101112public class Demo01 &#123; public static void main(String[] args) &#123; //创建自定义线程对象 MyThread mt = new MyThread("新的线程！"); //开启新线程 mt.start(); //在主方法中执行for循环 for (int i = 0; i &lt; 10; i++) &#123; System.out.println("main线程！"+i); &#125; &#125;&#125; 自定义线程类： 12345678910111213141516public class MyThread extends Thread &#123; //定义指定线程名称的构造方法 public MyThread(String name) &#123; //调用父类的String参数的构造方法，指定线程的名称 super(name); &#125; /** * 重写run方法，完成该线程执行的逻辑 */ @Override public void run() &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.println(getName()+"：正在执行！"+i); &#125; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java多线程、同步]]></title>
    <url>%2F2019%2F04%2F06%2FJava_10_%20thread2%2F</url>
    <content type="text"><![CDATA[Java多线程、同步知识点 能够描述Java中多线程运行原理 能够使用继承类的方式创建多线程 能够使用实现接口的方式创建多线程 能够说出实现接口方式的好处 能够解释安全问题的出现的原因 能够使用同步代码块解决线程安全问题 能够使用同步方法解决线程安全问题 能够说出线程6个状态的名称 第一章 线程1.1 多线程原理先画个多线程执行时序图来体现一下多线程程序的执行流程。代码如下：自定义线程类： 12345678910111213141516171819public class MyThread extends Thread&#123;/** 利用继承中的特点* 将线程名称传递 进行设置*/public MyThread(String name)&#123; super(name);&#125;/** 重写run方法* 定义线程要执行的代码*/public void run()&#123; for (int i = 0; i &lt; 20; i++) &#123; //getName()方法 来自父亲 System.out.println(getName()+i); &#125; &#125;&#125; 测试类： 12345678910public class Demo &#123; public static void main(String[] args) &#123; System.out.println(&quot;这里是main线程&quot;); MyThread mt = new MyThread(&quot;小强&quot;); mt.start();//开启了一个新的线程 for (int i = 0; i &lt; 20; i++) &#123; System.out.println(&quot;旺财:&quot;+i); &#125; &#125;&#125; 流程图： 程序启动运行main时候，java虚拟机启动一个进程，主线程main在main()调用时候被创建。随着调用mt的对象的start方法，另外一个新的线程也启动了，这样，整个应用就在多线程下运行。通过这张图我们可以很清晰的看到多线程的执行流程，那么为什么可以完成并发执行呢？我们再来讲一讲原理。多线程执行时，到底在内存中是如何运行的呢？以上个程序为例，进行图解说明：多线程执行时，在栈内存中，其实每一个执行线程都有一片自己所属的栈内存空间。进行方法的压栈和弹栈。 当执行线程的任务结束了，线程自动在栈内存中释放了。但是当所有的执行线程都结束了，那么进程就结束了。 1.2 Thread类我们已经可以完成最基本的线程开启，那么在我们完成操作过程中用到了java.lang.Thread 类，API中该类中定义了有关线程的一些方法，具体如下：构造方法： public Thread() :分配一个新的线程对象。 public Thread(String name) :分配一个指定名字的新的线程对象。 public Thread(Runnable target) :分配一个带有指定目标新的线程对象。 public Thread(Runnable target,String name) :分配一个带有指定目标新的线程对象并指定名字。 常用方法： public String getName() :获取当前线程名称。 public void start() :导致此线程开始执行; Java虚拟机调用此线程的run方法。 public void run() :此线程要执行的任务在此处定义代码。 public static void sleep(long millis) :使当前正在执行的线程以指定的毫秒数暂停（暂时停止执行）。 public static Thread currentThread() :返回对当前正在执行的线程对象的引用。 翻阅API后得知创建线程的方式总共有两种，一种是继承Thread类方式，一种是实现Runnable接口方式。 1.3 创建线程方式二采用java.lang.Runnable 也是非常常见的一种，我们只需要重写run方法即可。步骤如下： 定义Runnable接口的实现类，并重写该接口的run()方法，该run()方法的方法体同样是该线程的线程执行体。 创建Runnable实现类的实例，并以此实例作为Thread的target来创建Thread对象，该Thread对象才是真正 的线程对象。 调用线程对象的start()方法来启动线程。 代码如下： 12345678public class MyRunnable implements Runnable&#123; @Override public void run() &#123; for (int i = 0; i &lt; 20; i++) &#123; System.out.println(Thread.currentThread().getName()+&quot; &quot;+i); &#125; &#125;&#125; 123456789101112public class Demo &#123; public static void main(String[] args) &#123; //创建自定义类对象 线程任务对象 MyRunnable mr = new MyRunnable(); //创建线程对象 Thread t = new Thread(mr, &quot;小强&quot;); t.start(); for (int i = 0; i &lt; 20; i++) &#123; System.out.println(&quot;旺财 &quot; + i); &#125; &#125;&#125; 通过实现Runnable接口，使得该类有了多线程类的特征。run()方法是多线程程序的一个执行目标。所有的多线程代码都在run方法里面。Thread类实际上也是实现了Runnable接口的类。在启动的多线程的时候，需要先通过Thread类的构造方法Thread(Runnable target) 构造出对象，然后调用Thread对象的start()方法来运行多线程代码。实际上所有的多线程代码都是通过运行Thread的start()方法来运行的。因此，不管是继承Thread类还是实现Runnable接口来实现多线程，最终还是通过Thread的对象的API来控制线程的，熟悉Thread类的API是进行多线程编程的基础。tips:Runnable对象仅仅作为Thread对象的target，Runnable实现类里包含的run()方法仅作为线程执行体。而实际的线程对象依然是Thread实例，只是该Thread线程负责执行其target的run()方法。 1.4 Thread和Runnable的区别如果一个类继承Thread，则不适合资源共享。但是如果实现了Runable接口的话，则很容易的实现资源共享。总结：实现Runnable接口比继承Thread类所具有的优势： 适合多个相同的程序代码的线程去共享同一个资源。 可以避免java中的单继承的局限性。 增加程序的健壮性，实现解耦操作，代码可以被多个线程共享，代码和线程独立。 线程池只能放入实现Runable或Callable类线程，不能直接放入继承Thread的类。 扩充：在java中，每次程序运行至少启动2个线程。一个是main线程，一个是垃圾收集线程。因为每当使用java命令执行一个类的时候，实际上都会启动一个JVM，每一个JVM其实在就是在操作系统中启动了一个进程。 1.5 匿名内部类方式实现线程的创建使用线程的内匿名内部类方式，可以方便的实现每个线程执行不同的线程任务操作。使用匿名内部类的方式实现Runnable接口，重新Runnable接口中的run方法： 12345678910111213141516171819202122public class NoNameInnerClassThread &#123; public static void main(String[] args) &#123; // new Runnable()&#123; // public void run()&#123; // for (int i = 0; i &lt; 20; i++) &#123; // System.out.println(&quot;张宇:&quot;+i); // &#125; // &#125; // &#125;; //‐‐‐这个整体 相当于new MyRunnable() Runnable r = new Runnable()&#123; public void run()&#123; for (int i = 0; i &lt; 20; i++) &#123; System.out.println(&quot;张宇:&quot;+i); &#125; &#125; &#125;; new Thread(r).start(); for (int i = 0; i &lt; 20; i++) &#123; System.out.println(&quot;费玉清:&quot;+i); &#125; &#125; &#125; 第二章 线程安全2.1 线程安全如果有多个线程在同时运行，而这些线程可能会同时运行这段代码。程序每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。我们通过一个案例，演示线程的安全问题：电影院要卖票，我们模拟电影院的卖票过程。假设要播放的电影是 “葫芦娃大战奥特曼”，本次电影的座位共100个(本场电影只能卖100张票)。我们来模拟电影院的售票窗口，实现多个窗口同时卖 “葫芦娃大战奥特曼”这场电影票(多个窗口一起卖这100张票)需要窗口，采用线程对象来模拟；需要票，Runnable接口子类来模拟模拟票： 1234567891011121314151617181920212223242526public class Ticket implements Runnable &#123; private int ticket = 100; /* * 执行卖票操作 */ @Override public void run() &#123; //每个窗口卖票的操作 //窗口 永远开启 while (true) &#123; if (ticket &gt; 0) &#123;//有票 可以卖 //出票操作 //使用sleep模拟一下出票时间 try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; // TODO Auto‐generated catch block e.printStackTrace(); &#125; //获取当前线程对象的名字 String name = Thread.currentThread().getName(); System.out.println(name + &quot;正在卖:&quot; + ticket‐‐); &#125; &#125; &#125; &#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scrum团队角色]]></title>
    <url>%2F2019%2F04%2F04%2FProjectManagement_01_scrum%2F</url>
    <content type="text"><![CDATA[SCRUMScrum 是一个用于开发和维护复杂产品的框架 ，是一个增量的、迭代的开发过程。在这个框架中，整个开发过程由若干个短的迭代周期组成，一个短的迭代周期称为一个Sprint，每个Sprint的建议长度是2到4周(互联网产品研发可以使用1周的Sprint)。在Scrum中，使用产品Backlog来管理产品的需求，产品backlog是一个按照商业价值排序的需求列表，列表条目的体现形式通常为用户故事。Scrum团队总是先开发对客户具有较高价值的需求。在Sprint中，Scrum团队从产品Backlog中挑选最高优先级的需求进行开发。挑选的需求在Sprint计划会议上经过讨论、分析和估算得到相应的任务列表，我们称它为Sprint backlog。在每个迭代结束时，Scrum团队将递交潜在可交付的产品增量。 Scrum起源于软件开发项目，但它适用于任何复杂的或是创新性的项目。 Scrum流程如下: SCRUM框架包括3个角色、3个工件、5个事件、5个价值 3个角色 产品负责人（Product Owner） Scrum Master 开发团队 3个工件 产品Backlog（Product Backlog） SprintBacklog 产品增量（Increment） 5个事件 Sprint（Sprint本身是一个事件，包括了如下4个事件） Sprint计划会议（Sprint Planning Meeting） 每日站会（Daily Scrum Meeting） Sprint评审会议（Sprint Review Meeting） Sprint回顾会议（Sprint Retrospective Meeting） 5个价值 承诺 – 愿意对目标做出承诺 专注– 把你的心思和能力都用到你承诺的工作上去 开放– Scrum 把项目中的一切开放给每个人看 尊重– 每个人都有他独特的背景和经验 勇气– 有勇气做出承诺，履行承诺，接受别人的尊重 Scrum角色Scrum团队中包括三个角色，他们分别是产品负责人、开发团队和 Scrum Master。 Scrum 团队是自组织、跨职能的完整团队。自组织团队决定如何最好地完成他们的工作,而不是由团队外的其他人来指挥他 们。 跨职能的团队拥有完成工作所需要的全部技能,不需要依赖团队外部的人。Scrum 团队模式的目的是最大限度地优化适应性、创造性和生产力。 Scrum 团队通过迭代和增量交付产品功能的方法最大化反馈的机会。增量交付潜在可交付的产品增量保证了 每个迭代都有潜在可发布的版本。 Scrum角色之：产品负责人产品负责人负责最大化产品以及开发团队工作的价值。实现这一点的方式会随着组 织、Scrum 团队以及单个团队成员的不同而不同。 产品负责人是管理产品待办事项列表的唯一责任人。产品待办事项列表的管理包括: 清晰地表达产品代办事项列表条目 对产品代办事项列表中的条目进行排序,最好地实现目标和使命 确保开发团队所执行工作的价值 确保产品代办事项列表对所有人可见、透明、清晰,并且显示 Scrum 团队的下一步工作 确保开发团队对产品代办事项列表中的条目达到一定程度的理解 产品负责人可以亲自完成上述工作,也可以让开发团队来完成。然而,产品负责人是 负责任者。 产品负责人是一个人,而不是一个委员会。产品负责人可能会在产品代办事项列表中 体现一个委员会的需求,但要想改变某条目的优先级必须先说服产品负责人。 为保证产品负责人的工作取得成功,组织中的所有人员都必须尊重他的决定。产品负 责人所作的决定在产品待办事项列表的内容和排序中要清晰可见。任何人都不得要求开发 团队按照另一套需求开展工作,开发团队也不允许听从任何其他人的指令。 Scrum角色之：开发团队开发团队包含了专业人员,负责在每个 Sprint 的结尾交付潜在可发布的“完成”产 品增量。只有开发团队的成员才能创造增量。 开发团队由组织构建并授权,来组织和管理他们的工作。所产生的协同工作能最大化 开发团队的整体效率和效力。开发团队有以下几个特点: 他们是自组织的,没有人(即使是 Scrum Master 都不可以)告诉开发团队如何把产品 代办事项列表变成潜在可发布的功能。 开发团队是跨职能的,团队作为一个整体拥有创造产品增量所需要的全部技能。 Scrum 不认可开发团队成员的头衔,无论承担哪种工作他们都是开发者。此规则无一例外。 开发团队中的每个成员可以有特长和专注领域,但是责任归属于整个开发团队 开发团队不包含如测试或业务分析等负责特定领域的子团队。 开发团队的规模开发团队最佳规模是小到足以保持敏捷性,大到足以完成重要工作。少于 3 人的开发 团队没有足够的交互,因而所获得的生产力增长也不会很大。小团队在 Sprint 中可能会 受到技能限制,从而导致无法交付可发布的产品增量。大于 9 人的团队需要过多的协调沟 通工作。大型团队会产生太多复杂性,不便于经验过程管理。产品负责人和 Scrum Master 的角色不包含在此数字中,除非他们也参与执行 Sprint 代表事项列表中的工作。 Scrum角色之：Scrum MasterScrum Master 负责确保 Scrum 被理解并实施。为了达到这个目的,Scrum Master要确保 Scrum 团队遵循 Scrum 的理论、实践和规则。Scrum Master是Scrum团队中的服务式领导。 Scrum Master 帮助 Scrum 团队外的人员了解他们如何与 Scrum 团队交互是有益的。 Scrum Master 通过改变这些交互来最大化 Scrum 团队所创造的价值。 Scrum Master 服务于产品负责人Scrum Master 以各种方式服务于产品负责人,包括: 找到有效管理产品代办事项列表的技巧 清晰地和开发团队沟通愿景、目标和产品代表事项列表条目 教导开发团队创建清晰简明的产品代表事项列表条目 在经验主义环境中理解长期的产品规划 理解并实践敏捷 按需推动Scrum活动 Scrum Master 服务于开发团队Scrum Master 以各种方式服务于开发团队,包括: 指导开发团队自组织和跨职能 教导并领导开发团队创造高价值的产品 移除开发团队进展过程中的障碍 按需推动Scrum活动 在 Scrum 还未完全被采纳和理解的组织环境下指导开发团队 Scrum Master 服务于组织Scrum Master 以各种方式服务于组织,包括: 领导并指导组织采用 Scrum 在组织范围内计划 Scrum 的实施 帮助员工及干系人理解并实施 Scrum 和经验性产品开发 发起能提升Scrum 团队生产力的变革 与其他 Scrum Master 一起工作,帮助组织更有效的应用Scrum]]></content>
      <categories>
        <category>Project Management</category>
      </categories>
      <tags>
        <tag>Project Management</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java位操作-移位总结]]></title>
    <url>%2F2019%2F04%2F03%2FJava_07_%20shift%2F</url>
    <content type="text"><![CDATA[1.除2倒取余法根据二进制的计算方法，输入一个十进制数n，每次用n除以2，把余数记下来，再用商去除以2…依次循环，直到商为0结束。把余数倒着输出，就得到了转换后的二进制数。 可以用int来存储最后的二进制数，每次求余后把余数存储在int型数的低位，依次递增。 123456789101112 1 public void Decimal2binary(int n)&#123; 2 int t = 0; //用来记录位数 3 int bin = 0; //用来记录最后的二进制数 4 int r = 0; //用来存储余数 5 while(n != 0)&#123; 6 r = n % 2; 7 n = n / 2; 8 bin += r * Math().pow(10,t); 9 t++; 10 &#125;11 System.out.println(bin);12 &#125; 但是int只能表示2^31-1 的正数，存储的二进制数位数有限；所以可以使用字符串的拼接（+）来实现，代码如下: 123456781 public void Decimal2binary(int n)&#123;2 String str = &quot;&quot;;3 while(n!=0)&#123;4 str = n%2+str;5 n = n/2;6 &#125;7 System.out.println(str);8 &#125; 2. 移位实现利用移位操作对一个十进制数进行移位操作，将最高位的数移至最低位（移31位），使用按位 &amp; 操作，可以使用和1相与（&amp;），然后把这个数按十进制输出；再移次高位，做相同的操作，直到最后一位 ，代码如下。 12341 public void Decimal2binary(int n)&#123;2 for(int i = 31;i &gt;= 0; i--)3 System.out.print(n &gt;&gt;&gt; i &amp; 1);4 &#125; 说明：由于计算机中存储的都是数的补码，正数的原码、反码、补码都是相同的；而负数的原码、反码、补码是不一样的，补码=原码取反+1（符号位不变）。所以，负数是按照它的补码输出的。 >&gt;&gt;为逻辑移位符，向右移n位，高位补0>&gt; 算数移位符，也是向右移n位，不同的是：正数高位补0，负数高位补1 3.调用API函数通过Integer.toBinaryString()方法实现。 123456public void function1(int n)&#123;2 String result = Integer.toBinaryString(n);3 //int r = Integer.parseInt(result);4 //System.out.println(r);5 System.out.println(result);6 &#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习中训练和推断的区别]]></title>
    <url>%2F2019%2F03%2F31%2Ftensor_08_inference%2F</url>
    <content type="text"><![CDATA[深度学习中涉及到训练（Training）和推断（Inference），训练也就是搜索和求解模型最优参数的阶段。当模型参数已经求解出来，使用和部署模型，则称为推断阶段。二者的特点不同。 深度学习训练我们可以把深度学习的训练看成学习过程。人工神经网络是分层的、是在层与层之间互相连接的、网络中数据的传播是有向的。训练神经网络的时候，训练数据被输入到网络的第一层。然后所有的神经元，都会根据任务执行的情况，根据其正确或者错误的程度如何，分配一个权重参数（权值）。 如图是一个深层神经网络，信息从下到上流动。我们给这个网络大量的输入数据，网络的低层就会提取出不同类别数据的特征信息，通过激活函数、损失函数以后而到了最高层，网络提取到整个数据特征。所以，神经网络从低到高刚好能够提取图片数据中从低到高（从局部到整体）的多层次信息，最终的输出由网络中所有的权值共同决定。对多尺度层级结构的提取才使得深度学习神经网络可以得到很好的效果。 训练需要分batch多次迭代，inference只需要分batch执行一次计算流图。训练是计算密集型的，以GPU资源为主，CPU主要用于通信，参数更新等低消耗的任务。单次训练任务计算量大，需要用分布式系统才能较快得到结果。训练过程主要关心分布式集群的资源利用率。 深度学习推断推断过程关注的指标为： 访问延迟 吞吐量 模型版本管理 DevOps 推断过程常用的工具：TensorFlow Serving 是一个用于机器学习模型 serving 的高性能开源库。它可以将训练好的机器学习模型部署到线上，使用 gRPC和Restful 作为接口接受外部调用。它支持模型热更新与自动模型版本管理。这意味着一旦部署 TensorFlow Serving 后，你再也不需要为线上服务操心，只需要关心你的线下模型训练。 推断的网络权值已经固定下来，无后向传播过程，模型固定，可以对计算图进行优化。还可以输入输出大小固定，做memory优化（fine-tuning只是在已有的训练好的模型上做小的改动和调优，本质上仍然是训练过程，TensorRT没有fine-tuning） 推断的batch size要小很多，如果batch size很大，吞吐可以很大。比如每秒可以处理1024个batch，500毫秒处理完，吞吐可以达到2048，可以很好地利用GPU；但是推断关心延迟latency，不能有500毫秒处理延迟。所以batch可以是8或者16，吞吐降低，没有办法很好地利用GPU。 训练的时候因为要保证前后向传播，每次梯度的更新很微小，需要相对较高的精度，一般来说需要float型，如FP32，32位的浮点型来处理数据。但是推断对精度的要求没有那么高，可以使用低精度的技术，很多研究表明可以用如半长（16）的float型，即FP16，或者8位的整型（INT8）来做推断，研究结果表明没有特别大的精度损失，尤其对CNN。对Binary（二进制）的使用也处在研究中，即权值只有0和1。低精度计算的好处是一方面可以减少计算量，原来计算32位的单元处理FP16的时候，理论上可以达到两倍的速度，处理INT8的时候理论上可以达到四倍的速度。另一方面是模型需要的空间减少，不管是权值的存储还是中间值的存储，应用更低的精度，模型大小会相应减小。用于inference的模型要进行简化、压缩、针对运行性能优化：查找神经网络中经过训练后并没有用到、尚未激活的清洗掉。把神经网络中的多个层融合为一个单独的计算步骤。（通过神经网络剪枝、训练量化和Huffman编码等压缩模型），但仍能达到几乎一样的预测、识别准确率]]></content>
      <categories>
        <category>Deep learning</category>
      </categories>
      <tags>
        <tag>Deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Glances系统监控工具]]></title>
    <url>%2F2019%2F03%2F28%2Ftensor_07_glances%2F</url>
    <content type="text"><![CDATA[Glances 实时系统监控工具Glances 是一款用于 Linux、BSD 的跨平台的、基于命令行的系统监视工具，由 Python 语言编写，使用 Python 的 psutil 库来抓取系统数据。可以监控 CPU、负载均衡、内存、网络设备、磁盘 I/O、进程和文件系统使用等。本文介绍 glances 的使用方法和技巧，帮助 Linux 使用者了解掌握服务器性能。 一、输出信息概览glances 可以为 Unix 和 Linux 运维人员提供监视和分析性能数据的功能，其中包括： CPU 使用率 内存使用情况 内核统计信息和运行队列信息 磁盘 I/O 速度、传输和读/写比率 文件系统中的可用空间 磁盘适配器 网络 I/O 速度、传输和读/写比率 页面空间和页面速度 消耗资源最多的进程 计算机信息和系统资源 glances 工具可以实时显示重要的系统信息，并动态地更新。glances 在屏幕上对数据进行显示，并且每隔两秒钟对其进行更新。可以将这个时间间隔更改为更长或更短的数值。glances 工具还可以将相同的数据捕获到一个文件，便于以后对报告进行分析和绘制图形。输出文件可以是电子表格 (.csv) 或者 html 格式。 二、软件安装安装所需要的依赖 python 2.7,&gt;=3.4 psutil&gt;=5.3.0 (better with latest version) Glances 一般已集成到大多数 Linux 发行版的官方软件源中。可以直接使用系统的包管理器（如 apt-get、yum）安装： 1`sudo apt-get install glances `也可以使用 Python 的包管理器（pip 命令）进行安装： 12apt-get install -y python-pip`pip install glances` Glances 有 4 种颜色标记，分别表示不同的紧急程度： 绿色：OK 蓝色：CAREFUL 紫色：WARNING 红色：CRITICAL 默认为 careful = 50、warning = 70、critical = 90 。 三、命令选项（热键）glances 包括如下命令选项： 123456789101112131415-b：显示网络连接速度 Byte/ 秒-B @IP|host ：绑定服务器端 IP 地址或者主机名称-c @IP|host：连接 glances 服务器端-C file：设置配置文件默认是 /etc/glances/glances.conf -d：关闭磁盘 I/O 模块-e：显示传感器温度-f file：设置输出文件（格式是 HTML 或者 CSV）-m：关闭挂载的磁盘模块-n：关闭网络模块-p PORT：设置运行端口默认是 61209 -P password：设置客户端 / 服务器密码-s：设置 glances 运行模式为服务器-t sec：设置屏幕刷新的时间间隔，单位为秒，默认值为 2 秒，数值许可范围：1~32767 -h : 显示帮助信息-v : 显示版本信息 默认情况下，监控信息的刷新时间为 1 秒钟。可以使用 -t 选项自定义间隔时间： 1glances -t 2 glances 可以使用交互式的方式运行该工具，可以使用如下快捷键： 123456789101112h ： 显示帮助信息q ： 离开程序退出c ：按照 CPU 实时负载对系统进程进行排序m ：按照内存使用状况对系统进程排序i：按照 I/O 使用状况对系统进程排序p： 按照进程名称排序d ： 显示磁盘读写状况 w ： 删除日志文件l ：显示日志s： 显示传感器信息f ： 显示系统信息1 ：轮流显示每个 CPU 内核的使用情况（次选项仅仅使用在多核 CPU 系统） 四、显示界面 显示界面基本上可以分为3块在图的上部是 CPU 、Load（负载）、Mem（内存使用）、 Swap（交换分区）的使用情况。在图的左下部是磁盘 I/O 的使用情况。在图的右下部是网络接口、Processes（进程）的使用情况。通常包括如下字段： 1234567891011VIRT: 虚拟内存大小 RES: 进程占用的物理内存值 %CPU：该进程占用的 CPU 使用率 %MEM：该进程占用的物理内存和总内存的百分比 PID: 进程 ID 号 USER: 进程所有者的用户名 TIME+: 该进程启动后占用的总的 CPU 时间 IO_R 和 IO_W: 进程的读写 I/O 速率 NAME: 进程名称 NI: 进程优先级 S: 进程状态，其中 S 表示休眠，R 表示正在运行，Z 表示僵死状态。 五、输出到文件安装依赖库 1pip install Jinja2 文件采用逗号分隔值（CSV）的格式 1glances --export-csv ./glances.csv]]></content>
      <categories>
        <category>Tensorflow</category>
      </categories>
      <tags>
        <tag>Deep learning</tag>
        <tag>科研</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java工程师BAT应聘要求]]></title>
    <url>%2F2019%2F03%2F28%2Fwork_01_prepare%2F</url>
    <content type="text"><![CDATA[阿里 扎实的计算机专业基础，包括算法和数据结构，操作系统，计算机网络，计算机体系结构，数据库等 具有扎实的Java编程基础，理解IO、多线程等基础框架 熟练使用Linux系统的常用命令及shell有一定了解 精通多线程编程，熟悉分布式,缓存,消息队列等机制；熟悉JVM，包括内存模型、类加载机制以及性能优化 精通spring mvc、orm框架（ibatis或hibernate）、模板引擎（velocity）、关系型数据库设计及SQL 具备良好的面向对象编程经验，深入理解OO、AOP思想，具有很强的分析设计能力，熟悉常用设计模式 有大型分布式、高并发、高负载、高可用性系统设计和稳定性经验 熟悉面向对象设计开发，熟悉各种常用设计模式，并有在具体的应用场景落地经验 熟悉Spring、iBatis，等开源框架及消息，存储等常用中间件。 有通读过开源框架源码 熟悉基于Oracle或者Mysql的设计和开发、Linux操作系统 熟悉SOA，有平台化实施经验者，有大数据量、高并发系统和大型网站构建经验 分布式系统应用架构设计与研发经验，精通Java EE、SOA、OSGI等相关技术 对各种开源的框架如Spring、Hibernate等有深入的了解，对框架本身有过开发或重构者可优先考虑 具有大型电子商务网站、O2O行业、C端产品系统架构设计经验 腾讯 精通Web后台开发语言至少一种（PHP、Java、.Net、C++）,有一定的架构能力和良好代码规范 熟悉linux/unix系统与开发环境 熟悉TCP/IP协议，socket编程 熟悉mysql以及SQL语言 有高性能大容量服务系统设计开发经验 精通面向对象设计，精通J2EE开发，java web开发 全面并且扎实的软件知识结构（操作系统、软件工程、设计模式、数据结构、数据库系统、网络安全）； 具备良好的分析解决问题能力，能独立承担任务和有系统进度把控能力 精通MySQL或Mongo DB，熟悉缓存技术memcached、redis 有大型分布式、高并发、高负载、高可用系统设计、开发和调优经验 B/S结构系统分析及设计经验，有构建可伸缩、可扩展、高可用系统经验 有良好的开发习惯，熟悉Maven, Jenkins, JUnit等工具 精通MVC/REST架构、模板引擎、中间件的原理与应用 熟悉MySQL数据库，了解MySQL索引优化、查询优化和存储优化 头条 熟悉常见设计模式，掌握java流行的开源框架SpringMVC/Spring Boot/Spring Cloud，熟练使用至少一种 ORM 框架 熟练掌握基本的数据结构和算法，有系统分析和设计的实践经验 熟悉Rest，HTTP，Socket、webservice、HTTP协议，具备并发、多线程的编程经验 对Mysql、Redis、MongoDB 等数据库有研究或者项目经验 具有大型互联网服务设计及开发经验 熟悉JVM，对JVM有一定理解，并能借助相关工具进行JVM性能调优 熟悉常见的开源分布式中间件、缓存、消息队列等，熟悉nginx，MySQL，Redis，mongodb 等常用的开源软件 熟悉 MySQL 数据库设计和优化，有 NoSQL 数据库使用经验 具有大数据存储或者高性能计算平台架构、设计及开发等方面经历 具有大型互联网服务设计及开发经验]]></content>
      <categories>
        <category>Work</category>
      </categories>
      <tags>
        <tag>Work prepare</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaScript笔记2]]></title>
    <url>%2F2019%2F03%2F28%2Ffront_03_JavaScript02%2F</url>
    <content type="text"><![CDATA[JavaScript笔记21. JavaScript： 1. ECMAScript： 2. BOM： 3. DOM： 1. 事件 DOM简单学习：为了满足案例要求* 功能：控制html文档的内容 * 获取页面标签(元素)对象：Element * document.getElementById(&quot;id值&quot;):通过元素的id获取元素对象 * 操作Element对象： 1. 修改属性值： 1. 明确获取的对象是哪一个？ 2. 查看API文档，找其中有哪些属性可以设置 2. 修改标签体内容： * 属性：innerHTML 1. 获取元素对象 2. 使用innerHTML属性修改标签体内容 事件简单学习* 功能： 某些组件被执行了某些操作后，触发某些代码的执行。 * 造句： xxx被xxx,我就xxx * 我方水晶被摧毁后，我就责备对友。 * 敌方水晶被摧毁后，我就夸奖自己。 * 如何绑定事件 1. 直接在html标签上，指定事件的属性(操作)，属性值就是js代码 1. 事件：onclick--- 单击事件 2. 通过js获取元素对象，指定事件属性，设置一个函数 * 代码： &lt;body&gt; &lt;img id=&quot;light&quot; src=&quot;img/off.gif&quot; onclick=&quot;fun();&quot;&gt; &lt;img id=&quot;light2&quot; src=&quot;img/off.gif&quot;&gt; &lt;script&gt; function fun(){ alert(&apos;我被点了&apos;); alert(&apos;我又被点了&apos;); } function fun2(){ alert(&apos;咋老点我？&apos;); } //1.获取light2对象 var light2 = document.getElementById(&quot;light2&quot;); //2.绑定事件 light2.onclick = fun2; ​​ ​ ​ * 案例1：电灯开关 &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;电灯开关&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;img id=&quot;light&quot; src=&quot;img/off.gif&quot;&gt; &lt;script&gt; /* 分析： 1.获取图片对象 2.绑定单击事件 3.每次点击切换图片 * 规则： * 如果灯是开的 on,切换图片为 off * 如果灯是关的 off,切换图片为 on * 使用标记flag来完成 */ //1.获取图片对象 var light = document.getElementById(&quot;light&quot;); var flag = false;//代表灯是灭的。 off图片 //2.绑定单击事件 light.onclick = function(){ if(flag){//判断如果灯是开的，则灭掉 light.src = &quot;img/off.gif&quot;; flag = false; }else{ //如果灯是灭的，则打开 light.src = &quot;img/on.gif&quot;; flag = true; } ​​ }​ BOM:1. 概念：Browser Object Model 浏览器对象模型 * 将浏览器的各个组成部分封装成对象。 2. 组成： * Window：窗口对象 * Navigator：浏览器对象 * Screen：显示器屏幕对象 * History：历史记录对象 * Location：地址栏对象 3. Window：窗口对象 1. 创建 2. 方法 1. 与弹出框有关的方法： alert() 显示带有一段消息和一个确认按钮的警告框。 confirm() 显示带有一段消息以及确认按钮和取消按钮的对话框。 * 如果用户点击确定按钮，则方法返回true * 如果用户点击取消按钮，则方法返回false prompt() 显示可提示用户输入的对话框。 * 返回值：获取用户输入的值 2. 与打开关闭有关的方法： close() 关闭浏览器窗口。 * 谁调用我 ，我关谁 open() 打开一个新的浏览器窗口 * 返回新的Window对象 3. 与定时器有关的方式 setTimeout() 在指定的毫秒数后调用函数或计算表达式。 * 参数： 1. js代码或者方法对象 2. 毫秒值 * 返回值：唯一标识，用于取消定时器 clearTimeout() 取消由 setTimeout() 方法设置的 timeout。 setInterval() 按照指定的周期（以毫秒计）来调用函数或计算表达式。 clearInterval() 取消由 setInterval() 设置的 timeout。 3. 属性： 1. 获取其他BOM对象： history location Navigator Screen: 2. 获取DOM对象 document 4. 特点 * Window对象不需要创建可以直接使用 window使用。 window.方法名(); * window引用可以省略。 方法名(); 4. Location：地址栏对象 1. 创建(获取)： 1. window.location 2. location 2. 方法： * reload() 重新加载当前文档。刷新 3. 属性 * href 设置或返回完整的 URL。 5. History：历史记录对象 1. 创建(获取)： 1. window.history 2. history 2. 方法： * back() 加载 history 列表中的前一个 URL。 * forward() 加载 history 列表中的下一个 URL。 * go(参数) 加载 history 列表中的某个具体页面。 * 参数： * 正数：前进几个历史记录 * 负数：后退几个历史记录 3. 属性： * length 返回当前窗口历史列表中的 URL 数量。 DOM： * 概念： Document Object Model 文档对象模型 * 将标记语言文档的各个组成部分，封装为对象。可以使用这些对象，对标记语言文档进行CRUD的动态操作 * W3C DOM 标准被分为 3 个不同的部分： * 核心 DOM - 针对任何结构化文档的标准模型 * Document：文档对象 * Element：元素对象 * Attribute：属性对象 * Text：文本对象 * Comment:注释对象 * Node：节点对象，其他5个的父对象 * XML DOM - 针对 XML 文档的标准模型 * HTML DOM - 针对 HTML 文档的标准模型 * 核心DOM模型： * Document：文档对象 1. 创建(获取)：在html dom模型中可以使用window对象来获取 1. window.document 2. document 2. 方法： 1. 获取Element对象： 1. getElementById() ： 根据id属性值获取元素对象。id属性值一般唯一 2. getElementsByTagName()：根据元素名称获取元素对象们。返回值是一个数组 3. getElementsByClassName():根据Class属性值获取元素对象们。返回值是一个数组 4. getElementsByName(): 根据name属性值获取元素对象们。返回值是一个数组 2. 创建其他DOM对象： createAttribute(name) createComment() createElement() createTextNode() 3. 属性 * Element：元素对象 1. 获取/创建：通过document来获取和创建 2. 方法： 1. removeAttribute()：删除属性 2. setAttribute()：设置属性 * Node：节点对象，其他5个的父对象 * 特点：所有dom对象都可以被认为是一个节点 * 方法： * CRUD dom树： * appendChild()：向节点的子节点列表的结尾添加新的子节点。 * removeChild() ：删除（并返回）当前节点的指定子节点。 * replaceChild()：用新节点替换一个子节点。 * 属性： * parentNode 返回节点的父节点。 * HTML DOM 1. 标签体的设置和获取：innerHTML 2. 使用html元素对象的属性 3. 控制元素样式 1. 使用元素的style属性来设置 如： //修改样式方式1 div1.style.border = &quot;1px solid red&quot;; div1.style.width = &quot;200px&quot;; //font-size--&gt; fontSize div1.style.fontSize = &quot;20px&quot;; 2. 提前定义好类选择器的样式，通过元素的className属性来设置其class属性值。 事件监听机制：* 概念：某些组件被执行了某些操作后，触发某些代码的执行。 * 事件：某些操作。如： 单击，双击，键盘按下了，鼠标移动了 * 事件源：组件。如： 按钮 文本输入框... * 监听器：代码。 * 注册监听：将事件，事件源，监听器结合在一起。 当事件源上发生了某个事件，则触发执行某个监听器代码。 * 常见的事件： 1. 点击事件： 1. onclick：单击事件 2. ondblclick：双击事件 2. 焦点事件 1. onblur：失去焦点 2. onfocus:元素获得焦点。 3. 加载事件： 1. onload：一张页面或一幅图像完成加载。 4. 鼠标事件： 1. onmousedown 鼠标按钮被按下。 2. onmouseup 鼠标按键被松开。 3. onmousemove 鼠标被移动。 4. onmouseover 鼠标移到某元素之上。 5. onmouseout 鼠标从某元素移开。 ​​ 5. 键盘事件：​ 1. onkeydown 某个键盘按键被按下。​ 2. onkeyup 某个键盘按键被松开。​ 3. onkeypress 某个键盘按键被按下并松开。​ 6. 选择和改变 1. onchange 域的内容被改变。 2. onselect 文本被选中。 7. 表单事件： 1. onsubmit 确认按钮被点击。 2. onreset 重置按钮被点击。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>JS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaScript笔记1]]></title>
    <url>%2F2019%2F03%2F28%2Ffront_03_JavaScript01%2F</url>
    <content type="text"><![CDATA[JavaScript笔记1. JavaScript基础 JavaScript：* 概念： 一门客户端脚本语言 * 运行在客户端浏览器中的。每一个浏览器都有JavaScript的解析引擎 * 脚本语言：不需要编译，直接就可以被浏览器解析执行了 * 功能： * 可以来增强用户和html页面的交互过程，可以来控制html元素，让页面有一些动态的效果，增强用户的体验。 * JavaScript发展史： 1. 1992年，Nombase公司，开发出第一门客户端脚本语言，专门用于表单的校验。命名为 ： C-- ，后来更名为：ScriptEase 2. 1995年，Netscape(网景)公司，开发了一门客户端脚本语言：LiveScript。后来，请来SUN公司的专家，修改LiveScript，命名为JavaScript 3. 1996年，微软抄袭JavaScript开发出JScript语言 4. 1997年，ECMA(欧洲计算机制造商协会)，制定出客户端脚本语言的标准：ECMAScript，就是统一了所有客户端脚本语言的编码方式。 * JavaScript = ECMAScript + JavaScript自己特有的东西(BOM+DOM) * ECMAScript：客户端脚本语言的标准 1. 基本语法： 1. 与html结合方式 1. 内部JS： * 定义&lt;script&gt;，标签体内容就是js代码 2. 外部JS： * 定义&lt;script&gt;，通过src属性引入外部的js文件 * 注意： 1. &lt;script&gt;可以定义在html页面的任何地方。但是定义的位置会影响执行顺序。 2. &lt;script&gt;可以定义多个。 2. 注释 1. 单行注释：//注释内容 2. 多行注释：/*注释内容*/ 3. 数据类型： 1. 原始数据类型(基本数据类型)： 1. number：数字。 整数/小数/NaN(not a number 一个不是数字的数字类型) 2. string：字符串。 字符串 &quot;abc&quot; &quot;a&quot; &apos;abc&apos; 3. boolean: true和false 4. null：一个对象为空的占位符 5. undefined：未定义。如果一个变量没有给初始化值，则会被默认赋值为undefined 2. 引用数据类型：对象 4. 变量 * 变量：一小块存储数据的内存空间 * Java语言是强类型语言，而JavaScript是弱类型语言。 * 强类型：在开辟变量存储空间时，定义了空间将来存储的数据的数据类型。只能存储固定类型的数据 * 弱类型：在开辟变量存储空间时，不定义空间将来的存储数据类型，可以存放任意类型的数据。 * 语法： * var 变量名 = 初始化值; * typeof运算符：获取变量的类型。 * 注：null运算后得到的是object 5. 运算符 1. 一元运算符：只有一个运算数的运算符 ++，-- ， +(正号) * ++ --: 自增(自减) * ++(--) 在前，先自增(自减)，再运算 * ++(--) 在后，先运算，再自增(自减) * +(-)：正负号 * 注意：在JS中，如果运算数不是运算符所要求的类型，那么js引擎会自动的将运算数进行类型转换 * 其他类型转number： * string转number：按照字面值转换。如果字面值不是数字，则转为NaN（不是数字的数字） * boolean转number：true转为1，false转为0 2. 算数运算符 + - * / % ... 3. 赋值运算符 = += -+.... 4. 比较运算符 &gt; &lt; &gt;= &lt;= == ===(全等于) * 比较方式 1. 类型相同：直接比较 * 字符串：按照字典顺序比较。按位逐一比较，直到得出大小为止。 2. 类型不同：先进行类型转换，再比较 * ===：全等于。在比较之前，先判断类型，如果类型不一样，则直接返回false 5. 逻辑运算符 &amp;&amp; || ! * 其他类型转boolean： 1. number：0或NaN为假，其他为真 2. string：除了空字符串(&quot;&quot;)，其他都是true 3. null&amp;undefined:都是false 4. 对象：所有对象都为true 6. 三元运算符 ? : 表达式 var a = 3; var b = 4; var c = a &gt; b ? 1:0; * 语法： * 表达式? 值1:值2; * 判断表达式的值，如果是true则取值1，如果是false则取值2； 6. 流程控制语句： 1. if...else... 2. switch: * 在java中，switch语句可以接受的数据类型： byte int shor char,枚举(1.5) ,String(1.7) * switch(变量): case 值: * 在JS中,switch语句可以接受任意的原始数据类型 3. while 4. do...while 5. for 7. JS特殊语法： 1. 语句以;结尾，如果一行只有一条语句则 ;可以省略 (不建议) 2. 变量的定义使用var关键字，也可以不使用 * 用： 定义的变量是局部变量 * 不用：定义的变量是全局变量(不建议) 8. 练习：99乘法表 &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;99乘法表&lt;/title&gt; &lt;style&gt; td{ border: 1px solid; } &lt;/style&gt; &lt;script&gt; document.write(&quot;&lt;table align=&apos;center&apos;&gt;&quot;); ​ //1.完成基本的for循环嵌套，展示乘法表 for (var i = 1; i &lt;= 9 ; i++) { document.write(““); for (var j = 1; j &lt;=i ; j++) { document.write(““); //输出 1 * 1 = 1 document.write(i + &quot; * &quot; + j + &quot; = &quot; + ( i*j) +&quot;&amp;nbsp;&amp;nbsp;&amp;nbsp;&quot;); document.write(&quot;&lt;/td&gt;&quot;); } /*//输出换行 document.write(&quot;&lt;br&gt;&quot;);*/ document.write(&quot;&lt;/tr&gt;&quot;); } //2.完成表格嵌套 document.write(&quot;&lt;/table&gt;&quot;); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;/body&gt; &lt;/html&gt; 2. 基本对象： 1. Function：函数(方法)对象 1. 创建： 1. var fun = new Function(形式参数列表,方法体); //忘掉吧 2. function 方法名称(形式参数列表){ 方法体 } 3. var 方法名 = function(形式参数列表){ 方法体 } 2. 方法： 3. 属性： length:代表形参的个数 4. 特点： 1. 方法定义是，形参的类型不用写,返回值类型也不写。 2. 方法是一个对象，如果定义名称相同的方法，会覆盖 3. 在JS中，方法的调用只与方法的名称有关，和参数列表无关 4. 在方法声明中有一个隐藏的内置对象（数组），arguments,封装所有的实际参数 5. 调用： 方法名称(实际参数列表); 2. Array:数组对象 1. 创建： 1. var arr = new Array(元素列表); 2. var arr = new Array(默认长度); 3. var arr = [元素列表]; 2. 方法 join(参数):将数组中的元素按照指定的分隔符拼接为字符串 push() 向数组的末尾添加一个或更多元素，并返回新的长度。 3. 属性 length:数组的长度 4. 特点： 1. JS中，数组元素的类型可变的。 2. JS中，数组长度可变的。 3. Boolean 4. Date：日期对象 1. 创建： var date = new Date(); 2. 方法： toLocaleString()：返回当前date对象对应的时间本地字符串格式 getTime():获取毫秒值。返回当前如期对象描述的时间到1970年1月1日零点的毫秒值差 5. Math：数学对象 1. 创建： * 特点：Math对象不用创建，直接使用。 Math.方法名(); 2. 方法： random():返回 0 ~ 1 之间的随机数。 含0不含1 ceil(x)：对数进行上舍入。 floor(x)：对数进行下舍入。 round(x)：把数四舍五入为最接近的整数。 3. 属性： PI 6. Number 7. String 8. RegExp：正则表达式对象 1. 正则表达式：定义字符串的组成规则。 1. 单个字符:[] 如： [a] [ab] [a-zA-Z0-9_] * 特殊符号代表特殊含义的单个字符: \d:单个数字字符 [0-9] \w:单个单词字符[a-zA-Z0-9_] 2. 量词符号： ?：表示出现0次或1次 *：表示出现0次或多次 +：出现1次或多次 {m,n}:表示 m&lt;= 数量 &lt;= n * m如果缺省： {,n}:最多n次 * n如果缺省：{m,} 最少m次 3. 开始结束符号 * ^:开始 * $:结束 2. 正则对象： 1. 创建 1. var reg = new RegExp(&quot;正则表达式&quot;); 2. var reg = /正则表达式/; 2. 方法 1. test(参数):验证指定的字符串是否符合正则定义的规范 9. Global 1. 特点：全局对象，这个Global中封装的方法不需要对象就可以直接调用。 方法名(); 2. 方法： encodeURI():url编码 decodeURI():url解码 encodeURIComponent():url编码,编码的字符更多 decodeURIComponent():url解码 parseInt():将字符串转为数字 * 逐一判断每一个字符是否是数字，直到不是数字为止，将前边数字部分转为number isNaN():判断一个值是否是NaN * NaN六亲不认，连自己都不认。NaN参与的==比较全部问false eval():讲 JavaScript 字符串，并把它作为脚本代码来执行。 3. URL编码 传智播客 = %E4%BC%A0%E6%99%BA%E6%92%AD%E5%AE%A2 * BOM * DOM ​]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>JS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tensorflow Profile分析神经网络性能]]></title>
    <url>%2F2019%2F03%2F26%2Ftensor_06_profile%2F</url>
    <content type="text"><![CDATA[profiler分析TensorFlow程序性能1.TensorFlow profiler 功能从r1.3版本开始， tensorflow 提供profiler模块，参见github上的官网文档 profiler打开tf执行的黑盒，以graph node（神经网络模型简称为graph，其中的节点称为node.）为细粒度，从多个维度、多个层面去统计神经网络运行的时间和内存消耗，为进一步优化神经网络模型的运行效率提供最直接的数据依据。功能如下： 分析 TensorFlow 模型架构。 参数量、tensor的shape、浮点运算数、运算设备等。 分析 multiple-steps 模型性能。 执行时间，内存消耗。 自动 分析及建议。 训练加速设备使用情况的检查 较耗时op的检查 op配置的检查 分布式runtime检查（非OSS） 2.profiler 主要步骤profiler分为数据搜集和数据显示两个主要步骤。 数据收集 graph node的每一次执行，记录单步统计数据，主要是执行时间和占用内存，格式参见step_stats.proto，作为原始的最小粒度统计数据源； 每一次session.Run()，所有执行到的graph node的统计数据，都集中汇总保存到 RunMetadata 数据结构中; 用户程序把每一次搜集到的 RunMetadata 添加到profiler实例，做数据累计和加工处理。 数据显示： 数据的过滤、视图组织和显示输出部分规则需要用户自己指定：- 数据的过滤： 比如graph node过滤条件、 显示的字段、排序方式等。 四种视图： 对应显示节点之前的不同组织方式。 scope：应该是 python 层代码中用 tf.name_scope() 包起来的视图 graph：TensorFlow 计算图的视图 op：把 TensorFlow 计算图再细化一层 code：Python 代码视图 视图输出方式： time line : 输出JSON events file, 再用chrome浏览器tracing功能进行查看，可视性很棒。 stdout ： 标准输出设备打印。 pprof file: 输出pprof的文件格式，再用pprof工具查看。 file: 输出到普通的文本文件。 视图和输出方式，可以自由组合，除了部分特例不能输出，比如op view 不支持time line输出，只有code view能够输出pprof格式的文件等，详细规则参见 Options 2.快速教程首先，确认下载安装了 r1.3 以上的tensorflow。网络模型使用mnist.py . import相关的包 12345import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_datafrom tensorflow.python.profiler import model_analyzerfrom tensorflow.python.profiler import option_builder12341234 定义网络模型，创建session.、网络模型为 hidden1 + hidden2 + softmax 三层架构， hidden1和hidden2都是(Wx+b)-&gt;Relu的路径。 默认都运行在gpu:0 上。 12345678910111213141516171819# placeholderbatch_size = 100inputs = tf.placeholder(tf.float32, [batch_size,784])targets = tf.placeholder(tf.int32, [batch_size])# modelhidden1 = tf.layers.dense(inputs, 128, activation=tf.nn.relu, name='hidden1')hidden2 = tf.layers.dense(hidden1, 32, activation=tf.nn.relu, name='hidden2')logits = tf.layers.dense(hidden2, 10, activation=None, name='softmax_linear')# loss + train_oploss = tf.losses.sparse_softmax_cross_entropy(labels=targets, logits=logits)global_step = tf.Variable(0, name='global_step', trainable=False)train_op = tf.train.GradientDescentOptimizer(0.01).minimize(loss, global_step=global_step)init = tf.global_variables_initializer()sess = tf.Session()sess.run(init) 创建tfprofiler实例，作为记录、处理和显示数据的主体 12profiler = model_analyzer.Profiler(graph=sess.graph)11 定义trace level为FULL_TRACE，这样我们才能搜集到包括GPU硬件在内的最全统计数据 12run_options = tf.RunOptions(trace_level = tf.RunOptions.FULL_TRACE)11 创建RunMetadata， 用于在每次session.Run()时汇总统计数据 12run_metadata = tf.RunMetadata()11 循环执行session.Run()，搜集统计数据并添加到tfprofiler实例中 123456789101112131415mnist = input_data.read_data_sets(train_dir='./',fake_data=False)feed_dict = dict()for step in range(100): images_feed, labels_feed = mnist.train.next_batch(batch_size, fake_data=False) feed_dict = &#123;inputs: images_feed, targets: labels_feed&#125; #每 10 步，搜集一下统计数据： if step % 10 == 0: _, loss_value = sess.run(fetches=[train_op, loss],feed_dict=feed_dict, options=run_options, run_metadata=run_metadata) #将本步搜集的统计数据添加到tfprofiler实例中 profiler.add_step(step=step, run_meta=run_metadata) else: _, loss_value = sess.run(fetches=[train_op, loss], feed_dict=feed_dict) 接下来我们就可以显示统计视图了定义显示option 和 视图方式 定义显示option 和 视图方式option用于设置过滤条件、显示字段，完整option 参见Options，常用设置项目： account_type_regexes：采用Google RE2规则的正则表达式，过滤要显示的node的op type 和 device，比如 ‘.MatMul.‘, ‘.Conv2D’, ‘.gpu:0’等。 select：要显示的字段：[bytes|micros|accelerator_micros|cpu_micros|params|float_ops|occurrence|tensor_value|device|op_types|input_shapes] order_by: 显示结果排序方式：[name|depth|bytes|micros|accelerator_micros|cpu_micros|params|float_ops|occurrence] output: 输出方式：stdout, file 或者 timeline。 step: 显示在某个具体的Run() step的统计值. 缺省值-1，显示所有步骤的平均值。 一般来说， option和试图总是结合起来使用，这里举几个典型应用例子： 例子1：grpah view显示每个graph node运行时间，并输出到timeline 12345678910111213#统计内容为每个graph node的运行时间和占用内存profile_graph_opts_builder = option_builder.ProfileOptionBuilder( option_builder.ProfileOptionBuilder.time_and_memory())#输出方式为timeline# 输出文件夹必须存在profile_graph_opts_builder.with_timeline_output(timeline_file='/tmp/mnist_profiler.json')#定义显示sess.Run() 第70步的统计数据profile_graph_opts_builder.with_step(70)#显示视图为graph viewprofiler.profile_graph(profile_graph_opts_builder.build())123456789101112123456789101112 我们得到第70步的详细time line结果，打开chrome浏览器，输入about:tracing, 然后load “/tmp/mnist_profiler.json” 文件，这时候可以看见time line的显示结果。 横向是时间轴：各device对graph node的kernel调度时间轴、执行时间轴。 整个graph中所有执行到的node在devices上的运行分布。由于本例中node缺省使用gpu:0，所以cpu:0上没有执行node的分布。 一个kernel的执行包括调度和执行两个阶段，这两个阶段是异步操作，所以我们看到同一个时间点, 当 gpu:0/stream 上还在执行hidden1/Matmul, 而gpu：0已经开始调度下一个node: hidden1/add 的kernel, 这样实现了最大程度上不同node 间的并发。 你可以通过tf.device()将部分node分布到其他gpu上或者cpu上，看看做model parallel的结果。 例子2：scope view显示模型中的参数数量分布通过这种方式，查看各个layer中参数的总数，以控制模型的大小和参数分布。 1234567891011121314#统计内容为所有trainable Variable Opprofile_scope_opt_builder = option_builder.ProfileOptionBuilder( option_builder.ProfileOptionBuilder.trainable_variables_parameter())#显示的嵌套深度为4profile_scope_opt_builder.with_max_depth(4)#显示字段是params，即参数profile_scope_opt_builder.select(['params'])#根据params数量进行显示结果排序profile_scope_opt_builder.order_by('params')#显示视图为scope viewprofiler.profile_name_scope(profile_scope_opt_builder.build())1234567891011121312345678910111213 我们得到param数量从高到低的排序显示： 1234567891011121314==================Model Analysis Report======================node name | # parameters_TFProfRoot (--/104.94k params) hidden1 (--/100.48k params) hidden1/weights (784x128, 100.35k/100.35k params) hidden1/biases (128, 128/128 params) hidden2 (--/4.13k params) hidden2/weights (128x32, 4.10k/4.10k params) hidden2/biases (32, 32/32 params) softmax_linear (--/330 params) softmax_linear/weights (32x10, 320/320 params) softmax_linear/biases (10, 10/10 params)======================End of Report==========================]]></content>
      <categories>
        <category>Tensorflow</category>
      </categories>
      <tags>
        <tag>Deep learning</tag>
        <tag>科研 - 学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java String和StringBuffer区别]]></title>
    <url>%2F2019%2F03%2F22%2FJava_06_%20String%2F</url>
    <content type="text"><![CDATA[String可变性 简单的来说：String 类中使用 final 关键字字符数组保存字符串，private final char value[]，所以 String 对象是不可变的。而StringBuilder 与 StringBuffer 都继承自 AbstractStringBuilder 类，在 AbstractStringBuilder 中也是使用字符数组保存字符串char[]value 但是没有用 final 关键字修饰，所以这两种对象都是可变的。 StringBuilder 与 StringBuffer 的构造方法都是调用父类构造方法也就是 AbstractStringBuilder 实现的，可以参照源码。 123456789//AbstractStringBuilder.javaabstract class AbstractStringBuilder implements Appendable, CharSequence &#123; char[] value; int count; AbstractStringBuilder() &#123; &#125; AbstractStringBuilder(int capacity) &#123; value = new char[capacity]; &#125; String是不可变对象，即对象一旦生成，就不能被更改。对String对象的改变会引发新的String对象的生成。 121 String s = &quot;abcd&quot;;2 s = s+&quot;efgh&quot;; 执行以下代码实际上是生成了一个新的String对象。然后让引用指向新的String对象。所以内容经常改变的字符串不要使用String类型，由于这样会造成内存中大量的无引用对象，然后JVM的GC就会开始工作。 如下代码将会产生10000个无引用对象。 1234567891011String S1 = “abc”; For(int i = 0 ; i &lt; 10000 ; i ++) &#123; S1 + = “def”; S1 = “abc”; &#125; StringBufferStrinhBuffer:每次都对对象本身进行操作，而不是生成新的对象。所以在字符串内容不断改变的情况，建议使用StringBuffer。 String对象的字符串拼接其实是被JVM解释成了StringBuffer对象的拼接，所以这些时候String对象的速度并不会比StringBuffer慢。 如下代码，String的效率远比StringBuffer快。 121 String S1 = “This is only a” + “ simple” + “ test”; 2 StringBuffer Sb = new StringBuilder(“This is only a”).append(“simple”).append(“ test”); 这是因为，在JVM眼里：String S1 = “This is only a” + “ simple” + “ test”;就是String S1 = “This is only a simple test”; StringBuildStringBuild是JDK1.5新增加的一个类，与StringBuffer具有相同的操作。 区别在于：StringBuffer是线程安全的类。StringBuild不是线程安全的类，在单线程中性能要比StringBuffrer高。 例如：《Think in Java》中，描述HashTable和HashMap区别一样，就是因为HashTable支持线程同步、保证线程安全而导致的性能下降。 HashTable是线程安全的，很多方法都是synchronized方法。 HashMap不是线程安全的，但在单线程程序中的性能比HashTable要高。 使用总结 操作少量的数据 = String 单线程操作字符串缓冲区下操作大量数据 = StringBuilder 多线程操作字符串缓冲区下操作大量数据 = StringBuffer]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java - 学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql基础知识]]></title>
    <url>%2F2019%2F03%2F19%2FDatabase_01_MySQLbasic%2F</url>
    <content type="text"><![CDATA[内容 数据库的基本概念 MySQL数据库软件 安装 卸载 配置 SQL 数据库的基本概念1. 数据库的英文单词： DataBase 简称 ： DB 2. 什么数据库？ * 用于存储和管理数据的仓库。 3. 数据库的特点： 1. 持久化存储数据的。其实数据库就是一个文件系统 2. 方便存储和管理数据 3. 使用了统一的方式操作数据库 -- SQL 4. 常见的数据库软件 * 参见《MySQL基础.pdf》 MySQL数据库软件1. 安装 * 参见《MySQL基础.pdf》 2. 卸载 1. 去mysql的安装目录找到my.ini文件 * 复制 datadir=&quot;C:/ProgramData/MySQL/MySQL Server 5.5/Data/&quot; 2. 卸载MySQL 3. 删除C:/ProgramData目录下的MySQL文件夹。 3. 配置 * MySQL服务启动 1. 手动。 2. cmd--&gt; services.msc 打开服务的窗口 3. 使用管理员打开cmd * net start mysql : 启动mysql的服务 * net stop mysql:关闭mysql服务 * MySQL登录 1. mysql -uroot -p密码 2. mysql -hip -uroot -p连接目标的密码 3. mysql --host=ip --user=root --password=连接目标的密码 * MySQL退出 1. exit 2. quit * MySQL目录结构 1. MySQL安装目录：basedir=&quot;D:/develop/MySQL/&quot; * 配置文件 my.ini 2. MySQL数据目录：datadir=&quot;C:/ProgramData/MySQL/MySQL Server 5.5/Data/&quot; * 几个概念 * 数据库：文件夹 * 表：文件 * 数据：数据 SQL1.什么是SQL？ Structured Query Language：结构化查询语言 其实就是定义了操作所有关系型数据库的规则。每一种数据库操作的方式存在不一样的地方，称为“方言”。 2.SQL通用语法 1. SQL 语句可以单行或多行书写，以分号结尾。 2. 可使用空格和缩进来增强语句的可读性。 3. MySQL 数据库的 SQL 语句不区分大小写，关键字建议使用大写。 4. 3 种注释 * 单行注释: -- 注释内容 或 # 注释内容(mysql 特有) * 多行注释: /* 注释 */ 3. SQL分类 1) DDL(Data Definition Language)数据定义语言 用来定义数据库对象：数据库，表，列等。关键字：create, drop,alter 等 2) DML(Data Manipulation Language)数据操作语言 用来对数据库中表的数据进行增删改。关键字：insert, delete, update 等 3) DQL(Data Query Language)数据查询语言 用来查询数据库中表的记录(数据)。关键字：select, where 等 4) DCL(Data Control Language)数据控制语言(了解) 用来定义数据库的访问权限和安全级别，及创建用户。关键字：GRANT， REVOKE 等 DDL:操作数据库、表1. 操作数据库：CRUD 1. C(Create):创建 * 创建数据库： * create database 数据库名称; * 创建数据库，判断不存在，再创建： * create database if not exists 数据库名称; * 创建数据库，并指定字符集 * create database 数据库名称 character set 字符集名; * 练习： 创建db4数据库，判断是否存在，并制定字符集为gbk * create database if not exists db4 character set gbk; 2. R(Retrieve)：查询 * 查询所有数据库的名称: * show databases; * 查询某个数据库的字符集:查询某个数据库的创建语句 * show create database 数据库名称; 3. U(Update):修改 * 修改数据库的字符集 * alter database 数据库名称 character set 字符集名称; 4. D(Delete):删除 * 删除数据库 * drop database 数据库名称; * 判断数据库存在，存在再删除 * drop database if exists 数据库名称; 5. 使用数据库 * 查询当前正在使用的数据库名称 * select database(); * 使用数据库 * use 数据库名称; 2. 操作表 1. C(Create):创建 1. 语法： create table 表名( 列名1 数据类型1, 列名2 数据类型2, .... 列名n 数据类型n ); * 注意：最后一列，不需要加逗号（,） * 数据库类型： 1. int：整数类型 * age int, 2. double:小数类型 * score double(5,2) 3. date:日期，只包含年月日，yyyy-MM-dd 4. datetime:日期，包含年月日时分秒 yyyy-MM-dd HH:mm:ss 5. timestamp:时间错类型 包含年月日时分秒 yyyy-MM-dd HH:mm:ss * 如果将来不给这个字段赋值，或赋值为null，则默认使用当前的系统时间，来自动赋值 6. varchar：字符串 * name varchar(20):姓名最大20个字符 * zhangsan 8个字符 张三 2个字符 * 创建表 create table student( id int, name varchar(32), age int , score double(4,1), birthday date, insert_time timestamp ); * 复制表： * create table 表名 like 被复制的表名; 2. R(Retrieve)：查询 * 查询某个数据库中所有的表名称 * show tables; * 查询表结构 * desc 表名; 3. U(Update):修改 1. 修改表名 alter table 表名 rename to 新的表名; 2. 修改表的字符集 alter table 表名 character set 字符集名称; 3. 添加一列 alter table 表名 add 列名 数据类型; 4. 修改列名称 类型 alter table 表名 change 列名 新列别 新数据类型; alter table 表名 modify 列名 新数据类型; 5. 删除列 alter table 表名 drop 列名; 4. D(Delete):删除 * drop table 表名; * drop table if exists 表名 ; 客户端图形化工具：SQLYog DML：增删改表中数据1. 添加数据： * 语法： * insert into 表名(列名1,列名2,...列名n) values(值1,值2,...值n); * 注意： 1. 列名和值要一一对应。 2. 如果表名后，不定义列名，则默认给所有列添加值 insert into 表名 values(值1,值2,...值n); 3. 除了数字类型，其他类型需要使用引号(单双都可以)引起来 2. 删除数据： * 语法： * delete from 表名 [where 条件] * 注意： 1. 如果不加条件，则删除表中所有记录。 2. 如果要删除所有记录 1. delete from 表名; -- 不推荐使用。有多少条记录就会执行多少次删除操作 2. TRUNCATE TABLE 表名; -- 推荐使用，效率更高 先删除表，然后再创建一张一样的表。 3. 修改数据： * 语法： * update 表名 set 列名1 = 值1, 列名2 = 值2,... [where 条件]; * 注意： 1. 如果不加任何条件，则会将表中所有记录全部修改。 DQL：查询表中的记录* select * from 表名; 1. 语法： select 字段列表 from 表名列表 where 条件列表 group by 分组字段 having 分组之后的条件 order by 排序 limit 分页限定 2. 基础查询 1. 多个字段的查询 select 字段名1，字段名2... from 表名； * 注意： * 如果查询所有字段，则可以使用*来替代字段列表。 2. 去除重复： * distinct 3. 计算列 * 一般可以使用四则运算计算一些列的值。（一般只会进行数值型的计算） * ifnull(表达式1,表达式2)：null参与的运算，计算结果都为null * 表达式1：哪个字段需要判断是否为null * 如果该字段为null后的替换值。 4. 起别名： * as：as也可以省略 3. 条件查询 1. where子句后跟条件 2. 运算符 * &gt; 、&lt; 、&lt;= 、&gt;= 、= 、&lt;&gt; * BETWEEN...AND * IN( 集合) * LIKE：模糊查询 * 占位符： * _:单个任意字符 * %：多个任意字符 * IS NULL * and 或 &amp;&amp; * or 或 || * not 或 ! -- 查询年龄大于20岁 SELECT * FROM student WHERE age &gt; 20; SELECT * FROM student WHERE age &gt;= 20; -- 查询年龄等于20岁 SELECT * FROM student WHERE age = 20; -- 查询年龄不等于20岁 SELECT * FROM student WHERE age != 20; SELECT * FROM student WHERE age &lt;&gt; 20; -- 查询年龄大于等于20 小于等于30 SELECT * FROM student WHERE age &gt;= 20 &amp;&amp; age &lt;=30; SELECT * FROM student WHERE age &gt;= 20 AND age &lt;=30; SELECT * FROM student WHERE age BETWEEN 20 AND 30; -- 查询年龄22岁，18岁，25岁的信息 SELECT * FROM student WHERE age = 22 OR age = 18 OR age = 25 SELECT * FROM student WHERE age IN (22,18,25); -- 查询英语成绩为null SELECT * FROM student WHERE english = NULL; -- 不对的。null值不能使用 = （!=） 判断 SELECT * FROM student WHERE english IS NULL; -- 查询英语成绩不为null SELECT * FROM student WHERE english IS NOT NULL; -- 查询姓马的有哪些？ like SELECT * FROM student WHERE NAME LIKE &apos;马%&apos;; -- 查询姓名第二个字是化的人 SELECT * FROM student WHERE NAME LIKE &quot;_化%&quot;; -- 查询姓名是3个字的人 SELECT * FROM student WHERE NAME LIKE &apos;___&apos;; ​​ – 查询姓名中包含德的人​ SELECT * FROM student WHERE NAME LIKE ‘%德%’; ​]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库 - 学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dynamic Space-Time Scheduling for GPU Inference论文总结]]></title>
    <url>%2F2019%2F03%2F18%2Fpaper_03_Dynamic%20Space-Time%20Scheduling%20for%20GPU%20Inference%2F</url>
    <content type="text"><![CDATA[Dynamic Space-Time Scheduling for GPU Inference论文总结摘要1.在线推断任务典型的小批量导致GPU利用率较低，GPU资源共享可以解决性能差距。 2.在本文中，探索了几种利用时间和空间复用来提高深度学习推理工作负载的GPU利用率的技术。 3.与传统的批量推理相比，评估每种方法在资源效率，延迟可预测性和隔离方面的性能。 4.实验分析表明，通过探索更先进的空间和时间复用策略，可以提高5倍的利用率。 5.动态空时调度器的初步原型比仅用空间复用的策略高3.23倍浮点吞吐量，在卷积上比仅用时间复用策略增加7.73倍，同时还提供了更好的隔离和延迟可预测性。 出发点11.GPU通过并行性，高内存带宽和张量加速，可以快速计算大批量输入数据，对于深度学习至关重要。 2.深度学习部署在视频监控，语言翻译和语音识别等应用中，对并行硬件加速的需求很大以支持推理。虽然有许多专用推理处理器，但GPU的广泛性，对通用深度学习模型的支持使GPU成为推理必不可少的。 3.DNN训练成本高，但不频繁。而在线推理需要每天数十亿次查询。亚马逊宣布大约90％的机器学习计算用于推理（而非训练）。关键的应用程序指标会因延迟增加而受到严重影响。 4.端到端延迟预算（&lt;100ms），高准确性的模型尺寸和复杂性不断增加。SENet-184模型具有4：1的CPU推断延迟。 CPU无法支持今天的交互模型服务工作负载 出发点21.训练负载大，很容易使GPU饱和。但推理具有不同的性能要求，导致GPU利用率较低。与面向吞吐量的模型训练相比，推断查询会随机到达，推理必须满足延迟目标（牺牲吞吐量）。 2.在线推理无法实现小批量迭代训练时的高并行性; 较低的并行性导致GPU利用率低。 3.推理小批量所引发的问题随着模型复杂性增加而加剧，GPU推理延迟不断接近交互式SLO。由于推理工作负载必须连续运行并响应高度可变的需求，必须为需求峰值配置容量，这进一步降低了GPU利用率。 4.小批量可能导致GPU低利用率低于15％，测试中谷歌的Tensor Processing Unit的吞吐量平均低于峰值的23％，某些模型的吞吐量低于4％。目前独占访问GPU的做法导致硬件的低利用率，且无法得到扩展。 系统中总会有少量响应的延迟高于均值，我们把这些响应称为尾延迟（TailLatency）。 图1表示DNN模型的复杂性随着时间在CPU和GPU上不断增加。 大多数型号都无法满足CPU上300ms的延迟SLO。 图2表示为了满足延迟SLO，必须使用小批量尺寸，这导致GPU利用率较低。 SLO中ResNet-50的最大批量为26，但仅达到峰值V100 FP32吞吐量的28％。 改进做法概述1.在随机请求负载下，提高利用率的常用方法是利用多用户。通过多个预测工作负载之间共享GPU，可以潜在地利用工作负载级并行性并实现统计复用。但在GPU上利用多用户是一个开放的研究问题。首先，它的运行时性能必须是可预测的，但它并不总是正确的。 第二，它必须是资源有效的，作者探索了几种在一组执行内核之间共享GPU的技术，每种技术都有其缺点。 第三，需要衡量性能隔离度，通过公平的资源分配来实现。 2.当前方法通过空间或时间复用GPU。作者认为只有跨空间或时间的多路复用才能满足上述条件。第3节评估了针对上述三个标准的现行方法。通过使用动态查询批处理将多个执行内核打包在不相交的DNN图上，显示多租户解决方案吞吐量增加3倍，同时提供隔离和可预测性。 应用程序模型：托管云推理服务 使用云托管服务部署在线推理ML模型，如AWS SageMaker或GoogleCloud ML Engine。用户将训练好的模型上传到在线服务器。在线服务将模型部署到一个或多个副本上，每个副本可以使用CPU和GPU。用户设定某些服务级别目标（SLO），例如模型推断的尾延迟。 简化了模型，隔离多租户执行而产生的干扰影响。首先，在单个GPU上运行的所有模型都有相同的架构（权重不同），将异构模型架构的影响与多租户分开。其次，请求队列总是饱和，从而将模型服务延迟与请求排队延迟隔离开来。解决模型异构性和排队延迟是未来工作的重点。 仅空间和仅时间多路复用的限制1.当前模型推理的三种主要方法：（1）独占。每个型号独占GPU，AWS SageMaker，GoogleCloud ML Engine，Clipper 和TensorFlow Serving都使用这种方法。推断是分批进行的，执行前向传播时，新查询必须在队列中等待，直到之前的前向传播完成。 （2）时间复用。设备上调度程序一次启用多个CUDA上下文环境交叉执行。当多个进程使用相同的GPU并发运行时，这种方法很常见。当不同的进程竞争相同的资源时，这种方法依赖于内核来时间复用进程和GPU来交换上下文。 （3）空间复用。 利用NVIDIA Hyper-Q，内核执行可以重叠。 CUDA Streams和NVIDIA Multi Process Service（MPS）利用多个硬件队列来实现GPU的空间共享。 CUDA Streams API由ModelBatch和NVIDIA TensorRT 使用。AMD的MxGPU（SR-IOV）是另一种空间复用方法，本文没有考虑。 在本文中，考虑两种空间复用： a.使用MPS的隐式空间复用：NVIDIA MPS通过为它们分配不同的cuda流，允许同时在设备上运行多个进程。 b.使用CUDA流进行显式空间复用：使用此方法，我们可以直接与单个进程内的多个CUDA流进行交互。 评测每种模型推理方法的延迟可预测性，资源效率和性能隔离。 实验设置在两个图像分类神经上评估这三种虚拟化方法：MobileNet V2和ResNet-50。 这两种模型分别是低计算和高精度分类的代表。 1.在GPU上执行单个模型批量查询测试独占访问。虽然我们不能在单个GPU上使用多个模型，但此测试表示了单用户延迟下限，以及性能的理想情况。 2.在单独的CUDA上下文中运行每个模型并利用调度器来交错执行，测试时间复用。 这提供了内存安全性和租户之间的基本隔离。 3.通过使用NVIDIA MPS对跨CUDA Streams pool的不同模型的查询进行分区来测试空间复用。 所有实验都在Amazon AWS上使用p3.2xlarge或p3.8xlarge实例。 这些实例可直接访问NVIDIA V100数据中心级GPU，具有高达14 TFLOP / s的单精度浮点运算量。 在实验中没有测试Tensor Core共享。 图3表示，时间和空间复用都不如独占访问的性能; 空间复用比时间复用推理延迟更低。我们比较了GPU多用户的三种方法。 独占访问（通过对单个模型进行批处理建模）以高成本提供快速且可预测的延迟。 随着共享的增加，时间复用显着增加了推理延迟。 通过NVIDIA MPS进行空间复用可以通过共享资源更好地控制延迟。 实验结果图3中基准测试的结果，对于MobileNet V2（计算优化模型）和ResNet-50（高精度模型），我们测试了批量独占访问，时间复用和空间复用。 批量独占访问将整个GPU用于单个模型。这代表了如果只有一个模型独占GPU，并且吞吐量是唯一目标时的理想性能。（改变批量大小以增加吞吐量）但是如果希望最小化延迟，则使用更小的批量。 与独占访问相比，时间复用延迟慢了4.6倍，空间复用延迟慢了2.2倍。单一解决方案无法满足在第1节中建立的三个标准。 图4表示，当不同数量的进程同时运行时，隐式空间复用（使用MPS）具有不可预测的延迟。当我们向运行10个多租户模型的GPU添加副本时，我们会发现不可预测性，我们怀疑这是由设备上的调度程序引起的。 图5表示，时间和隐式空间复用都受内存限制，而 显式空间复用不受。 实验中，大多数方法在18个副本上达到16 GB的内存上限，此时GPU内存耗尽。而显式空间复用（不同线程上的CUDA Streams）能够扩展到至少60个ResNet-50模型。 1.独占访问满足低延迟，隔离和可预测性，但是无法共享GPU导致成本非常昂贵。正如图2中所示，这种性能是在权衡在线推理工作负载的低GPU利用率以满足严格的延迟SLO。如果在推理期间具有足够高的请求率，并且批量请求能同时到达开始前向传播，那么这种方法能很好利用GPU。 2.时间复用（CUDA上下文切换）可以实现多租户良好隔离和延迟可预测性，但代价是吞吐量降低和延迟高。这种方法的主要缺点是它无法利用内核的并行执行，因为GPU一次只允许运行一个CUDA上下文。这种方法在交错过程会略微提高资源效率;然而它在每个调度量程中仍然受到利用率低的影响，随着副本数量的增加，呈现线性减速。较差的延迟使得时间复用不能成为交互式推理查询服务的方法。 3.空间复用（Hyper-Q）提高了利用率，并实现了更好的资源效率，但是可预测性和隔离性较差。空间多路复用对租户数量的选择极其敏感。模型运行时，每个租户都具有一致的行为。 但是，在多个模型租户中，GPU上最快的模型与最慢的模型存在高达25％的延迟差距，如图4所示，当奇数个进程启用MPS同时运行时，不同进程之间的延迟不可预测性和差异会加剧。 动态时空调度1.图3和图5展示了仅空间和仅时间复用策略的可扩展性限制。图4详细说明了将租户添加到GPU时无法预测的延迟。图5显示了在GPU上安排数百个模型的唯一方法是在单个进程中每个线程使用一个CUDA流;因为我们通过将内核分派到不同的流来微观地管理推理，所以有机会对流进行更细粒度的调度以优化延迟和吞吐量。 2.鉴于这些限制，我们提出了动态时空调度，以便有效地利用GPU，同时保持隔离和可预测性。通过监控每个内核的推理延迟来保持虚拟化时的可预测性和隔离性，允许在租户之间重新分配资源。注意到CUDA Stream调度异常只会产生一些落后者，我们可以简单地驱逐落后者而不会显着影响总体系统吞吐量。 3.该方法显着提高了GPU上的资源效率，与仅时间多路复用相比，吞吐量平均速度提高了7.71，与仅空间多路复用相比增加了3.23。如图7所示，时空调度合并了许多不相交的DNN图上的并发小内核，成为较大的超级内核一起填充GPU。 超级内核避免了仅空间复用方法相关联的调度惩罚。交互式推理查询随机到达，我们无法提前计算超级内核。时空调度程序必须在内核到达时动态调度内核，我们正在研究更通用的动态调度程序设计。我们注意到，如果缓存超级内核，随着工作负载随时间稳定，开销会逐渐减少。 我们的目标是动态优化一批不同的模型，与先前的DNN图优化器相比，如TVM，Tensor Comprehensions，Halide，GLOW和TensorRT。这些优化器通过内核融合和自动调整优于单租户优化。但是，我们的方法侧重于优化许多不相交图的性能。 我们的方法是对Guevara等人开发的方法的动态替代方案。他们通过手动组合流中的小内核以提高GPU利用率，在高斯消除算法上产生高达1.3倍的加速。Guevara等人的工作侧重于在CUDA块级手动合并内核，我们的方法侧重于批量处理大量动态执行类似的矩阵乘法例程的内核，以及交错的CUDA流。我们的方法在多个神经网络任务中具有高可扩展性，并与现有生态系统相辅相成。 动态时空调度基准通过单精度浮点通用矩阵乘法内核（SGEMM）按仅时间，仅空间和空时多路复用策略评估总吞吐量。除了傅立叶域，Winograd域和直接内核实现之外，矩阵乘法通常用于在神经网络中实现卷积运算。 图7表明，与GPU共享的时间分割方法相比，通过Hyper-Q / CUDA流实现的空间复用可以提高吞吐量。但是吞吐量远低于V100提供的单精度吞吐量（3.1节）。我们设计了一种调度程序，它可以跨模型对内核进行批处理，而不是维护设备可以精细调度的单独内核流。通过将内核跨多个模型批处理组成单个超级内核中，有可能使GPU上的所有时间片资源饱和。 为了模拟时空多路复用软件调度器的性能，我们测量了标称方法的吞吐量 - 从同一架构的几个模型收集SGEMM问题到单个批量矩阵乘法超级内核。在多租户设置中，这些模型具有不同的权重和输入。 批量超级内核比许多较小的内核调用更有效，并且还可以更好地对GPU进行空间多路复用。 这还允许更好地预测延迟，因为动态内核调度程序可以选择性地将内核组成批并确定何时基于每个模型的SLO执行工作负载。 我们的目标是动态优化一批不同的模型，与先前的DNN图优化器相比，如TVM，Tensor Comprehensions，Halide，GLOW和TensorRT。这些优化器通过内核融合和自动调整优于单租户优化。但是，我们的方法侧重于优化许多不相交图的性能。 我们的方法是对Guevara等人开发的方法的动态替代方案。他们通过手动组合流中的小内核以提高GPU利用率，在高斯消除算法上产生高达1.3倍的加速。Guevara等人的工作侧重于在CUDA块级手动合并内核，我们的方法侧重于批量处理大量动态执行的矩阵乘法内核，以及交错的CUDA流。我们的方法在多个神经网络任务中具有高可扩展性，并与现有生态系统相辅相成。 总结这项工作中，我们评估了空间和时间复用技术，以支持在单个GPU上多个模型进行推理。我们首先考虑了流行的DNN框架和GPU供应商（如NVIDIA）使用的标准方法。虽然这些技术提高了利用率，但它们增加了基准测试中的延迟和预测可变性。仅空间和仅时间的多路复用技术都不能实现高资源效率，可预测的延迟和隔离。我们观察到批量级并行和仅空间复用之间存在巨大的性能差距，这表明有很多提高利用率的机会。我们提出了一个动态的空时调度程序，它可以满足上述三个标准。跨多模型和输入的内核运算的软件级融合，提供了一种有效的在线推理调度方法。作为方法的早期评估，我们通过SGEMM融合所有排队问题来研究性能上限，这提供了GPU多租户或多模型扩展的吞吐量。与在线推理先前技术水平相比，有超过3倍的加速比。我们相信这项工作指向通过智能模型间融合内核调度实现深度神经网络高效多租户执行的新方法。]]></content>
      <categories>
        <category>科研</category>
      </categories>
      <tags>
        <tag>深度学习任务调度 - 论文阅读 - 科研</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSS笔记]]></title>
    <url>%2F2019%2F03%2F17%2Ffront_02_CSS%2F</url>
    <content type="text"><![CDATA[CSS笔记1. HTML标签：表单标签 2. CSS： HTML标签：表单标签* 表单： * 概念：用于采集用户输入的数据的。用于和服务器进行交互。 * form：用于定义表单的。可以定义一个范围，范围代表采集用户数据的范围 * 属性： * action：指定提交数据的URL * method:指定提交方式 * 分类：一共7种，2种比较常用 * get： 1. 请求参数会在地址栏中显示。会封装到请求行中(HTTP协议后讲解)。 2. 请求参数大小是有限制的。 3. 不太安全。 * post： 2. 请求参数不会再地址栏中显示。会封装在请求体中(HTTP协议后讲解) 2. 请求参数的大小没有限制。 3. 较为安全。 * 表单项中的数据要想被提交：必须指定其name属性 ​ * 表单项标签： ​ * input：可以通过type属性值，改变元素展示的样式 ​ * type属性： ​ * text：文本输入框，默认值 ​ * placeholder：指定输入框的提示信息，当输入框的内容发生变化，会自动清空提示信息 ​ * password：密码输入框 ​ * radio:单选框 ​ * 注意： ​ 1. 要想让多个单选框实现单选的效果，则多个单选框的name属性值必须一样。 ​ 2. 一般会给每一个单选框提供value属性，指定其被选中后提交的值 ​ 3. checked属性，可以指定默认值 ​ * checkbox：复选框 ​ * 注意： ​ 1. 一般会给每一个单选框提供value属性，指定其被选中后提交的值 ​ 2. checked属性，可以指定默认值 ​ * file：文件选择框 * hidden：隐藏域，用于提交一些信息。 * 按钮： * submit：提交按钮。可以提交表单 * button：普通按钮 * image：图片提交按钮 * src属性指定图片的路径 * label：指定输入项的文字描述信息 * 注意： * label的for属性一般会和 input 的 id属性值 对应。如果对应了，则点击label区域，会让input输入框获取焦点。 * select: 下拉列表 * 子元素：option，指定列表项 * textarea：文本域 * cols：指定列数，每一行有多少个字符 * rows：默认多少行。 CSS：页面美化和布局控制1. 概念： Cascading Style Sheets 层叠样式表 * 层叠：多个样式可以作用在同一个html的元素上，同时生效 2. 好处： 1. 功能强大 2. 将内容展示和样式控制分离 * 降低耦合度。解耦 * 让分工协作更容易 * 提高开发效率 3. CSS的使用：CSS与html结合方式 1. 内联样式 * 在标签内使用style属性指定css代码 * 如：&lt;div style=&quot;color:red;&quot;&gt;hello css&lt;/div&gt; 2. 内部样式 * 在head标签内，定义style标签，style标签的标签体内容就是css代码 * 如： &lt;style&gt; div{ color:blue; } &lt;/style&gt; &lt;div&gt;hello css&lt;/div&gt; 3. 外部样式 1. 定义css资源文件。 2. 在head标签内，定义link标签，引入外部的资源文件 * 如： * a.css文件： div{ color:green; } &lt;link rel=&quot;stylesheet&quot; href=&quot;css/a.css&quot;&gt; &lt;div&gt;hello css&lt;/div&gt; &lt;div&gt;hello css&lt;/div&gt; * 注意： * 1,2,3种方式 css作用范围越来越大 * 1方式不常用，后期常用2,3 * 3种格式可以写为： &lt;style&gt; @import &quot;css/a.css&quot;; &lt;/style&gt; 4. css语法： * 格式： 选择器 { 属性名1:属性值1; 属性名2:属性值2; ... } * 选择器:筛选具有相似特征的元素 * 注意： * 每一对属性需要使用；隔开，最后一对属性可以不加； 5. 选择器：筛选具有相似特征的元素 * 分类： 1. 基础选择器 1. id选择器：选择具体的id属性值的元素.建议在一个html页面中id值唯一 * 语法：#id属性值{} 2. 元素选择器：选择具有相同标签名称的元素 * 语法： 标签名称{} * 注意：id选择器优先级高于元素选择器 3. 类选择器：选择具有相同的class属性值的元素。 * 语法：.class属性值{} * 注意：类选择器选择器优先级高于元素选择器 2. 扩展选择器： 1. 选择所有元素： * 语法： *{} 2. 并集选择器： * 选择器1,选择器2{} 3. 子选择器：筛选选择器1元素下的选择器2元素 * 语法： 选择器1 选择器2{} 4. 父选择器：筛选选择器2的父元素选择器1 * 语法： 选择器1 &gt; 选择器2{} 5. 属性选择器：选择元素名称，属性名=属性值的元素 * 语法： 元素名称[属性名=&quot;属性值&quot;]{} 6. 伪类选择器：选择一些元素具有的状态 * 语法： 元素:状态{} * 如： &lt;a&gt; * 状态： * link：初始化的状态 * visited：被访问过的状态 * active：正在访问状态 * hover：鼠标悬浮状态 6. 属性 1. 字体、文本 * font-size：字体大小 * color：文本颜色 * text-align：对其方式 * line-height：行高 2. 背景 * background： 3. 边框 * border：设置边框，符合属性 4. 尺寸 * width：宽度 * height：高度 5. 盒子模型：控制布局 * margin：外边距 * padding：内边距 * 默认情况下内边距会影响整个盒子的大小 * box-sizing: border-box; 设置盒子的属性，让width和height就是最终盒子的大小 * float：浮动 * left * right 案例： &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;注册页面&lt;/title&gt; &lt;style&gt; *{ margin: 0px; padding: 0px; box-sizing: border-box; } body{ background: url(&quot;img/register_bg.png&quot;) no-repeat center; padding-top: 25px; } .rg_layout{ width: 900px; height: 500px; border: 8px solid #EEEEEE; background-color: white; /*让div水平居中*/ margin: auto; } .rg_left{ /*border: 1px solid red;*/ float: left; margin: 15px; } .rg_left &gt; p:first-child{ color:#FFD026; font-size: 20px; } .rg_left &gt; p:last-child{ color:#A6A6A6; font-size: 20px; } ​ .rg_center{ ​ float: left; ​ /* border: 1px solid red;*/ ​ } .rg_right{ /*border: 1px solid red;*/ float: right; margin: 15px; } .rg_right &gt; p:first-child{ font-size: 15px; } .rg_right p a { color:pink; } .td_left{ width: 100px; text-align: right; height: 45px; } .td_right{ padding-left: 50px ; } #username,#password,#email,#name,#tel,#birthday,#checkcode{ width: 251px; height: 32px; border: 1px solid #A6A6A6 ; /*设置边框圆角*/ border-radius: 5px; padding-left: 10px; } #checkcode{ width: 110px; } #img_check{ height: 32px; vertical-align: middle; } #btn_sub{ width: 150px; height: 40px; background-color: #FFD026; border: 1px solid #FFD026 ; } &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div class=&quot;rg_layout&quot;&gt; &lt;div class=&quot;rg_left&quot;&gt; &lt;p&gt;新用户注册&lt;/p&gt; &lt;p&gt;USER REGISTER&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;rg_center&quot;&gt; &lt;div class=&quot;rg_form&quot;&gt; &lt;!--定义表单 form--&gt; &lt;form action=&quot;#&quot; method=&quot;post&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;td_left&quot;&gt;&lt;label for=&quot;username&quot;&gt;用户名&lt;/label&gt;&lt;/td&gt; &lt;td class=&quot;td_right&quot;&gt;&lt;input type=&quot;text&quot; name=&quot;username&quot; id=&quot;username&quot; placeholder=&quot;请输入用户名&quot;&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class=&quot;td_left&quot;&gt;&lt;label for=&quot;password&quot;&gt;密码&lt;/label&gt;&lt;/td&gt; &lt;td class=&quot;td_right&quot;&gt;&lt;input type=&quot;password&quot; name=&quot;password&quot; id=&quot;password&quot; placeholder=&quot;请输入密码&quot;&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class=&quot;td_left&quot;&gt;&lt;label for=&quot;email&quot;&gt;Email&lt;/label&gt;&lt;/td&gt; &lt;td class=&quot;td_right&quot;&gt;&lt;input type=&quot;email&quot; name=&quot;email&quot; id=&quot;email&quot; placeholder=&quot;请输入邮箱&quot;&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class=&quot;td_left&quot;&gt;&lt;label for=&quot;name&quot;&gt;姓名&lt;/label&gt;&lt;/td&gt; &lt;td class=&quot;td_right&quot;&gt;&lt;input type=&quot;text&quot; name=&quot;name&quot; id=&quot;name&quot; placeholder=&quot;请输入姓名&quot;&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class=&quot;td_left&quot;&gt;&lt;label for=&quot;tel&quot;&gt;手机号&lt;/label&gt;&lt;/td&gt; &lt;td class=&quot;td_right&quot;&gt;&lt;input type=&quot;text&quot; name=&quot;tel&quot; id=&quot;tel&quot; placeholder=&quot;请输入手机号&quot;&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class=&quot;td_left&quot;&gt;&lt;label&gt;性别&lt;/label&gt;&lt;/td&gt; &lt;td class=&quot;td_right&quot;&gt; &lt;input type=&quot;radio&quot; name=&quot;gender&quot; value=&quot;male&quot;&gt; 男 &lt;input type=&quot;radio&quot; name=&quot;gender&quot; value=&quot;female&quot;&gt; 女 &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class=&quot;td_left&quot;&gt;&lt;label for=&quot;birthday&quot;&gt;出生日期&lt;/label&gt;&lt;/td&gt; &lt;td class=&quot;td_right&quot;&gt;&lt;input type=&quot;date&quot; name=&quot;birthday&quot; id=&quot;birthday&quot; placeholder=&quot;请输入出生日期&quot;&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class=&quot;td_left&quot;&gt;&lt;label for=&quot;checkcode&quot; &gt;验证码&lt;/label&gt;&lt;/td&gt; &lt;td class=&quot;td_right&quot;&gt;&lt;input type=&quot;text&quot; name=&quot;checkcode&quot; id=&quot;checkcode&quot; placeholder=&quot;请输入验证码&quot;&gt; &lt;img id=&quot;img_check&quot; src=&quot;img/verify_code.jpg&quot;&gt; &lt;/td&gt; &lt;/tr&gt; ​ &lt;tr&gt; ​ &lt;td colspan=&quot;2&quot; align=&quot;center&quot;&gt;&lt;input type=&quot;submit&quot; id=&quot;btn_sub&quot; value=&quot;注册&quot;&gt;&lt;/td&gt; ​ &lt;/tr&gt; ​ &lt;/table&gt; ​ &lt;/form&gt; ​ &lt;/div&gt; ​ &lt;/div&gt; &lt;div class=&quot;rg_right&quot;&gt; &lt;p&gt;已有账号?&lt;a href=&quot;#&quot;&gt;立即登录&lt;/a&gt;&lt;/p&gt; &lt;/div&gt; ​ &lt;/div&gt; ​ &lt;/body&gt; ​ &lt;/html&gt;]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>CSS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTML笔记]]></title>
    <url>%2F2019%2F03%2F17%2Ffront_01_HTML%2F</url>
    <content type="text"><![CDATA[HTML笔记1. web概念概述 2. HTML web概念概述* JavaWeb： * 使用Java语言开发基于互联网的项目 * 软件架构： 1. C/S: Client/Server 客户端/服务器端 * 在用户本地有一个客户端程序，在远程有一个服务器端程序 * 如：QQ，迅雷... * 优点： 1. 用户体验好 * 缺点： 1. 开发、安装，部署，维护 麻烦 2. B/S: Browser/Server 浏览器/服务器端 * 只需要一个浏览器，用户通过不同的网址(URL)，客户访问不同的服务器端程序 * 优点： 1. 开发、安装，部署，维护 简单 * 缺点： 1. 如果应用过大，用户的体验可能会受到影响 2. 对硬件要求过高 * B/S架构详解 * 资源分类： 1. 静态资源： * 使用静态网页开发技术发布的资源。 * 特点： * 所有用户访问，得到的结果是一样的。 * 如：文本，图片，音频、视频, HTML,CSS,JavaScript * 如果用户请求的是静态资源，那么服务器会直接将静态资源发送给浏览器。浏览器中内置了静态资源的解析引擎，可以展示静态资源 2. 动态资源： * 使用动态网页及时发布的资源。 * 特点： * 所有用户访问，得到的结果可能不一样。 * 如：jsp/servlet,php,asp... * 如果用户请求的是动态资源，那么服务器会执行动态资源，转换为静态资源，再发送给浏览器 * 我们要学习动态资源，必须先学习静态资源！ * 静态资源： * HTML：用于搭建基础网页，展示页面的内容 * CSS：用于美化页面，布局页面 * JavaScript：控制页面的元素，让页面有一些动态的效果 HTML1. 概念：是最基础的网页开发语言 * Hyper Text Markup Language 超文本标记语言 * 超文本: * 超文本是用超链接的方法，将各种不同空间的文字信息组织在一起的网状文本. * 标记语言: * 由标签构成的语言。&lt;标签名称&gt; 如 html，xml * 标记语言不是编程语言 2. 快速入门： * 语法： 1. html文档后缀名 .html 或者 .htm 2. 标签分为 1. 围堵标签：有开始标签和结束标签。如 &lt;html&gt; &lt;/html&gt; 2. 自闭和标签：开始标签和结束标签在一起。如 &lt;br/&gt; 3. 标签可以嵌套： 需要正确嵌套，不能你中有我，我中有你 错误：&lt;a&gt;&lt;b&gt;&lt;/a&gt;&lt;/b&gt; 正确：&lt;a&gt;&lt;b&gt;&lt;/b&gt;&lt;/a&gt; 4. 在开始标签中可以定义属性。属性是由键值对构成，值需要用引号(单双都可)引起来 5. html的标签不区分大小写，但是建议使用小写。 * 代码： &lt;html&gt; &lt;head&gt; &lt;title&gt;title&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;FONT color=&apos;red&apos;&gt;Hello World&lt;/font&gt;&lt;br/&gt; &lt;font color=&apos;green&apos;&gt;Hello World&lt;/font&gt; &lt;/body&gt; &lt;/html&gt; 3. 标签学习： 1. 文件标签：构成html最基本的标签 * html:html文档的根标签 * head：头标签。用于指定html文档的一些属性。引入外部的资源 * title：标题标签。 * body：体标签 * &lt;!DOCTYPE html&gt;：html5中定义该文档是html文档 2. 文本标签：和文本有关的标签 * 注释：&lt;!-- 注释内容 --&gt; * &lt;h1&gt; to &lt;h6&gt;：标题标签 * h1~h6:字体大小逐渐递减 * &lt;p&gt;：段落标签 * &lt;br&gt;：换行标签 * &lt;hr&gt;：展示一条水平线 * 属性： * color：颜色 * width：宽度 * size：高度 * align：对其方式 * center：居中 * left：左对齐 * right：右对齐 * &lt;b&gt;：字体加粗 * &lt;i&gt;：字体斜体 * &lt;font&gt;:字体标签 * &lt;center&gt;:文本居中 * 属性： * color：颜色 * size：大小 * face：字体 * 属性定义： * color： 1. 英文单词：red,green,blue 2. rgb(值1，值2，值3)：值的范围：0~255 如 rgb(0,0,255) 3. #值1值2值3：值的范围：00~FF之间。如： #FF00FF * width： 1. 数值：width=&apos;20&apos; ,数值的单位，默认是 px(像素) 2. 数值%：占比相对于父元素的比例 * 案例：公司简介 &lt;!DOCTYPE html&gt; &lt;html lang=&quot;ch&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;黑马程序员简介&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt; 公司简介 &lt;/h1&gt; &lt;hr color=&quot;#ffd700&quot;&gt; &lt;p&gt; &lt;font color=&quot;#FF0000&quot;&gt;&quot;中关村黑马程序员训练营&quot;&lt;/font&gt;是由&lt;b&gt;&lt;i&gt;传智播客&lt;/i&gt;&lt;/b&gt;联合中关村软件园、CSDN， 并委托传智播客进行教学实施的软件开发高端培训机构，致力于服务各大软件企业，解决当前软件开发技术飞速发展， 而企业招不到优秀人才的困扰。 &lt;/p&gt; &lt;p&gt; 目前，“中关村黑马程序员训练营”已成长为行业“学员质量好、课程内容深、企业满意”的移动开发高端训练基地， 并被评为中关村软件园重点扶持人才企业。 &lt;/p&gt; &lt;p&gt; 黑马程序员的学员多为大学毕业后，有理想、有梦想，想从事IT行业，而没有环境和机遇改变自己命运的年轻人。 黑马程序员的学员筛选制度，远比现在90%以上的企业招聘流程更为严格。任何一名学员想成功入学“黑马程序员”， 必须经历长达2个月的面试流程，这些流程中不仅包括严格的技术测试、自学能力测试，还包括性格测试、压力测试、 品德测试等等测试。毫不夸张地说，黑马程序员训练营所有学员都是精挑细选出来的。百里挑一的残酷筛选制度确 保学员质量，并降低企业的用人风险。 中关村黑马程序员训练营不仅着重培养学员的基础理论知识，更注重培养项目实施管理能力，并密切关注技术革新， 不断引入先进的技术，研发更新技术课程，确保学员进入企业后不仅能独立从事开发工作，更能给企业带来新的技术体系和理念。 &lt;/p&gt; &lt;p&gt; 一直以来，黑马程序员以技术视角关注IT产业发展，以深度分享推进产业技术成长，致力于弘扬技术创新，倡导分享、 开放和协作，努力打造高质量的IT人才服务平台。 &lt;/p&gt; &lt;hr color=&quot;#ffd700&quot;&gt; &lt;font color=&quot;gray&quot; size=&quot;2&quot;&gt; &lt;center&gt; 江苏传智播客教育科技股份有限公司&lt;br&gt; 版权所有Copyright 2006-2018&amp;copy;, All Rights Reserved 苏ICP备16007882 &lt;/center&gt; &lt;/font&gt; ​ ​ &lt;/body&gt; ​ &lt;/html&gt; ​ ​ 3. 图片标签： ​ * img：展示图片 ​ * 属性： ​ * src：指定图片的位置 ​ * 代码： &lt;!--展示一张图片 img--&gt; &lt;img src=&quot;image/jingxuan_2.jpg&quot; align=&quot;right&quot; alt=&quot;古镇&quot; width=&quot;500&quot; height=&quot;500&quot;/&gt; &lt;!-- 相对路径 * 以.开头的路径 * ./：代表当前目录 ./image/1.jpg * ../:代表上一级目录 --&gt; &lt;img src=&quot;./image/jiangwai_1.jpg&quot;&gt; &lt;img src=&quot;../image/jiangwai_1.jpg&quot;&gt; 4. 列表标签： * 有序列表： * ol: * li: * 无序列表： * ul: * li: 5. 链接标签： * a:定义一个超链接 * 属性： * href：指定访问资源的URL(统一资源定位符) * target：指定打开资源的方式 * _self:默认值，在当前页面打开 * _blank：在空白页面打开 * 代码： &lt;!--超链接 a--&gt; &lt;a href=&quot;http://www.itcast.cn&quot;&gt;点我&lt;/a&gt; &lt;br&gt; &lt;a href=&quot;http://www.itcast.cn&quot; target=&quot;_self&quot;&gt;点我&lt;/a&gt; &lt;br&gt; &lt;a href=&quot;http://www.itcast.cn&quot; target=&quot;_blank&quot;&gt;点我&lt;/a&gt; &lt;br&gt; &lt;a href=&quot;./5_列表标签.html&quot;&gt;列表标签&lt;/a&gt;&lt;br&gt; &lt;a href=&quot;mailto:itcast@itcast.cn&quot;&gt;联系我们&lt;/a&gt; &lt;br&gt; &lt;a href=&quot;http://www.itcast.cn&quot;&gt;&lt;img src=&quot;image/jiangwai_1.jpg&quot;&gt;&lt;/a&gt; 6. div和span： * div:每一个div占满一整行。块级标签 * span：文本信息在一行展示，行内标签 内联标签 7. 语义化标签：html5中为了提高程序的可读性，提供了一些标签。 1. &lt;header&gt;：页眉 2. &lt;footer&gt;：页脚 8. 表格标签： * table：定义表格 * width：宽度 * border：边框 * cellpadding：定义内容和单元格的距离 * cellspacing：定义单元格之间的距离。如果指定为0，则单元格的线会合为一条、 * bgcolor：背景色 * align：对齐方式 * tr：定义行 * bgcolor：背景色 * align：对齐方式 * td：定义单元格 * colspan：合并列 * rowspan：合并行 * th：定义表头单元格 * &lt;caption&gt;：表格标题 * &lt;thead&gt;：表示表格的头部分 * &lt;tbody&gt;：表示表格的体部分 * &lt;tfoot&gt;：表示表格的脚部分 案例：旅游网站首页1. 确定使用table来完成布局 2. 如果某一行只有一个单元格，则使用&lt;tr&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt; 3. 如果某一行有多个单元格，则使用 &lt;tr&gt; &lt;td&gt; &lt;table&gt;&lt;/table&gt; &lt;/td&gt; &lt;/tr&gt; 4. 代码实现 &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;黑马旅游网&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;!--采用table来完成布局--&gt; &lt;!--最外层的table，用于整个页面的布局--&gt; &lt;table width=&quot;100%&quot; align=&quot;center&quot;&gt; &lt;!-- 第1行 --&gt; &lt;tr&gt; &lt;td&gt; &lt;img src=&quot;image/top_banner.jpg&quot; width=&quot;100%&quot; alt=&quot;&quot;&gt; &lt;/td&gt; &lt;/tr&gt; &lt;!-- 第2行 --&gt; &lt;tr&gt; &lt;td&gt; &lt;table width=&quot;100%&quot; align=&quot;center&quot;&gt; &lt;tr&gt; &lt;td&gt; &lt;img src=&quot;image/logo.jpg&quot; alt=&quot;&quot;&gt; &lt;/td&gt; &lt;td&gt; &lt;img src=&quot;image/search.png&quot; alt=&quot;&quot;&gt; &lt;/td&gt; &lt;td&gt; &lt;img src=&quot;image/hotel_tel.png&quot; alt=&quot;&quot;&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/td&gt; &lt;/tr&gt; &lt;!-- 第3行 --&gt; &lt;tr&gt; &lt;td&gt; &lt;table width=&quot;100%&quot; align=&quot;center&quot;&gt; &lt;tr bgcolor=&quot;#ffd700&quot; align=&quot;center&quot; height=&quot;45&quot; &gt; &lt;td&gt; &lt;a href=&quot;&quot;&gt;首页&lt;/a&gt; &lt;/td&gt; &lt;td&gt; 门票 &lt;/td&gt; &lt;td&gt; 门票 &lt;/td&gt; &lt;td&gt; 门票 &lt;/td&gt; &lt;td&gt; 门票 &lt;/td&gt; &lt;td&gt; 门票 &lt;/td&gt; &lt;td&gt; 门票 &lt;/td&gt; &lt;td&gt; 门票 &lt;/td&gt; &lt;td&gt; 门票 &lt;/td&gt; &lt;td&gt; 门票 &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/td&gt; &lt;/tr&gt; &lt;!-- 第4行 轮播图 --&gt; &lt;tr&gt; &lt;td&gt; &lt;img src=&quot;image/banner_3.jpg&quot; alt=&quot;&quot; width=&quot;100%&quot;&gt; &lt;/td&gt; &lt;/tr&gt; &lt;!-- 第5行 黑马精选--&gt; &lt;tr&gt; &lt;td&gt; &lt;img src=&quot;image/icon_5.jpg&quot; alt=&quot;&quot;&gt; 黑马精选 &lt;hr color=&quot;#ffd700&quot; &gt; &lt;/td&gt; &lt;/tr&gt; &lt;!-- 第6行 --&gt; &lt;tr&gt; &lt;td&gt; &lt;table align=&quot;center&quot; width=&quot;95%&quot;&gt; &lt;tr&gt; &lt;td&gt; &lt;img src=&quot;image/jiangxuan_1.jpg&quot; alt=&quot;&quot;&gt; &lt;p&gt;上海飞三亚五天4晚自由行(春节销售+亲子+蜜月+自由行)&lt;/p&gt; &lt;font color=&quot;red&quot;&gt;&amp;yen; 899&lt;/font&gt; &lt;/td&gt; &lt;td&gt; &lt;img src=&quot;image/jiangxuan_1.jpg&quot; alt=&quot;&quot;&gt; &lt;p&gt;上海飞三亚五天4晚自由行(春节销售+亲子+蜜月+自由行)&lt;/p&gt; &lt;font color=&quot;red&quot;&gt;&amp;yen; 899&lt;/font&gt; &lt;/td&gt; &lt;td&gt; &lt;img src=&quot;image/jiangxuan_1.jpg&quot; alt=&quot;&quot;&gt; &lt;p&gt;上海飞三亚五天4晚自由行(春节销售+亲子+蜜月+自由行)&lt;/p&gt; &lt;font color=&quot;red&quot;&gt;&amp;yen; 899&lt;/font&gt; &lt;/td&gt; &lt;td&gt; &lt;img src=&quot;image/jiangxuan_1.jpg&quot; alt=&quot;&quot;&gt; &lt;p&gt;上海飞三亚五天4晚自由行(春节销售+亲子+蜜月+自由行)&lt;/p&gt; &lt;font color=&quot;red&quot;&gt;&amp;yen; 899&lt;/font&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/td&gt; &lt;/tr&gt; &lt;!-- 第7行 国内游 --&gt; &lt;tr&gt; &lt;td&gt; &lt;img src=&quot;image/icon_6.jpg&quot; alt=&quot;&quot;&gt; 国内游 &lt;hr color=&quot;#ffd700&quot; &gt; &lt;/td&gt; &lt;/tr&gt; &lt;!-- 第8行 --&gt; &lt;tr&gt; &lt;td&gt; &lt;table align=&quot;center&quot; width=&quot;95%&quot;&gt; &lt;tr&gt; &lt;td rowspan=&quot;2&quot;&gt; &lt;img src=&quot;image/guonei_1.jpg&quot; alt=&quot;&quot;&gt; &lt;/td&gt; &lt;td&gt; &lt;img src=&quot;image/jiangxuan_2.jpg&quot; alt=&quot;&quot; height=&quot;100%&quot;&gt; &lt;p&gt;上海飞三亚五天4晚自由行(春节销售+亲子+蜜月+自由行)&lt;/p&gt; &lt;font color=&quot;red&quot;&gt;&amp;yen; 699&lt;/font&gt; &lt;/td&gt; &lt;td&gt; &lt;img src=&quot;image/jiangxuan_2.jpg&quot; alt=&quot;&quot;&gt; &lt;p&gt;上海飞三亚五天4晚自由行(春节销售+亲子+蜜月+自由行)&lt;/p&gt; &lt;font color=&quot;red&quot;&gt;&amp;yen; 699&lt;/font&gt; &lt;/td&gt; &lt;td&gt; &lt;img src=&quot;image/jiangxuan_2.jpg&quot; alt=&quot;&quot;&gt; &lt;p&gt;上海飞三亚五天4晚自由行(春节销售+亲子+蜜月+自由行)&lt;/p&gt; &lt;font color=&quot;red&quot;&gt;&amp;yen; 699&lt;/font&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;img src=&quot;image/jiangxuan_2.jpg&quot; alt=&quot;&quot;&gt; &lt;p&gt;上海飞三亚五天4晚自由行(春节销售+亲子+蜜月+自由行)&lt;/p&gt; &lt;font color=&quot;red&quot;&gt;&amp;yen; 699&lt;/font&gt; &lt;/td&gt; &lt;td&gt; &lt;img src=&quot;image/jiangxuan_2.jpg&quot; alt=&quot;&quot;&gt; &lt;p&gt;上海飞三亚五天4晚自由行(春节销售+亲子+蜜月+自由行)&lt;/p&gt; &lt;font color=&quot;red&quot;&gt;&amp;yen; 699&lt;/font&gt; &lt;/td&gt; &lt;td&gt; &lt;img src=&quot;image/jiangxuan_2.jpg&quot; alt=&quot;&quot;&gt; &lt;p&gt;上海飞三亚五天4晚自由行(春节销售+亲子+蜜月+自由行)&lt;/p&gt; &lt;font color=&quot;red&quot;&gt;&amp;yen; 699&lt;/font&gt; &lt;/td&gt; ​ &lt;/tr&gt; ​ &lt;/table&gt; ​ &lt;/td&gt; ​ &lt;/tr&gt; ​ ​ &lt;!-- 第9行 境外游 --&gt; ​ &lt;tr&gt; ​ &lt;td&gt; ​ &lt;img src=&quot;image/icon_7.jpg&quot; alt=&quot;&quot;&gt; ​ 境外游 ​ &lt;hr color=&quot;#ffd700&quot; &gt; ​ &lt;/td&gt; ​ &lt;/tr&gt; ​ &lt;!-- 第10行 --&gt; &lt;tr&gt; &lt;td&gt; &lt;table align=&quot;center&quot; width=&quot;95%&quot;&gt; &lt;tr&gt; &lt;td rowspan=&quot;2&quot;&gt; &lt;img src=&quot;image/jiangwai_1.jpg&quot; alt=&quot;&quot;&gt; &lt;/td&gt; &lt;td&gt; &lt;img src=&quot;image/jiangxuan_3.jpg&quot; alt=&quot;&quot; height=&quot;100%&quot;&gt; &lt;p&gt;上海飞三亚五天4晚自由行(春节销售+亲子+蜜月+自由行)&lt;/p&gt; &lt;font color=&quot;red&quot;&gt;&amp;yen; 699&lt;/font&gt; &lt;/td&gt; &lt;td&gt; &lt;img src=&quot;image/jiangxuan_3.jpg&quot; alt=&quot;&quot;&gt; &lt;p&gt;上海飞三亚五天4晚自由行(春节销售+亲子+蜜月+自由行)&lt;/p&gt; &lt;font color=&quot;red&quot;&gt;&amp;yen; 699&lt;/font&gt; &lt;/td&gt; &lt;td&gt; &lt;img src=&quot;image/jiangxuan_3.jpg&quot; alt=&quot;&quot;&gt; &lt;p&gt;上海飞三亚五天4晚自由行(春节销售+亲子+蜜月+自由行)&lt;/p&gt; &lt;font color=&quot;red&quot;&gt;&amp;yen; 699&lt;/font&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;img src=&quot;image/jiangxuan_3.jpg&quot; alt=&quot;&quot;&gt; &lt;p&gt;上海飞三亚五天4晚自由行(春节销售+亲子+蜜月+自由行)&lt;/p&gt; &lt;font color=&quot;red&quot;&gt;&amp;yen; 699&lt;/font&gt; &lt;/td&gt; &lt;td&gt; &lt;img src=&quot;image/jiangxuan_3.jpg&quot; alt=&quot;&quot;&gt; &lt;p&gt;上海飞三亚五天4晚自由行(春节销售+亲子+蜜月+自由行)&lt;/p&gt; &lt;font color=&quot;red&quot;&gt;&amp;yen; 699&lt;/font&gt; &lt;/td&gt; &lt;td&gt; &lt;img src=&quot;image/jiangxuan_3.jpg&quot; alt=&quot;&quot;&gt; &lt;p&gt;上海飞三亚五天4晚自由行(春节销售+亲子+蜜月+自由行)&lt;/p&gt; &lt;font color=&quot;red&quot;&gt;&amp;yen; 699&lt;/font&gt; &lt;/td&gt; ​ &lt;/tr&gt; ​ &lt;/table&gt; ​ &lt;/td&gt; ​ &lt;/tr&gt; ​ &lt;!-- 第11行 --&gt; ​ &lt;tr&gt; ​ &lt;td&gt; ​ &lt;img src=&quot;image/footer_service.png&quot; alt=&quot;&quot; width=&quot;100%&quot;&gt; ​ &lt;/td&gt; ​ &lt;/tr&gt; ​ ​ &lt;!-- 第12行 --&gt; ​ &lt;tr&gt; ​ &lt;td align=&quot;center&quot; bgcolor=&quot;#ffd700&quot; height=&quot;40&quot;&gt; ​ &lt;font color=&quot;gray&quot; size=&quot;2&quot;&gt; ​ 江苏传智播客教育科技股份有限公司 ​ 版权所有Copyright 2006-2018&amp;copy;, All Rights Reserved 苏ICP备16007882 ​ &lt;/font&gt; ​ &lt;/td&gt; ​ &lt;/tr&gt; ​ &lt;/table&gt; ​ &lt;/body&gt; ​ &lt;/html&gt;]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>HTML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 TensorFlow Serving 和 Docker 快速部署机器学习服务]]></title>
    <url>%2F2019%2F03%2F10%2Ftensor_04_docker_serving%2F</url>
    <content type="text"><![CDATA[从实验到生产，简单快速部署机器学习模型一直是一个挑战。这个过程要做的就是将训练好的模型对外提供预测服务。在生产中，这个过程需要可重现，隔离和安全。这里，我们使用基于Docker的TensorFlow Serving来简单地完成这个过程。TensorFlow 从1.8版本开始支持Docker部署，包括CPU和GPU，非常方便。 获得训练好的模型获取模型的第一步当然是训练一个模型，但是这不是本篇的重点，所以我们使用一个已经训练好的模型，比如ResNet。TensorFlow Serving 使用SavedModel这种格式来保存其模型，SavedModel是一种独立于语言的，可恢复，密集的序列化格式，支持使用更高级别的系统和工具来生成，使用和转换TensorFlow模型。这里我们直接下载一个预训练好的模型： 12$ mkdir /tmp/resnet$ curl -s https://storage.googleapis.com/download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp32_savedmodel_NHWC_jpg.tar.gz | tar --strip-components=2 -C /tmp/resnet -xvz 如果是使用其他框架比如Keras生成的模型，则需要将模型转换为SavedModel格式，比如： 12345678910111213141516171819from keras.models import Sequentialfrom keras import backend as Kimport tensorflow as tfmodel = Sequential()# 中间省略模型构建# 模型转换为SavedModelsignature = tf.saved_model.signature_def_utils.predict_signature_def( inputs=&#123;&apos;input_param&apos;: model.input&#125;, outputs=&#123;&apos;type&apos;: model.output&#125;)builder = tf.saved_model.builder.SavedModelBuilder(&apos;/tmp/output_model_path/1/&apos;)builder.add_meta_graph_and_variables( sess=K.get_session(), tags=[tf.saved_model.tag_constants.SERVING], signature_def_map=&#123; tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: signature &#125;)builder.save() 下载完成后，文件目录树为： 1234567$ tree /tmp/resnet/tmp/resnet└── 1538687457 ├── saved_model.pb └── variables ├── variables.data-00000-of-00001 └── variables.index 部署模型第一步是安装Docker CE。这将为您提供运行和管理Docker容器所需的所有工具。现在我们有了我们的模型，使用Docker服务就像拉动最新发布的TensorFlow服务服务环境镜像一样简单，并将其指向模型： 使用Docker部署模型服务： 12345678$ docker pull tensorflow/serving$ docker run -p 8501:8501 --name tfserving_resnet \--mount type=bind,source=/tmp/resnet,target=/models/resnet \-e MODEL_NAME=resnet -t tensorflow/serving &amp;…… main.cc:327] Running ModelServer at 0.0.0.0:8500…… main.cc:337] Exporting HTTP/REST API at:localhost:8501 … 分解命令行参数，分别是： -p 8501:8501 ：将容器的端口8501（TF服务响应REST API请求）发布到主机的端口8501 --name tfserving_resnet ：给容器我们创建名称“tfserving_resnet”，以便我们稍后可以参考它 --mount type=bind,source=/tmp/resnet,target=/models/resnet ：在主机（/ models / resnet）上安装主机的本地目录（/ tmp / resnet），以便TF服务可以从容器内部读取模型。 -e MODEL_NAME=resnet ：Telling TensorFlow服务加载名为“resnet”的模型 -t tensorflow/serving ：根据服务镜像“tensorflow / serving”运行Docker容器 其中，8500端口对于TensorFlow Serving提供的gRPC端口，8501为REST API服务端口。上述命令输出为 123456789101112131415161718192019-03-04 02:52:26.610387: I tensorflow_serving/model_servers/server.cc:82] Building single TensorFlow model file config: model_name: resnet model_base_path: /models/resnet2019-03-04 02:52:26.618200: I tensorflow_serving/model_servers/server_core.cc:461] Adding/updating models.2019-03-04 02:52:26.618628: I tensorflow_serving/model_servers/server_core.cc:558] (Re-)adding model: resnet2019-03-04 02:52:26.745813: I tensorflow_serving/core/basic_manager.cc:739] Successfully reserved resources to load servable &#123;name: resnet version: 1538687457&#125;2019-03-04 02:52:26.745901: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version &#123;name: resnet version: 1538687457&#125;2019-03-04 02:52:26.745935: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version &#123;name: resnet version: 1538687457&#125;2019-03-04 02:52:26.747590: I external/org_tensorflow/tensorflow/contrib/session_bundle/bundle_shim.cc:363] Attempting to load native SavedModelBundle in bundle-shim from: /models/resnet/15386874572019-03-04 02:52:26.747705: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: /models/resnet/15386874572019-03-04 02:52:26.795363: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags &#123; serve &#125;2019-03-04 02:52:26.828614: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA2019-03-04 02:52:26.923902: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:162] Restoring SavedModel bundle.2019-03-04 02:52:28.098479: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:138] Running MainOp with key saved_model_main_op on SavedModel bundle.2019-03-04 02:52:28.144510: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:259] SavedModel load for tags &#123; serve &#125;; Status: success. Took 1396689 microseconds.2019-03-04 02:52:28.146646: I tensorflow_serving/servables/tensorflow/saved_model_warmup.cc:83] No warmup data file found at /models/resnet/1538687457/assets.extra/tf_serving_warmup_requests2019-03-04 02:52:28.168063: I tensorflow_serving/core/loader_harness.cc:86] Successfully loaded servable version &#123;name: resnet version: 1538687457&#125;2019-03-04 02:52:28.174902: I tensorflow_serving/model_servers/server.cc:286] Running gRPC ModelServer at 0.0.0.0:8500 ...[warn] getaddrinfo: address family for nodename not supported2019-03-04 02:52:28.186724: I tensorflow_serving/model_servers/server.cc:302] Exporting HTTP/REST API at:localhost:8501 ...[evhttp_server.cc : 237] RAW: Entering the event loop ... 我们可以看到，TensorFlow Serving使用1538687457作为模型的版本号。我们使用curl命令来查看一下启动的服务状态，也可以看到提供服务的模型版本以及模型状态。 12345678910111213$ curl http://localhost:8501/v1/models/resnet&#123; &quot;model_version_status&quot;: [ &#123; &quot;version&quot;: &quot;1538687457&quot;, &quot;state&quot;: &quot;AVAILABLE&quot;, &quot;status&quot;: &#123; &quot;error_code&quot;: &quot;OK&quot;, &quot;error_message&quot;: &quot;&quot; &#125; &#125; ]&#125; 查看模型输入输出很多时候我们需要查看模型的输出和输出参数的具体形式，TensorFlow提供了一个saved_model_cli命令来查看模型的输入和输出参数： 12345678910111213141516171819202122232425262728293031323334353637$ saved_model_cli show --dir /tmp/resnet/1538687457/ --allMetaGraphDef with tag-set: &apos;serve&apos; contains the following SignatureDefs:signature_def[&apos;predict&apos;]: The given SavedModel SignatureDef contains the following input(s): inputs[&apos;image_bytes&apos;] tensor_info: dtype: DT_STRING shape: (-1) name: input_tensor:0 The given SavedModel SignatureDef contains the following output(s): outputs[&apos;classes&apos;] tensor_info: dtype: DT_INT64 shape: (-1) name: ArgMax:0 outputs[&apos;probabilities&apos;] tensor_info: dtype: DT_FLOAT shape: (-1, 1001) name: softmax_tensor:0 Method name is: tensorflow/serving/predictsignature_def[&apos;serving_default&apos;]: The given SavedModel SignatureDef contains the following input(s): inputs[&apos;image_bytes&apos;] tensor_info: dtype: DT_STRING shape: (-1) name: input_tensor:0 The given SavedModel SignatureDef contains the following output(s): outputs[&apos;classes&apos;] tensor_info: dtype: DT_INT64 shape: (-1) name: ArgMax:0 outputs[&apos;probabilities&apos;] tensor_info: dtype: DT_FLOAT shape: (-1, 1001) name: softmax_tensor:0 Method name is: tensorflow/serving/predict 注意到signature_def，inputs的名称，类型和输出，这些参数在接下来的模型预测请求中需要。 使用模型接口预测：REST和gRPCTensorFlow Serving提供REST API和gRPC两种请求方式，接下来将具体这两种方式。 REST我们下载一个客户端脚本，这个脚本会下载一张猫的图片，同时使用这张图片来计算服务请求时间。 1$ curl -o /tmp/resnet/resnet_client.py https://raw.githubusercontent.com/tensorflow/serving/master/tensorflow_serving/example/resnet_client.py 以下脚本使用requests库来请求接口，使用图片的base64编码字符串作为请求内容，返回图片分类，并计算了平均处理时间。 123456789101112131415161718192021222324252627282930313233343536373839404142from __future__ import print_functionimport base64import requests# The server URL specifies the endpoint of your server running the ResNet# model with the name &quot;resnet&quot; and using the predict interface.SERVER_URL = &apos;http://localhost:8501/v1/models/resnet:predict&apos;# The image URL is the location of the image we should send to the serverIMAGE_URL = &apos;https://tensorflow.org/images/blogs/serving/cat.jpg&apos;def main(): # Download the image dl_request = requests.get(IMAGE_URL, stream=True) dl_request.raise_for_status() # Compose a JSON Predict request (send JPEG image in base64). jpeg_bytes = base64.b64encode(dl_request.content).decode(&apos;utf-8&apos;) predict_request = &apos;&#123;&quot;instances&quot; : [&#123;&quot;b64&quot;: &quot;%s&quot;&#125;]&#125;&apos; % jpeg_bytes # Send few requests to warm-up the model. for _ in range(3): response = requests.post(SERVER_URL, data=predict_request) response.raise_for_status() # Send few actual requests and report average latency. total_time = 0 num_requests = 10 for _ in range(num_requests): response = requests.post(SERVER_URL, data=predict_request) response.raise_for_status() total_time += response.elapsed.total_seconds() prediction = response.json()[&apos;predictions&apos;][0] print(&apos;Prediction class: &#123;&#125;, avg latency: &#123;&#125; ms&apos;.format( prediction[&apos;classes&apos;], (total_time*1000)/num_requests))if __name__ == &apos;__main__&apos;: main() 输出结果为 12$ python resnet_client.pyPrediction class: 286, avg latency: 210.12310000000002 ms gRPC让我们下载另一个客户端脚本，这个脚本使用gRPC作为服务，传入图片并获取输出结果。这个脚本需要安装tensorflow-serving-api这个库。 12$ curl -o /tmp/resnet/resnet_client_grpc.py https://raw.githubusercontent.com/tensorflow/serving/master/tensorflow_serving/example/resnet_client_grpc.py$ pip install tensorflow-serving-api 脚本内容： 123456789101112131415161718192021222324252627282930313233343536373839404142434445from __future__ import print_function# This is a placeholder for a Google-internal import.import grpcimport requestsimport tensorflow as tffrom tensorflow_serving.apis import predict_pb2from tensorflow_serving.apis import prediction_service_pb2_grpc# The image URL is the location of the image we should send to the serverIMAGE_URL = &apos;https://tensorflow.org/images/blogs/serving/cat.jpg&apos;tf.app.flags.DEFINE_string(&apos;server&apos;, &apos;localhost:8500&apos;, &apos;PredictionService host:port&apos;)tf.app.flags.DEFINE_string(&apos;image&apos;, &apos;&apos;, &apos;path to image in JPEG format&apos;)FLAGS = tf.app.flags.FLAGSdef main(_): if FLAGS.image: with open(FLAGS.image, &apos;rb&apos;) as f: data = f.read() else: # Download the image since we weren&apos;t given one dl_request = requests.get(IMAGE_URL, stream=True) dl_request.raise_for_status() data = dl_request.content channel = grpc.insecure_channel(FLAGS.server) stub = prediction_service_pb2_grpc.PredictionServiceStub(channel) # Send request # See prediction_service.proto for gRPC request/response details. request = predict_pb2.PredictRequest() request.model_spec.name = &apos;resnet&apos; request.model_spec.signature_name = &apos;serving_default&apos; request.inputs[&apos;image_bytes&apos;].CopyFrom( tf.contrib.util.make_tensor_proto(data, shape=[1])) result = stub.Predict(request, 10.0) # 10 secs timeout print(result)if __name__ == &apos;__main__&apos;: tf.app.run() 输出的结果可以看到图片的分类，概率和使用的模型信息： 12345678910111213141516171819202122232425262728293031323334353637383940414243$ python resnet_client_grpc.pyoutputs &#123; key: &quot;classes&quot; value &#123; dtype: DT_INT64 tensor_shape &#123; dim &#123; size: 1 &#125; &#125; int64_val: 286 &#125;&#125;outputs &#123; key: &quot;probabilities&quot; value &#123; dtype: DT_FLOAT tensor_shape &#123; dim &#123; size: 1 &#125; dim &#123; size: 1001 &#125; &#125; float_val: 2.4162832232832443e-06 float_val: 1.9012182974620373e-06 float_val: 2.7247710022493266e-05 float_val: 4.426385658007348e-07 ...(中间省略) float_val: 1.4636580090154894e-05 float_val: 5.812107133351674e-07 float_val: 6.599806511076167e-05 float_val: 0.0012952701654285192 &#125;&#125;model_spec &#123; name: &quot;resnet&quot; version &#123; value: 1538687457 &#125; signature_name: &quot;serving_default&quot;&#125; 性能通过编译优化的TensorFlow Serving二进制来提高性能TensorFlows serving有时会有输出如下的日志： 1Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA TensorFlow Serving已发布Docker镜像旨在尽可能多地使用CPU架构，因此省略了一些优化以最大限度地提高兼容性。如果你没有看到此消息，则你的二进制文件可能已针对你的CPU进行了优化。根据你的模型执行的操作，这些优化可能会对你的服务性能产生重大影响。幸运的是，编译优化的TensorFlow Serving二进制非常简单。官方已经提供了自动化脚本，分以下两部进行： 1234567# 1. 编译开发版本：首先，我们要构建TensorFlow服务的优化版本。最简单的方法是构建官方的Tensorflow服务开发环境Docker镜像。这具有为图像构建的系统自动生成优化的TensorFlow服务二进制文件的良好特性。为了区分我们创建的图像和官方图像，我们将$ USER /添加到镜像名称之前。让我们称这个开发镜像为$ USER / tensorflow-serving-devel$ docker build -t $USER/tensorflow-serving-devel -f Dockerfile.devel https://github.com/tensorflow/serving.git#:tensorflow_serving/tools/docker# 2. 生产新的镜像：构建TensorFlow服务开发映像可能需要一段时间，具体取决于计算机的速度。完成后，让我们使用优化的二进制文件构建一个新的服务图像，并将其命名为$ USER / tensorflow-serving：$ docker build -t $USER/tensorflow-serving --build-arg TF_SERVING_BUILD_IMAGE=$USER/tensorflow-serving-devel https://github.com/tensorflow/serving.git#:tensorflow_serving/tools/docker 现在我们有了新的服务图像，让我们再次启动服务器：: 1234$ docker kill tfserving_resnet$ docker run -p 8501:8501 --name tfserving_resnet \ --mount type=bind,source=/tmp/resnet,target=/models/resnet \ -e MODEL_NAME=resnet -t $USER/tensorflow-serving &amp; 最后运行我们的客户端程序： 12$ python /tmp/resnet/resnet_client.pyPrediction class: 282, avg latency: 84.8849 ms 在我们的机器上，我们看到使用我们的原生优化二进制文件，每次预测平均加速超过100毫秒（119％）。根据您的机器（和型号），您可能会看到不同的结果。 最后，结束TensorFlow Serving容器： 1$ docker kill tfserving_resnet 参考 Serving ML Quickly with TensorFlow Serving and Docker Train and serve a TensorFlow model with TensorFlow Serving]]></content>
      <categories>
        <category>Tensorflow</category>
      </categories>
      <tags>
        <tag>Deep learning</tag>
        <tag>科研 - 学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tensorflow打印tensor值]]></title>
    <url>%2F2019%2F03%2F10%2Ftensor_05_print_tensor%2F</url>
    <content type="text"><![CDATA[tensorflow打印tensor值在tensorflow中，打印一个tensor值必须在在一个会话Session中进行，并且可以使用Session.run()或Tensor.eval()进行打印x的值： 使用 print(sess.run(x)) 使用print(x.eval()) Session.run和Tensor.eval1.联系：如果t是一个tf.Tensor对象，则tf.Tensor.eval是tf.Session.run的缩写（其中 的tf.Sesstion是tf.get_default_session)也就是： 1tensor.eval()=tf.get_default_session().run(tensor) 2.区别：这两个中间最主要的区别就在于 使用sess.run()能在同一步获取多个tensor中的值。 123456789import tensorflow as tfx = tf.ones(shape=[2, 3], dtype=tf.int32,name=&apos;x&apos;)y= tf.zeros(shape=[2, 3], dtype=tf.float32,name=&apos;y&apos;)with tf.Session() as sess: print(sess.run([x，y])) #一次能打印两个 print(x.eval()) print(y.eval()) #一次只能打印一个]]></content>
      <categories>
        <category>Tensorflow</category>
      </categories>
      <tags>
        <tag>Deep learning</tag>
        <tag>科研 - 学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[股票api接口]]></title>
    <url>%2F2019%2F03%2F09%2FJava_04_%20stockAPI%2F</url>
    <content type="text"><![CDATA[股票数据接口使用最近的作业需要用到股票数据接口，在此记录一下。 1. Tushare股票数据Tushare是一个免费、开源的python财经数据接口包。主要实现对股票等金融数据从数据采集、清洗加工 到 数据存储的过程，能够为金融分析人员提供快速、整洁、和多样的便于分析的数据，为他们在数据获取方面极大地减轻工作量，使他们更加专注于策略和模型的研究与实现上。考虑到Python pandas包在金融量化分析中体现出的优势，Tushare返回的绝大部分的数据格式都是pandas DataFrame类型，非常便于用pandas/NumPy/Matplotlib进行数据分析和可视化。 获取实时行情数据get_today_all()返回值说明： code：代码 name:名称 changepercent:涨跌幅 trade:现价 open:开盘价 high:最高价 low:最低价 settlement:昨日收盘价 volume:成交量 turnoverratio:换手率 amount:成交量 per:市盈率 pb:市净率 mktcap:总市值 nmc:流通市值 12import tushare as tsts.get_today_all() 2. 新浪股票数据接口以大秦铁路（股票代码：601006）为例，如果要获取它的最新行情，只需访问新浪的股票数据接口：http://hq.sinajs.cn/list=sh601006这个url会返回一串文本，例如：var hq_str_sh601006=”大秦铁路, 27.55, 27.25, 26.91, 27.55, 26.20, 26.91, 26.92,22114263, 589824680, 4695, 26.91, 57590, 26.90, 14700, 26.89, 14300,26.88, 15100, 26.87, 3100, 26.92, 8900, 26.93, 14230, 26.94, 25150, 26.95, 15220, 26.96, 2008-01-11, 15:05:32”;这个字符串由许多数据拼接在一起，不同含义的数据用逗号隔开了，顺序号从0开始。 0：”大秦铁路”，股票名字； 1：”27.55″，今日开盘价； 2：”27.25″，昨日收盘价； 3：”26.91″，当前价格； 4：”27.55″，今日最高价； 5：”26.20″，今日最低价； 6：”26.91″，竞买价，即“买一”报价； 7：”26.92″，竞卖价，即“卖一”报价； 8：”22114263″，成交的股票数，由于股票交易以一百股为基本单位，所以在使用时，通常把该值除以一百； 9：”589824680″，成交金额，单位为“元”，为了一目了然，通常以“万元”为成交金额的单位，所以通常把该值除以一万； 10：”4695″，“买一”申请4695股，即47手； 11：”26.91″，“买一”报价； 12：”57590″，“买二” 13：”26.90″，“买二” 14：”14700″，“买三” 15：”26.89″，“买三” 16：”14300″，“买四” 17：”26.88″，“买四” 18：”15100″，“买五” 19：”26.87″，“买五” 20：”3100″，“卖一”申报3100股，即31手； 21：”26.92″，“卖一”报价 (22, 23), (24, 25), (26,27), (28, 29)分别为“卖二”至“卖四的情况” 30：”2008-01-11″，日期； 31：”15:05:32″，时间； JavaScript应用例子:123456script type=&quot;text/javascript&quot; src=&quot;http://hq.sinajs.cn/list=sh601006&quot; charset=&quot;gb2312&quot;&gt;/script&gt; /javascript&quot;&gt; var elements=hq_str_sh601006.split(&quot;,&quot;); document.write(&quot;current price:&quot;+elements[3]); 这段代码输出大秦铁路（股票代码：601006）的当前股价 current price:14.20 如果同时查询多个股票，那么在URL最后加上一个逗号，再加上股票代码就可以了；比如你要一次查询大秦铁路（601006）和大同煤业（601001）的行情，就这样使用URL： http://hq.sinajs.cn/list=sh601003,sh601001 查询大盘指数，比如查询上证综合指数（000001）： http://hq.sinajs.cn/list=s_sh000001 服务器返回的数据为： var hq_str_s_sh000001=”上证指数,3094.668,-128.073,-3.97,436653,5458126”; 数据含义分别为：指数名称，当前点数，当前价格，涨跌率，成交量（手），成交额（万元）； 查询深圳成指数： http://hq.sinajs.cn/list=s_sz399001 股票趋势对于股票的K线图，日线图等的获取可以通过请求http://image.sinajs.cn/…./…/*.gif此URL获取，其中x代表股票代码，详见如下：分时线的查询： http://image.sinajs.cn/newchart/min/n/sh000001.gif 日K线查询： http://image.sinajs.cn/newchart/daily/n/sh000001.gif 周K线查询： http://image.sinajs.cn/newchart/weekly/n/sh000001.gif 月K线查询： http://image.sinajs.cn/newchart/monthly/n/sh000001.gif]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java - 学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[雅虎财经API]]></title>
    <url>%2F2019%2F03%2F09%2FJava_05_%20YahooAPI%2F</url>
    <content type="text"><![CDATA[Yahoo财经频道获取实时股票数据的API。 实时数据请求请求地址1http://finance.yahoo.com/d/quotes.csv?s=&lt;股票名称&gt;&amp;f=&lt;数据列选项&gt; 参数 s — 表示股票名称，多个股票之间使用英文加号分隔，如“XOM+BBDb.TO+JNJ+MSFT”，罗列了四个公司的股票：XOM, BBDb.TO, JNJ, MSFT。 f — 表示返回数据列，如“snd1l1yr”。更详细的参见附录。 示例1http://finance.yahoo.com/d/quotes.csv?s=XOM+BBDb.TO+JNJ+MSFT&amp;f=snd1l1yr 返回： 1234&quot;XOM&quot;,&quot;Exxon Mobil Corpo&quot;,&quot;10/7/2010&quot;,63.85,2.69,12.33&quot;BBD-B.TO&quot;,&quot;BOMBARDIER INC., &quot;,&quot;10/7/2010&quot;,5.27,1.90,N/A&quot;JNJ&quot;,&quot;Johnson &amp; Johnson&quot;,&quot;10/7/2010&quot;,63.22,3.26,13.06&quot;MSFT&quot;,&quot;Microsoft Corpora&quot;,&quot;10/7/2010&quot;,24.53,2.12,11.68 历史数据请求上述是获取当前最新的数据，若需要获得历史数据，请使用下面API。 请求地址1http://ichart.yahoo.com/table.csv?s=&lt;string&gt;&amp;a=&lt;int&gt;&amp;b=&lt;int&gt;&amp;c=&lt;int&gt;&amp;d=&lt;int&gt;&amp;e=&lt;int&gt;&amp;f=&lt;int&gt;&amp;g=d&amp;ignore=.csv 参数s — 股票名称a — 起始时间，月b — 起始时间，日c — 起始时间，年d — 结束时间，月e — 结束时间，日f — 结束时间，年g — 时间周期。Example: g=w, 表示周期是‘周’。d-&gt;‘日’(day), w-&gt;‘周’(week)，m-&gt;‘月’(mouth)，v-&gt;‘dividends only’一定注意月份参数，其值比真实数据-1。如需要9月数据，则写为08。 示例查询浦发银行2010.09.25 – 2010.10.8之间日线数据 1http://ichart.yahoo.com/table.csv?s=600000.SS&amp;a=08&amp;b=25&amp;c=2010&amp;d=09&amp;e=8&amp;f=2010&amp;g=d 返回12345Date,Open,High,Low,Close,Volume,Adj Close2010-09-30,12.37,12.99,12.32,12.95,76420500,12.952010-09-29,12.20,12.69,12.12,12.48,79916400,12.482010-09-28,12.92,12.92,12.57,12.58,63988100,12.582010-09-27,13.00,13.02,12.89,12.94,43203600,12.94 深沪股票代码yahoo的api是国际性的，是支持国内沪深股市的，但代码稍微变动一下，如浦发银行的代号是：600000.SS。规则是：上海市场末尾加.ss，深圳市场末尾加.sz。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java - 学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow savedmodel使用]]></title>
    <url>%2F2019%2F03%2F05%2Ftensor_03_savedModel%2F</url>
    <content type="text"><![CDATA[一.Saved Model模块介绍saved_model模块主要用于TensorFlow Serving。TF Serving是一个将训练好的模型部署至生产环境的系统，主要的优点在于可以保持Server端与API不变的情况下，部署新的算法或进行试验，同时还有很高的性能。 仅用Saver来保存/载入变量。这个方法显然不行，仅保存变量就必须在inference的时候重新定义Graph(定义模型)，这样不同的模型代码肯定要修改。即使同一种模型，参数变化了，也需要在代码中有所体现，至少需要一个配置文件来同步，这样就很繁琐了。 使用tf.train.import_meta_graph导入graph信息并创建Saver， 再使用Saver restore变量。相比第一种，不需要重新定义模型，但是为了从graph中找到输入输出的tensor，还是得用graph.get_tensor_by_name()来获取，也就是还需要知道在定义模型阶段所赋予这些tensor的名字。如果创建各模型的代码都是同一个人完成的，还相对好控制，强制这些输入输出的命名都一致即可。如果是不同的开发者，要在创建模型阶段就强制tensor的命名一致就比较困难了。这样就不得不再维护一个配置文件，将需要获取的tensor名称写入，然后从配置文件中读取该参数。 1.利用tf.train.Saver()保存和加载模型123456789&quot;&quot;&quot;保存模型和变量&quot;&quot;&quot;v1 = tf.Variable([0], name=&apos;v1&apos;)v2 = tf.Variable([0], name=&apos;v2&apos;)saver = tf.train.Saver() # 1. 初始化saverwith tf.Session() as sess: sess.run(tf.global_variables_initializer()) saver.save(sess, &apos;ckp&apos;) # 2. 保存模型和变量 1234&quot;&quot;&quot;恢复模型和变量&quot;&quot;&quot;with tf.Session() as sess: saver = tf.import_meta_graph(&apos;ckp.meta&apos;) # 3. 加载模型 saver.restore(sess, &apos;ckp&apos;) # 4. 加载变量 2.saved_model 保存/载入模型保存 123builder = tf.saved_model.builder.SavedModelBuilder(saved_model_dir)builder.add_meta_graph_and_variables(sess, [&apos;tag_string&apos;])builder.save() 首先构造SavedModelBuilder对象，初始化方法只需要传入用于保存模型的目录名，目录不用预先创建。 add_meta_graph_and_variables方法导入graph的信息以及变量，这个方法假设变量都已经初始化好了，对于每个SavedModelBuilder这个方法一定要执行一次用于导入第一个meta graph。 第一个参数传入当前的session，包含了graph的结构与所有变量。 第二个参数是给当前需要保存的meta graph一个标签，标签名可以自定义，在之后载入模型的时候，需要根据这个标签名去查找对应的MetaGraphDef，找不到就会报如RuntimeError: MetaGraphDef associated with tags &#39;foo&#39; could not be found in SavedModel这样的错。标签也可以选用系统定义好的参数，如tf.saved_model.tag_constants.SERVING与tf.saved_model.tag_constants.TRAINING。 save方法就是将模型序列化到指定目录底下。 保存好以后到saved_model_dir目录下，会有一个saved_model.pb文件以及variables文件夹。顾名思义，variables保存所有变量，saved_model.pb用于保存模型结构等信息。 载入 123# 使用`tf.saved_model.loader.load`方法就可以载入模型。如meta_graph_def = tf.saved_model.loader.load(sess, [&apos;tag_string&apos;], saved_model_dir) 第一个参数就是当前的session，第二个参数是在保存的时候定义的meta graph的标签，标签一致才能找到对应的meta graph。第三个参数就是模型保存的目录。 load完以后，也是从sess对应的graph中获取需要的tensor来inference。如 123456x = sess.graph.get_tensor_by_name(&apos;input_x:0&apos;)y = sess.graph.get_tensor_by_name(&apos;predict_y:0&apos;) # 实际的待inference的样本_x = ... sess.run(y, feed_dict=&#123;x: _x&#125;) 3.使用SignatureDef保存 SignatureDef定义了一些协议，对我们所需的信息进行封装，我们根据这套协议来获取信息，从而实现创建与使用模型的解耦。SignatureDef，将输入输出tensor的信息都进行了封装，并且给他们一个自定义的别名，所以在构建模型的阶段，可以随便给tensor命名，只要在保存训练好的模型的时候，在SignatureDef中给出统一的别名即可。 TensorFlow的关于这部分的例子中用到了不少signature_constants，这些constants的用处主要是提供了一个方便统一的命名。假设定义模型输入的别名为“input_x”，输出的别名为“output” ，使用SignatureDef的代码如下 123456789101112builder = tf.saved_model.builder.SavedModelBuilder(saved_model_dir)# x 为输入tensor, keep_prob为dropout的prob tensor inputs = &#123;&apos;input_x&apos;: tf.saved_model.utils.build_tensor_info(x), &apos;keep_prob&apos;: tf.saved_model.utils.build_tensor_info(keep_prob)&#125; # y 为最终需要的输出结果tensor outputs = &#123;&apos;output&apos; : tf.saved_model.utils.build_tensor_info(y)&#125; signature = tf.saved_model.signature_def_utils.build_signature_def(inputs, outputs, &apos;test_sig_name&apos;) builder.add_meta_graph_and_variables(sess, [&apos;test_saved_model&apos;], &#123;&apos;test_signature&apos;:signature&#125;)builder.save() 上述inputs增加一个keep_prob是为了说明inputs可以有多个， build_tensor_info方法将tensor相关的信息序列化为TensorInfo protocol buffer。 inputs，outputs都是dict，key是我们约定的输入输出别名，value就是对具体tensor包装得到的TensorInfo。 然后使用build_signature_def方法构建SignatureDef，第三个参数method_name暂时先随便给一个。 创建好的SignatureDef是用在add_meta_graph_and_variables的第三个参数signature_def_map中，但不是直接传入SignatureDef对象。事实上signature_def_map接收的是一个dict，key是我们自己命名的signature名称，value是SignatureDef对象。 载入 1234567891011121314151617181920## 略去构建sess的代码 signature_key = &apos;test_signature&apos;input_key = &apos;input_x&apos;output_key = &apos;output&apos; meta_graph_def = tf.saved_model.loader.load(sess, [&apos;test_saved_model&apos;], saved_model_dir)# 从meta_graph_def中取出SignatureDef对象signature = meta_graph_def.signature_def # 从signature中找出具体输入输出的tensor name x_tensor_name = signature[signature_key].inputs[input_key].namey_tensor_name = signature[signature_key].outputs[output_key].name # 获取tensor 并inferencex = sess.graph.get_tensor_by_name(x_tensor_name)y = sess.graph.get_tensor_by_name(y_tensor_name) # _x 实际输入待inference的datasess.run(y, feed_dict=&#123;x:_x&#125;) 我们只需要约定好输入输出的别名，在保存模型的时候使用这些别名创建signature，输入输出tensor的具体名称已经完全隐藏，这就实现创建模型与使用模型的解耦。]]></content>
      <categories>
        <category>Tensorflow</category>
      </categories>
      <tags>
        <tag>Deep learning</tag>
        <tag>科研 - 学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[static静态关键字和代码块]]></title>
    <url>%2F2019%2F02%2F20%2FJava_03_%20%E4%BB%A3%E7%A0%81%E5%9D%97%20%2F</url>
    <content type="text"><![CDATA[static静态关键字1.静态特点A: 被static修饰的成员变量属于类，不属于这个类的某个对象。（即多个对象共享同一个static成员变量） B: 被static修饰的成员可以通过类名直接访问 访问静态成员的格式: 123类名.静态成员变量名类名.静态成员方法名(参数) C: 静态的加载优先于对象,随着类的加载而加载 2.静态注意事项A:静态成员只能直接访问静态成员 B:非静态成员既可以访问非静态成员也可以访问静态成员 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/* * static的注意事项： * 静态方法： * 可以调用静态的成员变量 * 可以调用静态的成员方法 * 不可以调用非静态成员变量 * 不可以调用非静态成员方法 * 静态方法只能调用静态的成员 * 非静态方法： * 可以调用静态的成员变量 * 可以调用静态的成员方法 * 可以调用非静态的成员变量 * 可以调用非静态的成员方法 * * 静态的方法中是否有this这个对象？没有 */public class StaticDemo2 &#123; public static void main(String[] args) &#123; Student.graduateFrom = "传智学院"; Student.study(); &#125;&#125;class Student &#123; String name; int age; static String graduateFrom;//毕业院校 public static void study() &#123; ///System.out.println(graduateFrom); //sleep(); //System.out.println(name); //eat(); &#125; public static void sleep() &#123; System.out.println("sleep"); &#125; public void eat() &#123; System.out.println("eat"); System.out.println(graduateFrom); sleep(); &#125; &#125; 3. 静态变量 静态变量：又称为类变量，也就是说这个变量属于类的，类所有的实例都共享静态变量，可以直接通过类名来访问它。静态变量在内存中只存在一份。 实例变量：每创建一个实例就会产生一个实例变量，它与该实例同生共死。 1234567891011121314151617181920212223242526272829303132333435/* * static:是一个关键字，用于修饰成员变量和成员方法 * static的特点： * 被所有的对象所共享 * 可以使用类名调用 * 静态的加载优先于对象 * 随着类的加载而加载 * */public class StaticDemo &#123; public static void main(String[] args) &#123; Person.graduateFrom = "传智学院"; Person p = new Person(); p.name = "小苍同学"; p.age = 18; //p.graduateFrom = "传智学院"; p.speak(); Person p2 = new Person(); p2.name = "小波同学"; p2.age = 20; //p2.graduateFrom = "传智学院"; p2.speak(); &#125;&#125;class Person &#123; String name; int age; static String graduateFrom;//毕业院校 public void speak() &#123; System.out.println(name + "---" + graduateFrom); &#125;&#125; 4. 静态方法静态方法在类加载的时候就存在了，它不依赖于任何实例。所以静态方法必须有实现，也就是说它不能是抽象方法。 12345public abstract class A &#123; public static void func1()&#123; &#125; // public abstract static void func2(); // 静态方法不能是抽象方法&#125; 只能访问所属类的静态字段和静态方法，方法中不能有 this 和 super 关键字。 1234567891011public class A &#123; private static int x; private int y; public static void func1()&#123; int a = x; // int b = y; // 没有创建对象，无法使用成员变量 // int b = this.y; // 静态变量不能使用this &#125;&#125; 5. 静态代码块静态语句块在类初始化时运行一次。 12345678910public class A &#123; static &#123; System.out.println("123"); &#125; public static void main(String[] args) &#123; A a1 = new A(); A a2 = new A(); &#125;&#125; // 输出123 6. 静态内部类非静态内部类依赖于外部类的实例，而静态内部类不需要。 123456789101112131415public class OuterClass &#123; class InnerClass &#123; &#125; static class StaticInnerClass &#123; &#125; public static void main(String[] args) &#123; // InnerClass innerClass = new InnerClass(); // 'OuterClass.this' cannot be referenced from a static context OuterClass outerClass = new OuterClass(); InnerClass innerClass = outerClass.new InnerClass(); StaticInnerClass staticInnerClass = new StaticInnerClass(); &#125;&#125; 静态内部类不能访问外部类的非静态的变量和方法。 7. 静态导包在使用静态变量和方法时不用再指明 ClassName，从而简化代码，但可读性大大降低。 1import static com.xxx.ClassName.* 8.静态的优缺点A:静态优点: 对对象的共享数据提供单独空间的存储，节省空间，没有必要每一个对象都存储一份 可以直接被类名调用,不用在堆内存创建对象 静态成员可以通过类名直接访问,相对创建对象访问成员方便 B:静态弊端: 访问出现局限性。（静态虽好，但只能访问静态） 9.初始化顺序静态变量和静态语句块优先于实例变量和普通语句块，静态变量和静态语句块的初始化顺序取决于它们在代码中的顺序。 1public static String staticField = "静态变量"; 123static &#123; System.out.println("静态语句块");&#125; 1public String field = "实例变量"; 123&#123; System.out.println("普通语句块");&#125; 最后才是构造函数的初始化。 123public InitialOrderTest() &#123; System.out.println("构造函数");&#125; 存在继承的情况下，初始化顺序为： 父类（静态变量、静态语句块） 子类（静态变量、静态语句块） 父类（实例变量、普通语句块） 父类（构造函数） 子类（实例变量、普通语句块） 子类（构造函数）]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java - 学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[static静态关键字和代码块]]></title>
    <url>%2F2019%2F02%2F20%2FJava_02_%20static%E5%92%8C%E4%BB%A3%E7%A0%81%E5%9D%97%2F</url>
    <content type="text"><![CDATA[static静态关键字1.静态特点A: 被static修饰的成员变量属于类，不属于这个类的某个对象。（即多个对象共享同一个static成员变量） B: 被static修饰的成员可以通过类名直接访问 访问静态成员的格式: 123类名.静态成员变量名类名.静态成员方法名(参数) C: 静态的加载优先于对象,随着类的加载而加载 2.静态注意事项A:静态成员只能直接访问静态成员 B:非静态成员既可以访问非静态成员也可以访问静态成员 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/* * static的注意事项： * 静态方法： * 可以调用静态的成员变量 * 可以调用静态的成员方法 * 不可以调用非静态成员变量 * 不可以调用非静态成员方法 * 静态方法只能调用静态的成员 * 非静态方法： * 可以调用静态的成员变量 * 可以调用静态的成员方法 * 可以调用非静态的成员变量 * 可以调用非静态的成员方法 * * 静态的方法中是否有this这个对象？没有 */public class StaticDemo2 &#123; public static void main(String[] args) &#123; Student.graduateFrom = "传智学院"; Student.study(); &#125;&#125;class Student &#123; String name; int age; static String graduateFrom;//毕业院校 public static void study() &#123; ///System.out.println(graduateFrom); //sleep(); //System.out.println(name); //eat(); &#125; public static void sleep() &#123; System.out.println("sleep"); &#125; public void eat() &#123; System.out.println("eat"); System.out.println(graduateFrom); sleep(); &#125; &#125; 3. 静态变量 静态变量：又称为类变量，也就是说这个变量属于类的，类所有的实例都共享静态变量，可以直接通过类名来访问它。静态变量在内存中只存在一份。 实例变量：每创建一个实例就会产生一个实例变量，它与该实例同生共死。 1234567891011121314151617181920212223242526272829303132333435/* * static:是一个关键字，用于修饰成员变量和成员方法 * static的特点： * 被所有的对象所共享 * 可以使用类名调用 * 静态的加载优先于对象 * 随着类的加载而加载 * */public class StaticDemo &#123; public static void main(String[] args) &#123; Person.graduateFrom = "传智学院"; Person p = new Person(); p.name = "小苍同学"; p.age = 18; //p.graduateFrom = "传智学院"; p.speak(); Person p2 = new Person(); p2.name = "小波同学"; p2.age = 20; //p2.graduateFrom = "传智学院"; p2.speak(); &#125;&#125;class Person &#123; String name; int age; static String graduateFrom;//毕业院校 public void speak() &#123; System.out.println(name + "---" + graduateFrom); &#125;&#125; 4. 静态方法静态方法在类加载的时候就存在了，它不依赖于任何实例。所以静态方法必须有实现，也就是说它不能是抽象方法。 12345public abstract class A &#123; public static void func1()&#123; &#125; // public abstract static void func2(); // 静态方法不能是抽象方法&#125; 只能访问所属类的静态字段和静态方法，方法中不能有 this 和 super 关键字。 1234567891011public class A &#123; private static int x; private int y; public static void func1()&#123; int a = x; // int b = y; // 没有创建对象，无法使用成员变量 // int b = this.y; // 静态变量不能使用this &#125;&#125; 5. 静态代码块静态语句块在类初始化时运行一次。 12345678910public class A &#123; static &#123; System.out.println("123"); &#125; public static void main(String[] args) &#123; A a1 = new A(); A a2 = new A(); &#125;&#125; // 输出123 6. 静态内部类非静态内部类依赖于外部类的实例，而静态内部类不需要。 123456789101112131415public class OuterClass &#123; class InnerClass &#123; &#125; static class StaticInnerClass &#123; &#125; public static void main(String[] args) &#123; // InnerClass innerClass = new InnerClass(); // 'OuterClass.this' cannot be referenced from a static context OuterClass outerClass = new OuterClass(); InnerClass innerClass = outerClass.new InnerClass(); StaticInnerClass staticInnerClass = new StaticInnerClass(); &#125;&#125; 静态内部类不能访问外部类的非静态的变量和方法。 7. 静态导包在使用静态变量和方法时不用再指明 ClassName，从而简化代码，但可读性大大降低。 1import static com.xxx.ClassName.* 8.静态的优缺点A:静态优点: 对对象的共享数据提供单独空间的存储，节省空间，没有必要每一个对象都存储一份 可以直接被类名调用,不用在堆内存创建对象 静态成员可以通过类名直接访问,相对创建对象访问成员方便 B:静态弊端: 访问出现局限性。（静态虽好，但只能访问静态） 9.初始化顺序静态变量和静态语句块优先于实例变量和普通语句块，静态变量和静态语句块的初始化顺序取决于它们在代码中的顺序。 1public static String staticField = "静态变量"; 123static &#123; System.out.println("静态语句块");&#125; 1public String field = "实例变量"; 123&#123; System.out.println("普通语句块");&#125; 最后才是构造函数的初始化。 123public InitialOrderTest() &#123; System.out.println("构造函数");&#125; 存在继承的情况下，初始化顺序为： 父类（静态变量、静态语句块） 子类（静态变量、静态语句块） 父类（实例变量、普通语句块） 父类（构造函数） 子类（实例变量、普通语句块） 子类（构造函数）]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java - 学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[static静态关键字和代码块]]></title>
    <url>%2F2019%2F02%2F20%2FJava_02_%20static%2F</url>
    <content type="text"><![CDATA[static静态关键字1.静态特点A: 被static修饰的成员变量属于类，不属于这个类的某个对象。（即多个对象共享同一个static成员变量） B: 被static修饰的成员可以通过类名直接访问 访问静态成员的格式: 123类名.静态成员变量名类名.静态成员方法名(参数) C: 静态的加载优先于对象,随着类的加载而加载 2.静态注意事项A:静态成员只能直接访问静态成员 B:非静态成员既可以访问非静态成员也可以访问静态成员 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/* * static的注意事项： * 静态方法： * 可以调用静态的成员变量 * 可以调用静态的成员方法 * 不可以调用非静态成员变量 * 不可以调用非静态成员方法 * 静态方法只能调用静态的成员 * 非静态方法： * 可以调用静态的成员变量 * 可以调用静态的成员方法 * 可以调用非静态的成员变量 * 可以调用非静态的成员方法 * * 静态的方法中是否有this这个对象？没有 */public class StaticDemo2 &#123; public static void main(String[] args) &#123; Student.graduateFrom = "传智学院"; Student.study(); &#125;&#125;class Student &#123; String name; int age; static String graduateFrom;//毕业院校 public static void study() &#123; ///System.out.println(graduateFrom); //sleep(); //System.out.println(name); //eat(); &#125; public static void sleep() &#123; System.out.println("sleep"); &#125; public void eat() &#123; System.out.println("eat"); System.out.println(graduateFrom); sleep(); &#125; &#125; 3. 静态变量 静态变量：又称为类变量，也就是说这个变量属于类的，类所有的实例都共享静态变量，可以直接通过类名来访问它。静态变量在内存中只存在一份。 实例变量：每创建一个实例就会产生一个实例变量，它与该实例同生共死。 1234567891011121314151617181920212223242526272829303132333435/* * static:是一个关键字，用于修饰成员变量和成员方法 * static的特点： * 被所有的对象所共享 * 可以使用类名调用 * 静态的加载优先于对象 * 随着类的加载而加载 * */public class StaticDemo &#123; public static void main(String[] args) &#123; Person.graduateFrom = "传智学院"; Person p = new Person(); p.name = "小苍同学"; p.age = 18; //p.graduateFrom = "传智学院"; p.speak(); Person p2 = new Person(); p2.name = "小波同学"; p2.age = 20; //p2.graduateFrom = "传智学院"; p2.speak(); &#125;&#125;class Person &#123; String name; int age; static String graduateFrom;//毕业院校 public void speak() &#123; System.out.println(name + "---" + graduateFrom); &#125;&#125; 4. 静态方法静态方法在类加载的时候就存在了，它不依赖于任何实例。所以静态方法必须有实现，也就是说它不能是抽象方法。 12345public abstract class A &#123; public static void func1()&#123; &#125; // public abstract static void func2(); // 静态方法不能是抽象方法&#125; 只能访问所属类的静态字段和静态方法，方法中不能有 this 和 super 关键字。 1234567891011public class A &#123; private static int x; private int y; public static void func1()&#123; int a = x; // int b = y; // 没有创建对象，无法使用成员变量 // int b = this.y; // 静态变量不能使用this &#125;&#125; 5. 静态代码块静态语句块在类初始化时运行一次。 12345678910public class A &#123; static &#123; System.out.println("123"); &#125; public static void main(String[] args) &#123; A a1 = new A(); A a2 = new A(); &#125;&#125; // 输出123 6. 静态内部类非静态内部类依赖于外部类的实例，而静态内部类不需要。 123456789101112131415public class OuterClass &#123; class InnerClass &#123; &#125; static class StaticInnerClass &#123; &#125; public static void main(String[] args) &#123; // InnerClass innerClass = new InnerClass(); // 'OuterClass.this' cannot be referenced from a static context OuterClass outerClass = new OuterClass(); InnerClass innerClass = outerClass.new InnerClass(); StaticInnerClass staticInnerClass = new StaticInnerClass(); &#125;&#125; 静态内部类不能访问外部类的非静态的变量和方法。 7. 静态导包在使用静态变量和方法时不用再指明 ClassName，从而简化代码，但可读性大大降低。 1import static com.xxx.ClassName.* 8.静态的优缺点A:静态优点: 对对象的共享数据提供单独空间的存储，节省空间，没有必要每一个对象都存储一份 可以直接被类名调用,不用在堆内存创建对象 静态成员可以通过类名直接访问,相对创建对象访问成员方便 B:静态弊端: 访问出现局限性。（静态虽好，但只能访问静态） 9.初始化顺序静态变量和静态语句块优先于实例变量和普通语句块，静态变量和静态语句块的初始化顺序取决于它们在代码中的顺序。 1public static String staticField = "静态变量"; 123static &#123; System.out.println("静态语句块");&#125; 1public String field = "实例变量"; 123&#123; System.out.println("普通语句块");&#125; 最后才是构造函数的初始化。 123public InitialOrderTest() &#123; System.out.println("构造函数");&#125; 存在继承的情况下，初始化顺序为： 父类（静态变量、静态语句块） 子类（静态变量、静态语句块） 父类（实例变量、普通语句块） 父类（构造函数） 子类（实例变量、普通语句块） 子类（构造函数）]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java - 学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序员代码面试指南]]></title>
    <url>%2F2019%2F02%2F18%2FReviewGuide_01_getMin%2F</url>
    <content type="text"><![CDATA[《程序员代码面试指南 IT名企算法与数据结构题目最优解》题解1.题目01 2.题解思路 方法一： 如原书思路，设置两个栈stackData和stackMin，当前数据为data，先压入stackData，然后判断stackMin是否为空。 如果为空，data压入stackMin中，如果不空，则比较data和stackMin栈顶元素。如果data小则入栈，否则stackMin的栈顶元素重复入栈。如图： 方法二： 只用一个栈实现，在栈的类中添加返回最小值的方法。使用ArrayList来存储栈内元素，然后便利ArrayList返回栈中最小值。 3.代码实现方法一： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package com.ITexercise;import java.util.ArrayList;public class MyStack &#123; public static void main(String[] args) &#123; ArrayList&lt;Integer&gt; array = new ArrayList&lt;Integer&gt;(); MyStack stack =new MyStack(); stack.push(array,1); stack.push(array, 2); stack.push(array, 5); stack.push(array, 6); printStack(array); System.out.println(&quot;--------------&quot;); stack.pop(array); printStack(array); System.out.println(&quot;--------------&quot;); System.out.println(stack.getMin(array)); &#125; public static void printStack(ArrayList&lt;Integer&gt; array) &#123; for (int i = 0; i &lt; array.size(); i++) &#123; System.out.print(array.get(i)+&quot;\t&quot;); &#125; &#125; public static boolean pop(ArrayList&lt;Integer&gt; array) &#123; if (array.size() == 0) &#123; return false; &#125; else &#123; array.remove(array.size() - 1); return true; &#125; &#125; public static boolean push(ArrayList&lt;Integer&gt; array, int data) &#123; array.add(data); return true; &#125; public static int getMin(ArrayList&lt;Integer&gt; array) &#123; int min = array.get(0); for (int i = 0; i &lt; array.size(); i++) &#123; if (array.get(i) &lt; min) &#123; min = array.get(i); &#125; &#125; return min; &#125;&#125; 方法二： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.ITexercise;import java.util.Stack;import javax.management.RuntimeErrorException;public class MyStack2 &#123; private Stack&lt;Integer&gt; stackData; private Stack&lt;Integer&gt; stackMin; public MyStack2() &#123; this.stackData =new Stack&lt;Integer&gt;(); this.stackMin = new Stack&lt;Integer&gt;(); &#125; public void push(int data) &#123; if(this.stackMin.isEmpty()) &#123; this.stackMin.push(data); &#125; else if (data &lt; this.stackMin.pop()) &#123; this.stackMin.push(data); &#125; else &#123; this.stackMin.push(this.stackMin.pop()); &#125; stackData.push(data); &#125; public int pop() &#123; if(this.stackData.isEmpty()) &#123; throw new RuntimeException(&quot;stack is empty&quot;); &#125; else &#123; this.stackMin.pop(); return this.stackData.pop(); &#125; &#125; public int getMin() &#123; if(this.stackData.isEmpty()) &#123; throw new RuntimeException(&quot;stack is empty&quot;); &#125; return this.stackMin.peek(); &#125; &#125; 4.分析方法一时间复杂度为O（1），空间复杂度为O（n） 方法二getMin（）时间复杂度为O（n），空间复杂度为O（n）]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>Java - 面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Eclipse常用操作]]></title>
    <url>%2F2019%2F02%2F17%2Fjava_01_Eclipse%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[Eclipse常用操作1.Eclipse基本操作选择工作空间 工作空间 其实就是我们写的源代码所在的目录 用Eclipse来完成一个HelloWorld案例 A:创建Java项目：点击File或者在最左侧空白处，选择Java项目，在界面中写一个项目名称，然后Finish即可。 B:创建包：展开项目，在源包src下建立一个包com.itheima C:创建类：在com.ithiema包下建立一个类HelloWorld在界面中写一个类名：HelloWorld，然后finish即可。 D:编写代码：在HelloWorld类写main方法，在main方法中写一条输出语句。 E:编译：自动编译，在保存的那一刻帮你做好了 F:运行 选择要运行的文件或者在要运行的文件内容中，右键 – Run as - Java Application即可 2.Eclipse工作空间的基本配置A:行号的显示和隐藏 ​ 显示：在代码区域的最左边的空白区域，右键 – Show Line Numbers即可。 ​ 隐藏：把上面的动作再做一次。 B:字体大小及颜色 ​ a:Java代码区域的字体大小和颜色： window – Preferences – General – Appearance – Colors And Fonts – Java – Java Edit Text Font ​ b:控制台 window – Preferences – General – Appearance – Colors And Fonts – Debug – Console font ​ c:其他文件 window – Preferences – General – Appearance – Colors And Fonts – Basic – Text Font C:窗体给弄乱了，怎么办? ​ window – Perspective – Reset Perspective D:控制台找不到了，怎么办? ​ Window–Show View—Console 3.常用辅助键和快捷键内容辅助键 alt+/ main 然后alt+/ syso 然后alt+/ 快捷键 注释 单行 选中内容，ctrl+/, 再来一次取消 多行 选中内容，ctrl+shift+/, ctrl+shift+\ 格式化 ctrl+shift+f 4.项目删除、导入A:删除项目 ​ 选中项目 – 右键 – 删除 ​ 从项目区域中删除 ​ 从硬盘上删除 B:导入项目 ​ 在项目区域右键找到import ​ 找到General，展开，并找到 ​ Existing Projects into Workspace ​ 点击next,然后选择你要导入的项目 ​ 注意：这里选择的是项目名称]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java - 学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow内核学习]]></title>
    <url>%2F2019%2F01%2F16%2Ftensor_02_serving%2F</url>
    <content type="text"><![CDATA[一.TF serving实现 TF serving托管模型流程包括4个步骤：训练模型，导出模型，发布模型，更新线上模型服务。 TF serving官方文档 1.ServablesServables 是 TensorFlow Serving 中最核心的抽象，是服务器端提供计算和查询服务的的实例对象。Servables 的大小和力度是灵活的，单个 Servable 可能包含从一个查找表的单个分片，到一个单独的模型，或是推理模型的元组。一套TF serving支持同时运行多个服务。 Servables 并不管理自身的生命周期。 典型的 Servables 包括： 一个 TensorFlow 的 SavedModelBundle (tensorflow::Session) 一个用于 Embedding 的查找表或词汇表 Servables Streams 一个 Servables Stream 是多个版本的 Servable 的序列，其按照版本号的递增排序。 2.ModelsTensorFlow Serving 将一个 模型 (model) 表示为一个或多个 Servables。一个机器学习模型可能包括一个或多个算法 (包括学习到的权重) 和查找表。 可以将一个 复合模型 (composite model) 表示成如下形式： 多个独立的 Servables 一个组合的 Servables 一个 Servable 也可能是一个模型的一部分，例如，一个大的查找表可能被分割到多个不同的 TensorFlow Serving 实例中。 3.LoadersLoaders 管理一个 Servable 的生命周期。Loaders 将一个 Servable 的加载和卸载的 API 进行了标准化，并且提供评估系统资源是否足够加载Servable的接口。 4.SourcesSources 是数据处理器抽象，负责监控和处理Servable加载的数据，比如文件系统指定路径下的查找表文件或模型文件。TensorFlow Serving 中 Sources 的接口可以从任意的存储系统中发现 Servables，TesorFlow Serving 包含了 Source 实现的通用引用。例如：Sources 可以利用 RPC 等机制，并可以轮训文件系统。Sources 可以维护多个 Servables 或 不同版本分片中的状态，这将有助于 Servables 在不同版本之间进行 Delta (diff) 更新。 5.ManagersManagers 维护 Servables 的整个生命周期，包括： 加载 Servables 为 Servables 提供服务 卸载 Servables Managers 从 Sources 获取信息并跟踪所有的 Versions。Manager 尽可能的满足 Sources 的请求，但当所需的资源不存在时，会拒绝载入一个 Aspired Versions。Manager 也可能延迟触发一个卸载 (unload)，例如：基于要确保任意时点都要至少有一个 Version 被加载的策略，Manager 需要等待一个新的 Version 完成加载后再卸载之前的 Version。 6.SavedModel是TF模型持久化存储的通用序列化格式，是打通从模型训练到服务发布流程的关键。在训练阶段，我们可能使用输入流水线和超参数优化操作。当模型发布为服务时，需要删除或替换这些操作，否则会出现推理准确率低，输入队列阻塞的情况。 为了提升服务发布后的准确率或其他评价指标，我们需要保存多分不同的数据流图进行测试。SavedModel支持用一份saved_model.pb文件来保存多幅不同的数据流图，这些数据流图可以共享模型参数和资源。 7.ServableHandle是响应gPRC客户端访问请求的服务句柄，ServableHandle与已加载的Servable一一对应。客户端请求TF serving服务时，服务端ServableHandle会调用相应的Servable服务接口，并将相应返回给客户端。如果服务尚未加载，则向客户端返回错误信息。 8.Batchbatch文档 将多个请求批处理为单个请求可以显著降低推理的成本，特别是在有 GPU 等加速器的情况下。TensorFlow Serving 包含了一个用于批处理请求的小工具，它允许客户端可以轻松的将请求中特定类型的推断合成一个批处理请求，以便系统能够更有效的处理。 在提供TensorFlow模型时，将单个模型推理请求一起批处理对于性能非常重要。特别是，批处理对于解锁GPU等硬件加速器所承诺的高吞吐量是必要的。这是一个用于批处理请求和调度批处理的库。该库本身并不依赖于GPU，并且可以用于串联处理小任务组的任何情况。 它提供了特定的TensorFlow会话API，以及可用于在其他粒度批处理的低级API。 该库目前分为:（1）core / kernels / batching_util（核心API和实现）（2）tensorflow_serving / batching（更高级别和实验代码）。 BatchingSessionBatchingSession将批处理添加到标准tensorflow :: Session，并允许您使用单个（非批处理）张量调用Session :: Run（），同时获得批量处理“隐藏”的好处。请求线程使得在等待其他组调用阻塞的Session :: Run（），调用进入同一个批处理。要使用此同步API实现良好的吞吐量，建议将客户端线程数设置为最大批量大小的两倍。 使用BatchingSession的最简单方法是通过CreateRetryingBasicBatchingSession（），它使用下面的BasicBatchSchedule提供了一个tensorflow :: Session对象，并且还处理溢出调度程序队列的重试请求。 Batch大小可以设置为1-1024。 BasicBatchSchedulerBasicBatchScheduler是一个比BatchingSession更低级的抽象，它与张量/ TensorFlow本身无关。它适用于处理同类请求的服务器。BasicBatchScheduler提供了一个异步API，称为BatchScheduler，该API由BatchTask类进行模板化，该类封装了要批处理的工作单元。 非阻塞Schedule（）方法用于将任务排入队列以进行处理。 准备好处理一批任务后，将在单独的线程上调用回调来处理批处理 Mixed CPU/GPU/IO Workloads除了主要的GPU工作之外，一些模型还执行非常重要的CPU工作。虽然核心矩阵操作可以在GPU上良好运行，但是外围操作可以在CPU上进行，例如，嵌入查找，词汇查找，量化/反量化。根据GPU的管理方式，将整个CPU和GPU步骤序列作为一个单元进行批处理可能无法充分利用GPU。 可以在请求线程中执行非GPU预处理和后处理，批处理调度程序仅用于工作的GPU部分。 或者，非GPU工作可以在批处理线程中完成，在批处理调度程序调用的回调中。要允许回调在完全形成批处理之前对任务执行非批处理工作，可以使用StreamingBatchScheduler。它专为非常精确控制延迟的服务器而设计，需要对流水线的每个阶段进行精细控制。 如果调度程序当前没有处理能力，StreamingBatchScheduler将拒绝任务。如果要自动重试因此原因而被拒绝的任务，可以在批处理调度程序之上对BatchSchedulerRetrier进行分层。有一个便利功能，用于创建与调度程序相结合的流调度程序：CreateRetryingStreamingBatchScheduler（）。 将模型推理逻辑拆分为多个不同阶段以优化延迟或利用率时，请记住，对于给定请求，每个阶段都应使用相同版本的模型。确保此属性的一个好方法是协调跨线程在每个阶段使用哪个ServableHandle对象。 最后，I / O密集的推理阶段，例如查找磁盘或远程服务器可能会受益于批处理以隐藏其延迟。您可以使用两个批处理调度程序实例：一个用于批处理这些查找，另一个用于批处理GPU工作。 二. TF serving流程1.训练和导出模型TF服务器端组件只负责模型服务的发布和更新，模型导出由TF原生的tensorflow.saved_model.builder.SavedModelBuilder模块实现。SavedModelBuilder定期向文件系统中的目标路径导出模型快照，模型快照的格式为SavedModel序列化格式。对于 SavedModel 格式的详细信息，参见 SavedModel REAMDE.md 文档，如下代码片段说明了将模型保存至硬盘的一般流程。 12345678910111213141516export_path_base = sys.argv[-1]export_path = os.path.join( compat.as_bytes(export_path_base), compat.as_bytes(str(FLAGS.model_version)))print &apos;Exporting trained model to&apos;, export_pathbuilder = tf.saved_model.builder.SavedModelBuilder(export_path)builder.add_meta_graph_and_variables( sess, [tag_constants.SERVING], signature_def_map=&#123; &apos;predict_images&apos;: prediction_signature, signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: classification_signature, &#125;, main_op=main_op)builder.save() 每个版本子目录中包含如下文件： saved_model.pb 是序列化的 tensorflow::SavedModel 文件。其包含一个或多个计算图的定义，同时也包含模型的一些元信息，例如 Signatures。 variables 为一系列包含了计算图中的变量的序列化文件。 谷歌推荐的保存模型的方式是保存模型为 PB 文件，它具有语言独立性，可独立运行，封闭的序列化格式，任何语言都可以解析它，它允许其他语言和深度学习框架读取、继续训练和迁移 TensorFlow 的模型。它的主要使用场景是实现创建模型与使用模型的解耦， 使得前向推导 inference的代码统一。另外的好处是保存为 PB 文件时候，模型的变量都会变成固定的，导致模型的大小会大大减小，适合在手机端运行。 2.定义模型服务的参数和配置使用SavedModelBuilder导出模型分为以下3步： 构造SavedModelBuilder实例，并设置模型的导出路径 定义模型服务的SignatureDef 使用SavedModelBuilder实例导出模型 创建SavedModelBuilder实例后，调用它的add_meta_graph_and_variables成员方法，添加期望导出的数据流图和模型参数。add_meta_graph_and_variables发放的主要输入参数包括： sess 为包含需要导出的训练好的模型的 TensorFlow 会话。 tags 数据流图的类型标签，可以选的取值包括SERVING，TRAINING和GPU。分别表示该数据流图用于提供服务，训练模型，以及使用GPU设备。 signature_def_map 指定了用于添加到 Meta Graph 中的从用户提供的键到 tensorflow::SignatureDef 之间的映射。Signature 指定了导出模型的类型，以及在进行推理阶段所绑定的输入和输出张量。 predict_signature签名配置（包括回归，分类，推理）作为一个 predict_signature 定义的示例，工具函数接受如下参数： inputs={&#39;images&#39;: tensor_info_x} 指定输入张量的信息。 outputs={&#39;scores&#39;: tensor_info_y} 指定输出评分张量的信息。 method_name 表示用于推理的方法。对于预测请求，其应被设置为 tensorflow/serving/predict，对于其他方法名称，参见 TensorFlow API 文档。 3.Serving with Docker using GPU（1）Install nvidia-docker (下载)Before serving with a GPU, in addition to installing Docker, you will need: Up-to-date NVIDIA drivers for your system nvidia-docker: You can follow the installation instructions here （2）Running a GPU serving imageRunning a GPU serving image is identical to running a CPU image. For more details, see running a serving image. （3）Serving GPU docker image1docker pull tensorflow/serving:latest-gpu （4）指定GPU Docker加载模型12345docker run --runtime=nvidia -p 8501:8501 \ --mount type=bind,\ source=/home/asphel/Desktop/models/official/resnet/savedmodel,\ target=/models/resnet \ -e MODEL_NAME=resnet -t tensorflow/serving:latest-gpu &amp; （5）服务运行在指定端口，通过网络请求调用服务122019-01-11 00:07:20.773693: I tensorflow_serving/model_servers/main.cc:333]Exporting HTTP/REST API at:localhost:8501 ... 发送请求，调用服务 12$ curl -d '&#123;"instances": [1.0, 2.0, 5.0]&#125;' \ -X POST http://localhost:8501/v1/models/resnet 三.实验实验环境core i3 4核心 3.1GHZ GTX 1050 4G显存 内存 4GB 测量参数1.CPU利用率，CPU负载 2.内存占用 3.GPU显存占用，GPU利用率 1. 多用户依次请求10000个用户请求陆续到达，服务器依次响应每个用户请求。 用户请求相同每次用户请求的模型和输入数据都相同 用户请求不同每次用户请求的模型和输入数据都相同 2. 多用户按批次请求10000个用户请求按批次加载到服务器，服务器按批次执行用户请求。 Batching can be turned on by providing proper SessionBundleConfig when creating the SavedModelBundleSourceAdapter. In this case we set the BatchingParameters with pretty much default values. Batching can be fine-tuned by setting custom timeout, batch_size, etc. values. For details, please refer to BatchingParameters. 12345678910SessionBundleConfig session_bundle_config;// Batching configif (enable_batching) &#123; BatchingParameters* batching_parameters = session_bundle_config.mutable_batching_parameters(); batching_parameters-&gt;mutable_thread_pool_name()-&gt;set_value( &quot;model_server_batch_threads&quot;);&#125;*saved_model_bundle_source_adapter_config.mutable_legacy_config() = session_bundle_config; 在到达完整批处理时，推理请求在内部合并为单个大请求（张量），并调用tensorflow :: Session :: Run（）（这是GPU上实际效率增益的来源） 3.模型训练（对比）10000个epochs训练过程 四.模型分析模型分析方法 1. 神经网络显存占用神经网络模型占用的显存包括： 模型自身的参数 模型的输出 举例来说，对于如下图所示的一个全连接网络(不考虑偏置项b) 模型的显存占用包括： 参数：二维数组 W模型的输出： 二维数组 Y输入X可以看成是上一层的输出，因此把它的显存占用归于上一层。 1.2 参数的显存占用只有有参数的层，才会有显存占用。这部份的显存占用和输入无关，模型加载完成之后就会占用。 有参数的层主要包括： 卷积 全连接 BatchNorm Embedding层 … … 无参数的层： 多数的激活层(Sigmoid/ReLU) 池化层 Dropout … … 更具体的来说，模型的参数数目(这里均不考虑偏置项b)为： Linear(M-&gt;N): 参数数目：M×N Conv2d(Cin, Cout, K): 参数数目：Cin × Cout × K × K BatchNorm(N): 参数数目： 2N Embedding(N,W): 参数数目： N × W 参数占用显存 = 参数数目×n n = 4 ：float32 n = 2 : float16 n = 8 : double64 在PyTorch中，当你执行完model=MyGreatModel().cuda()之后就会占用相应的显存，占用的显存大小基本与上述分析的显存差不多（会稍大一些，因为其它开销）。 1.3 梯度与动量的显存占用举例来说， 优化器如果是SGD： 可以看出来，除了保存W之外还要保存对应的梯度 ，因此显存占用等于参数占用的显存x2, 如果是带Momentum-SGD 这时候还需要保存动量， 因此显存x3 如果是Adam优化器，动量占用的显存更多，显存x4 总结一下，模型中与输入无关的显存占用包括： 参数 W 梯度 dW（一般与参数一样） 优化器的动量（普通SGD没有动量，momentum-SGD动量与梯度一样，Adam优化器动量的数量是梯度的两倍） 1.4 输入输出的显存占用这部份的显存主要看输出的feature map 的形状。 feature map 比如卷积的输入输出满足以下关系： 据此可以计算出每一层输出的Tensor的形状，然后就能计算出相应的显存占用。 模型输出的显存占用，总结如下： 需要计算每一层的feature map的形状（多维数组的形状） 需要保存输出对应的梯度用以反向传播（链式法则） 显存占用与 batch size 成正比 模型输出不需要存储相应的动量信息。 深度学习中神经网络的显存占用，我们可以得到如下公式： 1显存占用 = 模型显存占用 + batch_size × 每个样本的显存占用 可以看出显存不是和batch-size简单的成正比，尤其是模型自身比较复杂的情况下：比如全连接很大，Embedding层很大 另外需要注意： 输入（数据，图片）一般不需要计算梯度 神经网络的每一层输入输出都需要保存下来，用来反向传播，但是在某些特殊的情况下，我们可以不要保存输入。比如ReLU，在PyTorch中，使用nn.ReLU(inplace = True) 能将激活函数ReLU的输出直接覆盖保存于模型的输入之中，节省不少显存。]]></content>
      <categories>
        <category>Tensorflow</category>
      </categories>
      <tags>
        <tag>Deep learning</tag>
        <tag>科研 - 学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux性能监测工具（深度学习资源监控）]]></title>
    <url>%2F2019%2F01%2F12%2FLinux_07_%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[Linux性能监测工具相关链接：Linux 如何查看 CPU 利用率？ 1.toptop 命令会显示 Linux 的进程。它提供了一个运行中系统的实时动态视图，即实际的进程活动。默认情况下，它显示在服务器上运行的 CPU 占用率最高的任务，并且每五秒更新一次。 top 的常用快捷键常用快捷键列表： （2）htop - 交互式的进程查看器htop 命令详解 htop 是一款免费并开源的基于 ncurses 的 Linux 进程查看器。它比 top 命令更简单易用。您无需使用 PID、无需离开 htop 界面，便可以杀掉进程或调整其调度优先级。 1$ htop 输出示例： htop输出到文件先安装 aha 和 html2text 。 1echo q | htop -C | aha --line-fix | html2text -width 999 | grep -v &quot;F1Help&quot; | grep -v &quot;xml version=&quot; &gt; file.txt 2.mpstat - 监控多处理器的使用情况mpstat 命令显示每个可用处理器的使用情况，编号从 0 开始。命令 mpstat -P ALL 显示了每个处理器的平均使用率： 1# mpstat -P ALL 输出示例： 12345678Linux 2.6.18-128.1.14.el5 (www03.nixcraft.in) 06/26/201806:48:11 PM CPU %user %nice %sys %iowait %irq %soft %steal %idle intr/s06:48:11 PM all 3.50 0.09 0.34 0.03 0.01 0.17 0.00 95.86 1218.0406:48:11 PM 0 3.44 0.08 0.31 0.02 0.00 0.12 0.00 96.04 1000.3106:48:11 PM 1 3.10 0.08 0.32 0.09 0.02 0.11 0.00 96.28 34.9306:48:11 PM 2 4.16 0.11 0.36 0.02 0.00 0.11 0.00 95.25 0.0006:48:11 PM 3 3.77 0.11 0.38 0.03 0.01 0.24 0.00 95.46 44.80 3. Sysstat Package相关链接：利用Ksar分析系统瓶颈 中文教程 sar 命令用用收集、报告、或者保存 UNIX / Linux 系统的活动信息： CPU 使用率 内存页面和使用率 网络 I/O 和传输统计 进程创建活动 所有的块设备活动 每秒中断数等等 sar 命令的输出能够用于识别服务器瓶颈。但是，分析 sar 命令提供的信息可能比较困难，所以要使用 kSar 工具。kSar 工具可以将 sar 命令的输出绘制成基于时间周期的、易于理解的图表。 sar、sa1、和 sa2 命令都是 sysstat 包的一部分。它是 Linux 包含的性能监视工具集合。 sar：显示数据 sa1 和 sa2：收集和保存数据用于以后分析。sa2 shell 脚本在 /var/log/sa 目录中每日写入一个报告。sa1 shell 脚本将每日的系统活动信息以二进制数据的形式写入到文件中。 sadc —— 系统活动数据收集器。可以通过修改sa1和sa2脚本去配置各种选项。它们位于以下的目录： /usr/lib64/sa/sa1 （64 位）或者 /usr/lib/sa/sa1 （32 位） —— 它调用 sadc 去记录报告到 /var/log/sa/sadX 格式。 /usr/lib64/sa/sa2 （64 位）或者 /usr/lib/sa/sa2 （32 位） —— 它调用 sar 去记录报告到 /var/log/sa/sarX 格式。 4.KDE 系统监控器 - 实时系统报告和图形化显示 KSysguard 手册 KSysguard 是 KDE 桌面的网络化系统监控程序。这个工具可以通过 ssh 会话运行。它提供了许多功能，比如可以监控本地和远程主机的客户端-服务器模式。前端图形界面使用传感器来检索信息。传感器可以返回简单的值或更复杂的信息，如表格。每种类型的信息都有一个或多个显示界面，并被组织成工作表的形式，这些工作表可以分别保存和加载。所以，KSysguard 不仅是一个简单的任务管理器，还是一个控制大型服务器平台的强大工具。 5. Holy LanceHoly Lance 是一个简单易用的 基于 PHP]的 Linux 图形化性能监视器。 基于PHP，单文件，易于部署。Web界面，动态更新，实时简便，即开即用。目前可以动态监控CPU占用率、内存、磁盘、网络、进程，还带有环境探针以及性能测试功能。 6. GPU监控nvidia-smi文档 nvidia-smi是Nvidia显卡命令行管理套件，基于NVML库，旨在管理和监控Nvidia GPU设备。 这是nvidia-smi命令的输出，其中最重要的两个指标： 显存占用 GPU利用率 显存占用和GPU利用率是两个不一样的东西，显卡是由GPU计算单元和显存等组成的，显存和GPU的关系有点类似于内存和CPU的关系。 （1）编写脚本 monitor.sh12watch -n2.0 nvidia-smi \--query-gpu=index,timestamp,name,temperature.gpu,utilization.gpu,utilization.memory,memory.total,memory.free,memory.used --format=csv watch命令是为命令行输出设计的工具，其结果包含很多不可打印的字符，所以可以的解决方法有两个 把输出结果的语句写到command里面比如监控GPU的显存变化并写入日志 1watch -n 3 &apos;nvidia-smi -q -d MEMORY|tee -a gpu.log&apos; 写脚本 12345while &lt;some condition&gt;do &lt;mycommand&gt; 2&gt;&amp;1 | tee -a /path/to/logfile sleep 60done （2）gpustatgpustat文档 pip install gpustat即可安装，gpustat基于nvidia-smi，可以提供更美观简洁的展示，结合watch命令，可以动态实时监控GPU的使用情况。 1watch --color -n1 gpustat -cpu （3）Glances官方文档 glances 工具可以在用户的终端上实时显示重要的系统信息，并动态地对其进行更新。这个高效的工具可以工作于任何终端屏幕。glances 工具还可以将相同的数据捕获到一个文件，便于以后对报告进行分析和绘制图形。 1glances --export csv --export-csv-file ./glances.csv]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Deep Learning - 学习 - 科研</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习GPU监控]]></title>
    <url>%2F2019%2F01%2F12%2FLinux_08_GPU%E7%9B%91%E6%8E%A7%20%2F</url>
    <content type="text"><![CDATA[GPU监测工具在进行深度学习实验时，GPU 的实时状态监测很重要。nvidia-smi 是最常用的命令。 上图是服务器上 GeForce GTX 1080 Ti 的信息，下面一一解读参数。上面的表格中的红框中的信息与下面的四个框的信息是一一对应的： GPU：GPU 编号；Name：GPU 型号；Persistence-M：持续模式的状态。持续模式虽然耗能大，但是在新的GPU应用启动时，花费的时间更少，这里显示的是off的状态；Fan：风扇转速，从0到100%之间变动；Temp：温度，单位是摄氏度；Perf：性能状态，从P0到P12，P0表示最大性能，P12表示状态最小性能（即 GPU 未工作时为P0，达到最大工作限度时为P12）。Pwr:Usage/Cap：能耗；Memory Usage：显存使用率；Bus-Id：涉及GPU总线的东西，domain bus:device.function；Disp.A：Display Active，表示GPU的显示是否初始化；Volatile GPU-Util：浮动的GPU利用率；Uncorr. ECC：Error Correcting Code，错误检查与纠正；Compute M：compute mode，计算模式。下方的 Processes 表示每个进程对 GPU 的显存使用率。 第二个命令：nvidia-smi -L该命令用于列出所有可用的 NVIDIA 设备信息。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Deep Learning - 学习 - 科研</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux远程管理]]></title>
    <url>%2F2019%2F01%2F10%2FLinux_06_%E8%BF%9C%E7%A8%8B%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[远程管理常用命令目录 关机/重启 shutdown 查看或配置网卡信息 ifconfig ping 远程登录和复制文件 ssh scp 01. 关机/重启 序号 命令 含义 作用 01 shutdown 选项 时间 shutdown 关机／重新启动 1.1 shutdown shutdown 命令可以 安全 关闭 或者 重新启动系统| 选项 | 含义 || – | —— || -r | 重新启动 | 提示： 不指定选项和参数，默认表示 1 分钟之后 关闭电脑 远程维护服务器时，最好不要关闭系统，而应该重新启动系统 常用命令示例 1234567891011121314# 重新启动操作系统，其中 now 表示现在$ shutdown -r now# 立刻关机，其中 now 表示现在$ shutdown now# 系统在今天的 20:25 会关机$ shutdown 20:25# 系统再过十分钟后自动关机$ shutdown +10# 取消之前指定的关机计划$ shutdown -c 2.1 网卡 和 IP 地址网卡 网卡是一个专门负责网络通讯的硬件设备 IP 地址是设置在网卡上的地址信息 我们可以把 电脑 比作 电话，网卡 相当于 SIM 卡，IP 地址 相当于 电话号码 IP 地址 每台联网的电脑上都有 IP 地址，是保证电脑之间正常通讯的重要设置 注意：每台电脑的 IP 地址不能相同，否则会出现 IP 地址冲突，并且没有办法正常通讯 2.2 ifconfig ifconfig 可以查看／配置计算机当前的网卡配置信息 12345# 查看网卡配置信息$ ifconfig# 查看网卡对应的 IP 地址$ ifconfig | grep inet 提示：一台计算机中有可能会有一个 物理网卡 和 多个虚拟网卡，在 Linux 中物理网卡的名字通常以 ensXX 表示 127.0.0.1 被称为 本地回环/环回地址，一般用来测试本机网卡是否正常 2.3 ping12345# 检测到目标主机是否连接正常$ ping IP地址# 检测本地网卡工作正常$ ping 127.0.0.1 ping 一般用于检测当前计算机到目标计算机之间的网络 是否通畅，数值越大，速度越慢 ping 的工作原理与潜水艇的声纳相似，ping 这个命令就是取自 声纳的声音 网络管理员之间也常将 ping 用作动词 —— ping 一下计算机X，看他是否开着 原理：网络上的机器都有 唯一确定的 IP 地址，我们给目标 IP 地址发送一个数据包，对方就要返回一个数据包，根据返回的数据包以及时间，我们可以确定目标主机的存在 提示：在 Linux 中，想要终止一个终端程序的执行，绝大多数都可以使用 CTRL + C 03. 远程登录和复制文件 序号 命令 对应英文 作用 01 ssh 用户名@ip secure shell 关机／重新启动 02 scp 用户名@ip:文件名或路径 用户名@ip:文件名或路径 secure copy 远程复制文件 3.1 ssh 基础（重点）在 Linux 中 SSH 是 非常常用 的工具，通过 SSH 客户端 我们可以连接到运行了 SSH 服务器 的远程机器上 SSH 客户端是一种使用 Secure Shell（SSH） 协议连接到远程计算机的软件程序 1SSH 是目前较可靠， 专为远程登录会话和其他网络服务 提供安全性的协议 利用 SSH 协议 可以有效防止远程管理过程中的信息泄露 通过 SSH 协议 可以对所有传输的数据进行加密，也能够防止 DNS 欺骗和 IP 欺骗 SSH 的另一项优点是传输的数据可以是经过压缩的，所以可以加快传输的速度 1) 域名 和 端口号域名 由一串 用点分隔 的名字组成，例如：www.itcast.cn 是 IP 地址 的别名，方便用户记忆 端口号 IP 地址：通过 IP 地址 找到网络上的 计算机 端口号：通过 端口号 可以找到 计算机上运行的应用程序 SSH 服务器 的默认端口号是 22，如果是默认端口号，在连接的时候，可以省略 常见服务端口号列表： 序号 服务 端口号 01 SSH 服务器 22 02 Web 服务器 80 03 HTTPS 443 04 FTP 服务器 21 提示：有关 端口号的详细内容，在就业班会详细讲解！ 2) SSH 客户端的简单使用1ssh [-p port] user@remote user 是在远程机器上的用户名，如果不指定的话默认为当前用户 remote 是远程机器的地址，可以是 IP／域名，或者是 后面会提到的别名 port 是 SSH Server 监听的端口，如果不指定，就为默认值 22 提示： 使用 exit 退出当前用户的登录 注意： ssh 这个终端命令只能在 Linux 或者 UNIX 系统下使用 如果在 Windows 系统中，可以安装 PuTTY 或者 XShell 客户端软件即可 提示： 在工作中，SSH 服务器的端口号很有可能不是 22，如果遇到这种情况就需要使用 -p 选项，指定正确的端口号，否则无法正常连接到服务器 3) Windows 下 SSH 客户端的安装 Putty http://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html XShell http://xshellcn.com 建议从官方网站下载正式的安装程序 3.2 scp（掌握） scp 就是 secure copy，是一个在 Linux 下用来进行 远程拷贝文件 的命令 它的地址格式与 ssh 基本相同，需要注意的是，在指定端口时用的是大写的 -P 而不是小写的 12345678910111213# 把本地当前目录下的 01.py 文件 复制到 远程 家目录下的 Desktop/01.py# 注意：`:` 后面的路径如果不是绝对路径，则以用户的家目录作为参照路径scp -P port 01.py user@remote:Desktop/01.py# 把远程 家目录下的 Desktop/01.py 文件 复制到 本地当前目录下的 01.pyscp -P port user@remote:Desktop/01.py 01.py# 加上 -r 选项可以传送文件夹# 把当前目录下的 demo 文件夹 复制到 远程 家目录下的 Desktopscp -r demo user@remote:Desktop# 把远程 家目录下的 Desktop 复制到 当前目录下的 demo 文件夹scp -r user@remote:Desktop demo 选项 含义 -r 若给出的源文件是目录文件，则 scp 将递归复制该目录下的所有子目录和文件，目标文件必须为一个目录名 -P 若远程 SSH 服务器的端口不是 22，需要使用大写字母 -P 选项指定端口 注意： scp 这个终端命令只能在 Linux 或者 UNIX 系统下使用 如果在 Windows 系统中，可以安装 PuTTY，使用 pscp 命令行工具或者安装 FileZilla 使用 FTP 进行文件传输 FileZilla 官方网站：https://www.filezilla.cn/download/client FileZilla 在传输文件时，使用的是 FTP 服务 而不是 SSH 服务，因此端口号应该设置为 21 3.3 SSH 高级（知道） 免密码登录 配置别名 提示：有关 SSH 配置信息都保存在用户家目录下的 .ssh 目录下 1）免密码登录步骤 配置公钥 执行 ssh-keygen 即可生成 SSH 钥匙，一路回车即可 上传公钥到服务器 执行 ssh-copy-id -p port user@remote，可以让远程服务器记住我们的公钥 非对称加密算法 使用 公钥 加密的数据，需要使用 私钥 解密 使用 私钥 加密的数据，需要使用 公钥 解密 2) 配置别名每次都输入 ssh -p port user@remote，时间久了会觉得很麻烦，特别是当 user, remote 和 port 都得输入，而且还不好记忆 而 配置别名 可以让我们进一步偷懒，譬如用：ssh mac 来替代上面这么一长串，那么就在 ~/.ssh/config 里面追加以下内容： 1234Host mac HostName ip地址 User itheima Port 22 保存之后，即可用 ssh mac 实现远程登录了，scp 同样可以使用]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Linux - 学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Taskonomy Disentangling Task Transfer Learning]]></title>
    <url>%2F2019%2F01%2F01%2Fpaper_02_Tasknomy%2F</url>
    <content type="text"><![CDATA[Taskonomy: Disentangling Task Transfer Learning摘要这篇论文是计算机视觉顶会 CVPR 2018 最佳论文奖的文章：Taskonomy: Disentangling Task Transfer Learning。文章作者团队来自斯坦福大学和加州大学伯克利分校。文章的主题是探索任务迁移学习，通过做大量的实验，来揭示任务迁移学习中的一些现象。 人类的视觉具备多种多样的能力，计算机视觉届基于此定义了许多不同的视觉任务。长远来看，计算机视觉着眼于解决大多数甚至所有视觉任务，但现有方法大多尝试将视觉任务逐一击破。这种方法造成了两个问题：第一， 逐一击破需要为每一项任务收集大量数据，随着任务数量的增多，这将会是不可行的；第二，逐一击破会带来不同任务之间的冗余计算和重复学习。总的来说，逐一击破的策略忽略了视觉任务之间的关联性，比如法线 (Surface Normals) 是由深度 (Depth) 求导得来，语义分割 (Semantic Segmentation) 又似乎和遮挡边缘测试 (Occlusion edge detection) 有着千丝万缕的关联。基于上述两个问题，我们希望能有效测量并利用视觉任务之间的关联来避免重复学习，从而用更少的数据学习我们感兴趣的一组任务。 Taskonomy是一项量化不同视觉任务之间关联、并利用这些关联来最优化学习策略的研究。如果两个视觉任务A、B具有关联性，那么在任务A中习得的representations理应可为解决任务B提供有效的统计信息 。由此我们通过迁移学习计算了26个不同视觉任务之间的一阶以及高阶关联。如图一，如果有预测法线的网络和预测遮挡边缘测试的网络，我们可以通过结合两个网络的representations来快速通过少量数据解决Reshading和点匹配 (Point matching)。基于这些关联，我们利用0-1整数规划 (Binary Integer Programming) 求得一组我们感兴趣的任务，如何去最优分配训练数据量。 比如，如果想最高效地解决10个问题，利用Taskonomy提供的学习策略可以减少2/3的训练数据量。 正文文章的方法概括起来就叫做 Taskonomy (Task taxonomy)，这是一个计算图，它定义了任务之间的可迁移性。图中的节点表示任务，节点之间的边就表示迁移性，边的权重表示从一个任务迁移到另一个任务的可能表现。这个方法是文章的核心。它一共由下图所示的 4 个步骤构成。这 4 个步骤从逻辑上非常好理解。首先我们要对不同任务进行建模，然后让它们两两之间进行迁移并获取迁移的表现。接着为了构建一个统一的字典，我们对这些迁移结果进行归一化。最后，我们构建可迁移图。在迁移实验开始前，最重要的是，需要一个可用的超大型数据集，要包含不同的任务。然而目前没有。怎么办？很简单，作者构建了一个！这个数据集有从 600 个建筑物内拍摄的 400 万张图片。每张图片都针对不同的任务做了标注，也就是说都适用于每个任务。 1.问题定义首先，定义要解决的问题。我们想在有限的监督预算 下最大化在一组目标任务 上的表现。同时，我们有一组起始任务 ，其定义为我们可从零学习的任务。监督预算 的定义为多少起始任务我们愿意从零开始学习（从零开始学习需要收集大量数据，监督预算表达了我们所面对的金钱、计算力和时间上的限制）。那么， 代表了我们感兴趣但不能从零学习的任务，比如一个只能有少量数据的任务。 代表了我们不感兴趣但可以从零学习（来帮助我们更好的学习 ）的任务，如jigsaw、colorization等自我监督的视觉任务。 代表了我们感兴趣也能从零学习的任务，但因为从零学习会消耗监督预算，我们希望从中选择出符合预算的一组从零学习，余下的通过少量数据的迁移学习来实现。我们称 为我们的任务词典 (task dictionary)。最后，我们对视觉任务 的定义为一个基于图片的方程 。 如下图所示，收集了一个有四百万张图片的数据，每张图片均有26个不同视觉任务的标注(ground truth)。这26个任务涵盖了2D的、3D的和语义的任务，构成了本项research的任务词典。因为这26个任务均有标答， 也为这26个任务。 下面，进入第一大阶段，量化视觉任务的关联。 2.第一步：从零学习对于每个起始任务, 我们为其从零开始学习一个神经网络。为了能更好地控制变量从而比较任务关联，每个任务的神经网络具有相似的encoder decoder结构。所有的encoder都是相同的类ResNet 50结构。因为每个任务的output维度各不相同，decoder的结构对不同的任务各不相同，但都只有几层，远小于encoder的大小。 3.第二步：迁移学习如上图所示，对于一个起始任务 和一个目标任务 ，我们将以 的representation作为输入来学习 。我们将freeze任务 的encoder 参数，并基于encoder的输出 (representations) 学习一个浅层神经网络read out function。严谨来讲，如果我们用 表示 的encoder， 表示 的标注， 表示 的loss函数， 来表示图片和迁移训练集， 表示要迁移学习的浅层神经网络，学习目标为： 对于所有 和 组合，我们均训练了一个 。如下图所示，对于 ，不同的 会对 的表现造成不同的影响。更具关联的 会为 提供更有效的统计信息，从而仅用1/60的训练数据（相较于从零学习）就能取得不错的结果；相反不具备关联的 则并不能有此表现。因此，我们认为 在 任务中的表现可以很好地代表了 之于 的关联性。 上述迁移代表了任务之间一对一的关联，我们称其为一阶关联。如下图，几个任务之间可能具有互补性，结合几个起始任务的representations会对解决目标任务起到帮助。因此，我们也研究了任务之间多对一的关联，我们称其问高阶关联。在这种情况下，我们将几个起始任务的representation结合起来当作目标任务的输入，其余细节跟上段类似。 因为高阶的任务组合数量太大，我们基于一阶表现选择了一部分的组合进行迁移学习。对于小于五阶的高阶，我们根据一阶的表现，将前五的所有组合作为输入。对于n&gt;5阶，我们选择结合一阶表现前n的起始任务作为输入。 4.第三步：任务相似性标准化这一步的目标很明确，就是构建一个迁移学习的相似度矩阵，从中我们可以很清楚地知道哪两个任务迁移效果最好。如何构建？我们本能地想到，可以把上一步中训练的损失函数拿来用。然而，不同任务下的损失函数不具有可比性，因此不能用。自然地，我们又想到了归一化，把所有的结果归一化到 [0,1] 之间。这也是通常用的办法。但是问题又来了，通常来说，神经网络的损失函数具有很大的震荡幅度，直接拿来用是不可行的。 作者提出了一种基于序列的方法，使得训练的表现和损失函数的值呈正相关。对于目标任务 t，用矩阵 Wt来表示可迁移到 t 的源域任务的表现。矩阵中的元素 wij 就表示：在同一个分出来的测试集上，源域 si 迁移到 t，比 sj 迁移到 t 的表现好的百分比。比如 s1 到 t 要比 s2 到 t 好 15%。这个矩阵表示的是两两之间的比较，因此作者形象地把它叫做 tournament matrix（锦标赛矩阵）。 最后作者对得到的新矩阵进行了特征分解，则 si 到 t 的迁移表现就是第 i 个特征向量。把所有目标域 t 的特征向量组合起来就得到了一个相似度矩阵。这个矩阵是归一化过的。 这个方法不是作者发明的，是之前有人发明的，叫做 Analytic Hierarchy Process。 5.第四步：计算可迁移图最后一步，我们要基于affinity matrix求得如何最有效地学习一组我们感兴趣的任务。我们可以这个问题想象成一个subgraph selection的问题：选择一些任务从零学习，剩下的任务用少量数据进行迁移学习，具体迁移学习的策略由subgraph中的edge来决定（对一条directed edge，起始点代表我们从零学习的一个任务，终点代表要进行迁移的目标任务）。基于此，我们可以通过解如下BIP最优化问题来得到最优解： 这个最优问题有三个限制条件： 如果我们选择了一个迁移，那么迁移的起始任务（可能为高阶起始集）和目标任务均要出现在subgraph中； 每个目标任务有且仅有一个迁移（我们将从零学习在途中定义为从自己到自己的迁移，即一条自己到自己的edge）； 不超过监督预算。 结论实验部分是本文的重点。作者收集的数据集共包含 26 个计算机视觉的通用任务。在这些任务上，作者进行源领域训练、单一迁移、高阶迁移，一共构建了大约 3000 个学习任务，一共需要47886 个 GPU 小时来进行计算。 实验所用的所有编码器都是相同的，都基于 ResNet-50，去掉了 pooling 层。所有的迁移网络用的都是包含 2 个卷积的网络。损失函数和解码器就相应地根据不同任务进行调整。调整方式可见文章。 作者在一部分数据上进行实验，把这部分数据进行了如下的划分：训练集 120k，验证集 16k，测试集 17k。主要进行了以下方面的实验： 目标网络的性能 作者首先比较了不迁移情况下，目标网络的性能，也就是方法部分中的第 1 步。对比两个最近的方法可以看出，文章的网络性能不错。 领域相似度情况 作者验证了根据构建出的相似度矩阵进行相似度挖掘的实验，对不同的任务都画出了迁移性能图。从图中就可以清楚地知道哪些任务是对目标任务的迁移效果好坏。 作者又进一步对这些结果进行了更好的图示。 新任务上的泛化能力 将一个任务作为目标任务，其他 25 个任务作为源领域任务，考察模型在新任务上的泛化能力。实现效果显示这种迁移会比当前一些最好的非迁移深度方法还要好。从中我们得出的结论是，如果能够选择好源域任务，那么通常来说迁移学习的表现都要比直接从目标领域训练要好。 模型的扩展性 另外，作者还在 MIT Place 和 ImageNet 两个大型图像数据集上测试了方法的可扩展性。并且根据迁移效果，构建了迁移树用于进一步分析迁移表现。 局限性作者还在文章花费很多篇幅讨论了自己方法的局限性。主要有以下几点： 方法可能依赖于特定的数据和模型：尽管作者在不同的大型数据集上做了大量实验，作者依然担心，方法可能会依赖于特定的数据和网络。这么实诚的人不多了。 任务的通用性：作者只是在一些认为定义的任务上进行了实验。但有没有可能有更复杂更高级的任务？ 任务空间限制：可能还需要更多的实验。迁移到非视觉和机器人任务。这是一个值得考虑的问题。 终身学习：此方法目前还是离线的。如何实现在线终身学习？ 总结本文最大的亮点是，构建了非常多的迁移学习任务，详尽地探索了不同任务之间进行迁移的效果，为以后的研究提供了宝贵的基础。方法比较朴素，但是实现完备，很值得我们学习。作者在探索之外，还专门提供了一个数据集，这种精神值得钦佩！我们在今后的研究中，也要学习这种实验精神，多做，少说，慢慢积累。 迁移到非视觉和机器人任务。这是一个值得考虑的问题。 终身学习。此方法目前还是离线的。如何实现在线终身学习？ 参考文献 Zamir A R, Sax A, Shen W, et al. Taskonomy: Disentangling Task Transfer Learning[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 3712-3722.]]></content>
      <categories>
        <category>科研</category>
      </categories>
      <tags>
        <tag>深度学习任务调度 - 论文阅读 - 科研</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018年末碎语]]></title>
    <url>%2F2018%2F12%2F31%2FJournal2018%2F</url>
    <content type="text"><![CDATA[2018年末碎语 2018.12.31 ——EdwardZhao 1. 第一章 ​ 距离上一次提笔记录自己的心声，已经不知道过去多久了。很多年来的年末碎语我都缺席了，每次提笔准备文思泉涌的时候，我都想：” 算了，想记录的东西都在脑海里了，又何必写下来给别人看呢。“ 懒是一个原因，但不愿意分享自己的生活才是主因。”又有谁，又有多少人会关心你的生活呢？“我时常这样想。 ​ ” 没人关心你的生活，人们只是关心你过得没有他们好而已。“，我是赞同这个观点的。很多年前的我，身边有一群可以称兄道弟的好友，有一群无话不说的好姐妹，那时候我说过最多的话，或许是” 我们会是一辈子的好兄弟，好蓝颜，一定一定！“现在想来，自己那时候真的好傻好可爱。 ​ 倒不是说现在自己不愿意交际了，大学、研究生仍然和很多人关系不错，但也只限于此了。每个人的心都有一道墙，把他人拒之门外。现在的关系，更像是利益交换，别人有求于你的时候总是很主动、很热忱。完事之后，人与人之间又隔了厚厚的墙。我知道我无力改变这种事，又因为接触的事物和所在的位置不同，和不少朋友也渐行渐远，没有什么共同话语了。 ​ 但幸运的是，总还是有一些朋友，无论过去多久，无论多久没联系，无论我们现在相隔多远，总还是默默关心着对方的发展，打电话聊起来总能相谈甚欢，真遇到什么难事了总能第一时间得到援助和支持。所以我决定写下这一年的感悟，倒也不是给别人看的，只是想对自己更负责一些，也能让关心着自己的人安心一些。 ​ 大约是九月的某一周，连着几天梦见了高中时候的好友。于是趁着意识朦胧的时候，拿起手机给几个朋友发信息，说 “ 昨天梦见你们了，估计是想你们了，最近还过的好不好。“虽然自己也觉得很尴尬，不过发完信息心里还是很暖。这一年，和很多朋友打过电话嘘寒问暖，互相勉励；与很多朋友吃过饭，把酒言欢。所以时不时，梦里回到高中的球场和课堂，看着那些在阳光的映衬下格外耀眼的身影，那是我最美好的青春。看着远隔重洋的好友给寄的明信片，看着他们用心地感悟着生活，享受生活。也由衷地为他们感到高兴。这一年，作为朋友我是合格的，无论是作为倾听者，抑或是施以援手，给予鼓励。我深切地感受到那种亲密感，是我宝贵的财富。 ​ 当然，也免不了梦见罗姐，说起来惭愧，我连罗姐微信都没有。其实自己是害怕让他们看到自己咸鱼的一面吧，哎，自己真的是很虚伪。想起去年在滇中拥抱罗姐，说：“ 罗姐，下次见你的时候希望你能有个白白胖胖的小宝宝。”，后来又听苏3提起，也不知道现在罗姐怎么样。心像花儿一样美的大姐姐，真的希望神明能保佑着她，希望她一切都好。 2. 第二章 ​ 细想这一年真的发生了很多事。一月带爸妈在这个千里冰封，万里雪飘的地方体验了巨大的南北差异，零下二十度的严寒真的让人却步，我却越发觉得那茫茫白雪，晶莹剔透的寒冰让人心静，如此美丽。爸妈这样的土生南方人，看见那么多的雪自然是开心的不得了，他们用尽青春和心血将我抚养大，带他们一起领略大千世界的美丽，不由地成了自己的心愿。看到妈妈脸上幸福的笑容，和我爸爽朗的神情，我知道以后无论多忙我都要好好陪陪他们，这是我一生最爱的人啊。 ​ 北方的萧条已是大势所趋，每个人都在逃离，天时地利人和却是亘古不变的道理。但传统工业转型，向服务业进军的口号，只是放任北方萧条的借口，但凡有决心和政策倾斜，何处不能像美国西北蒸蒸日上。贫富差距和地区不平衡越拉越大，很多很多的问题，不再像从前那样只是听别人来解说了，无论是墙内墙外的观点，所有的事都会自己去判断，不做糊涂虫和跟风虫了，我想这是成长的一方面。 ​ 研究生考试准备的很仓促，或许是因为自己一直在困惑和迷茫吧，在结果发生之前谁不知道这是否是更好的选择。17年9月底比赛回来才开始全身心的准备，这样的仓促导致了后来的慌乱，所以志愿也摇摆不定。我深刻感受到，缺乏预见性和规划性是我的缺陷。如果早一点想好保研或者出国，那就不会有后来那么多烦心事了。17年12月底的考试，我没有那么平静，所以也没有那么稳定的发挥。考完之后虽然自己假装不在乎，说大不了重头再来，但其实自己心里很清楚应该是没什么问题的。知道要开始准备复试的时候，觉得没啥问题了，但大意失荆州，任何事真的马虎不得，没有尽心去做，就不会有相应的结果，这也是自己的一个教训。所以直博协议书签完以后的我，得知没能去深圳读博，还得留在本校，心里说不出的苦。后来想过，如果再花一年时间来充分准备，自己肯定能做得很好，去到更好的地方。但自己不想这样去假设，人生没有存档点，我们只能打好手里已有的牌。 ​ 凡事没有所谓的对错，现在研究生的我再来回看当时没能直博的路，不由得松一口气。我不知道去到深圳5，6年全心做研究的我会是什么样，或许过得很惬意、很享受，亦或许很痛苦，压力重重。我相信平行宇宙的观点，我想做出那样选择的我会有不一样的精彩。而没能读博的我也会有别样的风景。现在别人再问我是否愿意读博的时候，我会有所犹豫，但我还是知道，自己心没有那么平静，可以不受纷繁的外界所扰，自己也不像高斯、爱因斯坦、纳什他们那样，把毕生心血用于追求真理，在兴趣的推动下孜孜不倦，提起自己的研究问题可以像看到宝藏一样两眼放光。我想，那样的人才适合做研究，追求真理。一辈子很短，我想去多体验一些更有趣的事物。 ​ 本科的同学一半读了研，其中读研的又有一半直了博。Peer pressure，这个词真的无时无刻在我们身边发生着，所以保有自己的初心，真的不是一件容易的事。很多次和亲密的舍友说起这个问题，我说“ 你这么聪明干嘛不读个博？或者自己开个公司啊”。他说：“ 能读读，不能读就拉倒，人还是要佛系一点。“我说：”人一辈子不会太短了吗，你就不想过得光彩耀眼一点？“他说：”哎，人干嘛活的那么累。我就想有个稳定的收入能满足生活，然后和自己心爱的人在一起，去世界各地走走看看，日出而作日落而归。老了和孩子孙子说说自己年轻时候的故事和冒险，我就很知足了。”欲速则不达，我想心态对我们行动的影响真的很重，正是他这份与世无争的心，让他过得很自在，做每一件事都凭兴趣做到最好。而人的欲望总是无止尽的，新的一年，也希望自己能够佛系一点。 ​ 有时候我两会讨论起关于死亡的话题，你说我们死后究竟会以什么样的形式存在呢？“ 没有人知道答案，因为没有死去的人能告诉我们。“这几年，不时传来从前朝夕相处的朋友或同学、以及亲人离世的消息。很遗憾，也很可惜，时不时会想起他们。他说：“我觉得生命和意识是以概率图的形式在宇宙中随机出现的，当死亡时，这些点就不再存在这个宇宙中了。如果有下一个幸运的点刚好在这个坐标出现，那么新的生命和意识又诞生了，只是不再是从前那个点了。这个概率图会随着宇宙不断变化和发展，也对应了人类的繁衍生息。”我说，“当这个点不再存在宇宙中时，它不会很悲伤、很孤独吗？没有人能再听到它的声音。”他说：“我觉得像CoCo里说的那样，只有当所有人都忘记它时，它才真正的消失了。” 从前无情地挥霍着时间，现在却由衷地意识到了生命的短暂和宝贵。想起乔布斯的话，“人与人之间最公平的是时间。”我们无法改变生老病死，却能延展生命的意义。朋友说，“多么想念小时候的自己，每天都能有一个新奇的念头让自己早早醒来，不论是玩游戏或是钓鱼还是一件傻乎乎的事。能让自己充满力量，不知疲倦。”我也在找寻这样一件让自己由衷热爱的事，一个让自己每个清晨都如沐春风的念头。问自己：“如果今天就是自己生命最后一天，我会想做什么？” 3. 第三章 ​ 这一年让自己脸上时常泛起笑容的事，莫过于每天和女友交谈的时光以及浮想起她的身影时的闲暇。陪伴她，走过了高考，走过了2次研究生考试。在这一个个人生的转折点上，我很高兴自己都参与其中。虽然这段旅程中，我经历了很多事情，但我幸运的发现，她始终在我身边，在我需要的时候，陪我一同走过 风风雨雨。得知她第一次没有考好时，我拥抱着对她说：“ 我知道你已经付出了很多，做得很棒了。无论你之后选择什么样的道路，我都会支持你，鼓励你。”我知道和我一样生性好强的她，是不会放弃的。所以当她决定全力以赴再次奋战时，我拥抱着对她说：“ 我知道你一直都很努力，当你如此渴望去做好一件事时，一定能愿望成真的。”和她之间的关系，真的很亲密，也很融洽。我归结为我们之间个性相异，但想法互补。我们因为彼此的存在，没有受到太多的束缚，在一起很轻松也很愉快，也想为了对方而变得更好。 ​ 我知道她很努力，也知道她对自己的要求很高。所以这一年以来，倒也没有和她分享多少有用的经验和方法。反倒是，在她失落时想尽办法哄她开心，在她迷茫时给她写些书信告诉她我是她坚实的后盾，单调枯燥复习时找些好吃的让她分分心，时不时想些小点子给她一些小礼物让她对考试之后的生活有所寄托。在她快要上考场之前，剪辑完视频想要告诉她，人生有那么多有趣的事想要和她一同去经历，她身边一直有我。那个大雨滂沱的晚上，在她家楼下，我拥抱着她说：“ 只要尽力去做就好了，你不是一个人在战斗，你有我。” ​ 我想这就是我理解的爱情，想要获得幸福，那么爱情便是其中重中之重。爱情没有童话故事那么浪漫，但也没有电视剧那样撕心裂肺，爱情就是生活中的点点滴滴。我们在一起很开心，很舒服，仍能在关系之中保有自己的有所个性，又被对方所吸引。能一起欢笑，一起幻想未来的生活，能分享彼此的酸甜苦辣，能陪伴着对方走过风雨。 ​ 今后还有很多的未知，但我真的很想努力和她在一起，一起去看看这美丽的世界，一起去经历冷暖人情，世间百态。很想和她在同一个地方工作，有一个幸福美满的家庭。 ​ 有时候看到路边的小孩子，会去思考自己今后会如何去教导孩子，该让孩子选择什么样的道路，我接受的教育中欠缺了什么，父母给我的教育中哪些能做得更好。我时常在想，我会是一个合格的丈夫、父亲吗？自己是否能以身作则？虽然我知道这是很多年以后的事，但或许是从意识到自己是一个男子汉、男人的时候，这份内心的责任感便一直随行了。在面对很多事的时候，内心总会有许多邪恶的念头，但又因为道德观念和责任感的作用，很快就烟消云散了。我想这也是成长的一方面。 4. 第四章 ​ 再过几个月，自己就要23岁了，现在最为牵挂的人自然是父母。每次和爸妈通视频电话，总能聊很久，看着他们脸上的笑容，也会由心地高兴。朋友都很羡慕我能有这样的家庭，和爸妈更像是朋友，时常关心挂念着。爸妈也很开明，支持我做的每一个决定，鼓励我去选择自己想要的生活和道路。从高中住校开始，我妈总会想我，隔三岔五给我打个电话，担心叨扰我，怕我太忙了就总是发个信息提醒我早点休息。怕我遇到烦心事了，受委屈了，就总问我有难过的事要跟爸爸妈妈说啊。每次都要问我钱够不够用，多穿衣服注意身体。 ​ 虽然每次嘴上都说，嫌我妈烦。我早就不是小孩子了，不用操那么多心。但听到我妈的声音，还是会觉得很甜很温馨。妈妈因为教书的缘故，总和小朋友们在一起，所以心态真的很好，上次看到她的白发和憔悴的面容时，妈问我她是不是老了，我说哪里会，你还漂亮的很呢。我妈从小把我带到大，我们之间真的有心灵感应，那份亲密感真的暖在心底。记忆里，妈妈年轻时是一个非常严厉但又温柔、而且很要强的老师，同学们都听她话，都喜欢她。妈妈年轻的时候真的很漂亮，转眼就过去了那么久了。我爸虽然嘴上不说，但也一直很关心我，从小到大我的愿望他都会满足我。小时候我挺怕我爸的，因为他每次发火脾气都很大，但大了以后就不怕我爸了，他脾气也好了很多，我两关系也更像是铁哥们。我爸是个很聪明很有韧性的人，他从根本不会游泳，到自学以后每次游3公里。把我不再吹的葫芦丝拿来自学到一首唯美的《月光下的凤尾竹》，我的吉他他也开始自学。自从有高血压以后每天坚持走10000步，然后减肥成功。有空还写一首漂亮的行草或楷书，装裱成画。我爸身上的韧性真的是我需要学习的。 ​ 现在爸妈每周都会去爬山，去参加各种有趣的活动，然后分享他们的喜悦和快乐，这几年因为求学没能好好陪陪他们。希望自己以后还是常回家，多陪爸妈出去走走看看，多花时间陪陪我最爱的他们。对了，以后要多对爸妈说我爱你，多抱抱他们。这应该是中国家庭都欠缺的，爱还是需要表达和传递的。 5. 第五章 ​ 六月份的毕业典礼，在艳阳高照的北回归线附近进行。炎热、汗水、青春，或许是我对毕业的记忆。毕业设计花了挺多时间和精力去做，虽然自己都觉得我做的都是啥玩意儿。但还是给自己的本科交了一个不错的答复。7月连着游了一个月泳，那个时候真的精力旺盛。现在真的很喜欢游泳，健身这样的非对抗性运动，不再去篮球、足球场挥洒汗水了。接踵而至的研究生第一个学期，真的很忙，做了挺多事，也学了挺多东西。起码在学校官微做了很多海报、推送、书签这样的平面设计，虽然没什么用。 ​ 然后开始写技术博客了，虽然现在内容还不多，但看着自己GitHub的Dash Board，还是有点小小的满足感的。NG，Fei Fei Li这些学术大牛真的很厉害，很优秀，在学术上高屋建瓴，又能把自己的思想和所学无私地传授给后继者。很庆幸自己能生在这样一个年代，这样一个科技改变时代，改变生活的时代。虽然这个领域越来越热，跟风的人越来越多，泡沫也越来越大，但既然是自己的愿望所在，又何必顾虑那么多。做自己喜欢的、有意思的事，只是这样，就已经很好了。一个学期下来研究课题不能说有太多进展，但起码有了一些可以着手去做的事。下个学期会更忙碌，希望自己能更抓紧一点。冬天过后也希望自己能锻炼得更频繁一些，这个学期刚开始坚持得不错，但后来因为忙就推脱了。身体才是本钱，没有这个一，要多少0都没有意义。 ​ 雅思明年初也得考了，虽然还是会有很多语法错，但现在能和foreign people很流畅地对话了，英语却是得靠积累，希望明年自己也能每天坚持学一点。 ​ 现在最为憧憬的就是明年要去瑞典留学交换了，想要去欧洲几个主要国家都逛一逛，去好好体验一下诺贝尔的诞生地。 ​ 或许这几年来，自己因为迷茫走得慢了些，但现在却又开始步入正轨，走得快了起来，希望新的一年自己能有不一样的感悟和精彩。Life is Fantastic！Work hard！Play hard！]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux文件目录常用命令]]></title>
    <url>%2F2018%2F12%2F25%2FLinux_05_%E6%96%87%E4%BB%B6%E7%9B%AE%E5%BD%95%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[文件和目录常用命令 目标 查看目录内容ls切换目录cd创建和删除操作touchrmmkdir拷贝和移动文件cpmv查看文件内容catmoregrep其他echo重定向 &gt; 和 &gt;&gt;管道 | 01. 查看目录内容 1.1 终端实用技巧 1&gt; 自动补全 在敲出 文件／目录／命令 的前几个字母之后，按下 tab 键如果输入的没有歧义，系统会自动补全如果还存在其他 文件／目录／命令，再按一下 tab 键，系统会提示可能存在的命令 2&gt; 曾经使用过的命令 按 上／下 光标键可以在曾经使用过的命令之间来回切换如果想要退出选择，并且不想执行当前选中的命令，可以按 ctrl + c 1.2 ls 命令说明 ls 是英文单词 list 的简写，其功能为列出目录的内容，是用户最常用的命令之一，类似于 DOS 下的 dir 命令 Linux 下文件和目录的特点 Linux 文件 或者 目录 名称最长可以有 256 个字符以 . 开头的文件为隐藏文件，需要用 -a 参数才能显示. 代表当前目录.. 代表上一级目录 1.3 ls 常用选项 参数 含义 -a 显示指定目录下所有子目录与文件，包括隐藏文件 -l 以列表方式显示文件的详细信息 -h 配合 -l 以人性化的方式显示文件大小 计算机中文件大小的表示方式（科普） 单位 英文 含义 字节 B（Byte） 在计算机中作为一个数字单元，一般为 8 位二进制数 千 K（Kibibyte） 1 KB = 1024 B，千字节 （1024 = 2 ** 10） 兆 M（Mebibyte） 1 MB = 1024 KB，百万字节 千兆 G（Gigabyte） 1 GB = 1024 MB，十亿字节，千兆字节 太 T（Terabyte） 1 TB = 1024 GB，万亿字节，太字节 拍 P（Petabyte） 1 PB = 1024 TB，千万亿字节，拍字节 艾 E（Exabyte） 1 EB = 1024 PB，百亿亿字节，艾字节 泽 Z（Zettabyte） 1 ZB = 1024 EB，十万亿亿字节，泽字节 尧 Y（Yottabyte） 1 YB = 1024 ZB，一亿亿亿字节，尧字节 1.4 ls 通配符的使用 通配符 含义 * 代表任意个数个字符 ? 代表任意一个字符，至少 1 个 [] 表示可以匹配字符组中的任一一个 [abc] 匹配 a、b、c 中的任意一个 [a-f] 匹配从 a 到 f 范围内的的任意一个字符 02. 切换目录 2.1 cd cd 是英文单词 change directory 的简写，其功能为更改当前的工作目录，也是用户最常用的命令之一 注意：Linux 所有的 目录 和 文件名 都是大小写敏感的 命令 含义 cd 切换到当前用户的主目录(/home/用户目录) cd ~ 切换到当前用户的主目录(/home/用户目录) cd . 保持在当前目录不变 cd .. 切换到上级目录 cd - 可以在最近两次工作目录之间来回切换 2.2 相对路径和绝对路径 相对路径 在输入路径时，最前面不是 / 或者 ~，表示相对 当前目录 所在的目录位置绝对路径 在输入路径时，最前面是 / 或者 ~，表示从 根目录/家目录 开始的具体目录位置 03. 创建和删除操作 3.1 touch 创建文件或修改文件时间如果文件 不存在，可以创建一个空白文件如果文件 已经存在，可以修改文件的末次修改日期 3.2 mkdir 创建一个新的目录 选项 含义 -p 可以递归创建目录 新建目录的名称 不能与当前目录中 已有的目录或文件 同名 3.3 rm 删除文件或目录 使用 rm 命令要小心，因为文件删除后不能恢复 选项 含义 -f 强制删除，忽略不存在的文件，无需提示 -r 递归地删除目录下的内容，删除文件夹 时必须加此参数 04. 拷贝和移动文件 序号 命令 对应英文 作用 01 tree [目录名] tree 以树状图列出文件目录结构 02 cp 源文件 目标文件 copy 复制文件或者目录 03 mv 源文件 目标文件 move 移动文件或者目录／文件或者目录重命名 4.1 tree tree 命令可以以树状图列出文件目录结构 选项 含义 -d 只显示目录 4.2 cp cp 命令的功能是将给出的 文件 或 目录 复制到另一个 文件 或 目录 中，相当于 DOS 下的 copy 命令 选项 含义 -i 覆盖文件前提示 -r 若给出的源文件是目录文件，则 cp 将递归复制该目录下的所有子目录和文件，目标文件必须为一个目录名 4.3 mv mv 命令可以用来 移动 文件 或 目录，也可以给 文件或目录重命名 选项 含义 -i 覆盖文件前提示 05. 查看文件内容 序号 命令 对应英文 作用 01 cat 文件名 concatenate 查看文件内容、创建文件、文件合并、追加文件内容等功能 02 more 文件名 more 分屏显示文件内容 03 grep 搜索文本 文件名 grep 搜索文本文件内容 5.1 cat cat 命令可以用来 查看文件内容、创建文件、文件合并、追加文件内容 等功能cat 会一次显示所有的内容，适合 查看内容较少 的文本文件 选项 含义 -b 对非空输出行编号 -n 对输出的所有行编号 Linux 中还有一个 nl 的命令和 cat -b 的效果等价 5.2 more more 命令可以用于分屏显示文件内容，每次只显示一页内容适合于 查看内容较多的文本文件 使用 more 的操作键： 操作键 功能 空格键 显示手册页的下一屏 Enter 键 一次滚动手册页的一行 b 回滚一屏 f 前滚一屏 q 退出 /word 搜索 word 字符串 5.3 grep Linux 系统中 grep 命令是一种强大的文本搜索工具grep允许对文本文件进行 模式查找，所谓模式查找，又被称为正则表达式，在就业班会详细讲解 选项 含义 -n 显示匹配行及行号 -v 显示不包含匹配文本的所有行（相当于求反） -i 忽略大小写 常用的两种模式查找 参数 含义 ^a 行首，搜寻以 a 开头的行 ke$ 行尾，搜寻以 ke 结束的行 06. 其他 6.1 echo 文字内容 echo 会在终端中显示参数指定的文字，通常会和 重定向 联合使用 6.2 重定向 &gt; 和 &gt;&gt; Linux 允许将命令执行结果 重定向到一个 文件将本应显示在终端上的内容 输出／追加 到指定文件中 其中 &gt; 表示输出，会覆盖文件原有的内容&gt;&gt; 表示追加，会将内容追加到已有文件的末尾 6.3 管道 | Linux 允许将 一个命令的输出 可以通过管道 做为 另一个命令的输入可以理解现实生活中的管子，管子的一头塞东西进去，另一头取出来，这里 | 的左右分为两端，左端塞东西（写），右端取东西（读） 常用的管道命令有： more：分屏显示内容grep：在命令执行结果的基础上查询指定的文本]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Linux - 学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux命令格式]]></title>
    <url>%2F2018%2F12%2F24%2FLinux_04_linux%E5%91%BD%E4%BB%A4%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[@media print{ .hljs{overflow: visible; word-wrap: break-word !important;} } Linux 终端命令格式 目标 了解终端命令格式知道如何查阅终端命令帮助信息 01. 终端命令格式 command [-options] [parameter] 说明： command：命令名，相应功能的英文单词或单词的缩写[-options]：选项，可用来对命令进行控制，也可以省略parameter：传给命令的参数，可以是 零个、一个 或者 多个 [] 代表可选 02. 查阅命令帮助信息（知道） 提示现阶段只需要 知道 通过以下两种方式可以查询命令的帮助信息先学习常用命令及常用选项的使用即可，工作中如果遇到问题可以借助 网络搜索2.1 –helpcommand –help说明：显示 command 命令的帮助信息2.2 manman command说明：查阅 command 命令的使用手册man 是 manual 的缩写，是 Linux 提供的一个 手册，包含了绝大部分的命令、函数的详细使用说明 使用 man 时的操作键： 操作键功能空格键显示手册页的下一屏Enter 键一次滚动手册页的一行b回滚一屏f前滚一屏q退出/word搜索 word 字符串]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Linux - 学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flask生成 secret key]]></title>
    <url>%2F2018%2F12%2F24%2Fpython_05_flaskerror%2F</url>
    <content type="text"><![CDATA[Flask SECRET_KEY报错在flask项目中，Session, Cookies以及一些第三方扩展都会用到SECRET_KEY值，这是一个比较重要的配置值。 在使用flask时，产生了这个错误： 1RuntimeError: The session is unavailable because no secret key was set. Set the secret_key on the application to something unique and secret. 解决方法是在flask项目文件_inti__.py加入设置SECRET_KEY。 123456app = Flask(__name__) app.config[&apos;SECRET_KEY&apos;] = &apos;123456&apos; # or app.secret_key = &apos;123456&apos; # or app.config.update(SECRET_KEY=&apos;123456&apos;) 如果需要设置一个随机的SECRET_KEY值。我们可以使用os模块的urandom函数来获得随机值: 123&gt;&gt;&gt; import os &gt;&gt;&gt; os.urandom(24) &apos;\xeew\xe4\xc0\xee\xb1]\x9b\xa0\x9e)\x15Qhem\xe5\xf17\xd6\xceB\xb7\xb4&apos;]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python函数进阶]]></title>
    <url>%2F2018%2F12%2F24%2Fpython_04_%E5%87%BD%E6%95%B0%E8%BF%9B%E9%98%B6%2F</url>
    <content type="text"><![CDATA[函数进阶目标 函数参数和返回值的作用 函数的返回值 进阶 函数的参数 进阶 递归函数 01. 函数参数和返回值的作用函数根据 有没有参数 以及 有没有返回值，可以 相互组合，一共有 4 种 组合形式 无参数，无返回值 无参数，有返回值 有参数，无返回值 有参数，有返回值 定义函数时，是否接收参数，或者是否返回结果，是根据 实际的功能需求 来决定的！ 如果函数 内部处理的数据不确定，就可以将外界的数据以参数传递到函数内部 如果希望一个函数 执行完成后，向外界汇报执行结果，就可以增加函数的返回值 1.1 无参数，无返回值此类函数，不接收参数，也没有返回值，应用场景如下： 只是单纯地做一件事情，例如 显示菜单 在函数内部 针对全局变量进行操作，例如：新建名片，最终结果 记录在全局变量 中 注意： 如果全局变量的数据类型是一个 可变类型，在函数内部可以使用 方法 修改全局变量的内容 —— 变量的引用不会改变 在函数内部，使用赋值语句 才会 修改变量的引用 1.2 无参数，有返回值此类函数，不接收参数，但是有返回值，应用场景如下： 采集数据，例如 温度计，返回结果就是当前的温度，而不需要传递任何的参数 1.3 有参数，无返回值此类函数，接收参数，没有返回值，应用场景如下： 函数内部的代码保持不变，针对 不同的参数 处理 不同的数据 例如 名片管理系统 针对 找到的名片 做 修改、删除 操作 1.4 有参数，有返回值此类函数，接收参数，同时有返回值，应用场景如下： 函数内部的代码保持不变，针对 不同的参数 处理 不同的数据，并且 返回期望的处理结果 例如 名片管理系统 使用 字典默认值 和 提示信息 提示用户输入内容 如果输入，返回输入内容 如果没有输入，返回字典默认值 02. 函数的返回值 进阶 在程序开发中，有时候，会希望 一个函数执行结束后，告诉调用者一个结果，以便调用者针对具体的结果做后续的处理 返回值 是函数 完成工作后，最后 给调用者的 一个结果 在函数中使用 return 关键字可以返回结果 调用函数一方，可以 使用变量 来 接收 函数的返回结果 问题：一个函数执行后能否返回多个结果？ 示例 —— 温度和湿度测量 假设要开发一个函数能够同时返回当前的温度和湿度 先完成返回温度的功能如下： 1234567891011def measure(): """返回当前的温度""" print("开始测量...") temp = 39 print("测量结束...") return tempresult = measure()print(result) 在利用 元组 在返回温度的同时，也能够返回 湿度 改造如下： 123456789def measure(): """返回当前的温度""" print("开始测量...") temp = 39 wetness = 10 print("测量结束...") return (temp, wetness) 提示：如果一个函数返回的是元组，括号可以省略 技巧 在 Python 中，可以 将一个元组 使用 赋值语句 同时赋值给 多个变量 注意：变量的数量需要和元组中的元素数量保持一致 1result = temp, wetness = measure() 面试题 —— 交换两个数字题目要求 有两个整数变量 a = 6, b = 100 不使用其他变量，交换两个变量的值 解法 1 —— 使用其他变量1234# 解法 1 - 使用临时变量c = bb = aa = c 解法 2 —— 不使用临时变量1234# 解法 2 - 不使用临时变量a = a + bb = a - ba = a - b 解法 3 —— Python 专有，利用元组1a, b = b, a 03. 函数的参数 进阶3.1. 不可变和可变的参数 问题 1：在函数内部，针对参数使用 赋值语句，会不会影响调用函数时传递的 实参变量？ —— 不会！ 无论传递的参数是 可变 还是 不可变 只要 针对参数 使用 赋值语句，会在 函数内部 修改 局部变量的引用，不会影响到 外部变量的引用 12345678910111213141516171819def demo(num, num_list): print("函数内部") # 赋值语句 num = 200 num_list = [1, 2, 3] print(num) print(num_list) print("函数代码完成")gl_num = 99gl_list = [4, 5, 6]demo(gl_num, gl_list)print(gl_num)print(gl_list) 问题 2：如果传递的参数是 可变类型，在函数内部，使用 方法 修改了数据的内容，同样会影响到外部的数据 12345678910def mutable(num_list): # num_list = [1, 2, 3] num_list.extend([1, 2, 3]) print(num_list)gl_list = [6, 7, 8]mutable(gl_list)print(gl_list) 面试题 —— += 在 python 中，列表变量调用 += 本质上是在执行列表变量的 extend 方法，不会修改变量的引用 1234567891011121314151617181920def demo(num, num_list): print("函数内部代码") # num = num + num num += num # num_list.extend(num_list) 由于是调用方法，所以不会修改变量的引用 # 函数执行结束后，外部数据同样会发生变化 num_list += num_list print(num) print(num_list) print("函数代码完成")gl_num = 9gl_list = [1, 2, 3]demo(gl_num, gl_list)print(gl_num)print(gl_list) 3.2 缺省参数 定义函数时，可以给 某个参数 指定一个默认值，具有默认值的参数就叫做 缺省参数 调用函数时，如果没有传入 缺省参数 的值，则在函数内部使用定义函数时指定的 参数默认值 函数的缺省参数，将常见的值设置为参数的缺省值，从而 简化函数的调用 例如：对列表排序的方法 123456789gl_num_list = [6, 3, 9]# 默认就是升序排序，因为这种应用需求更多gl_num_list.sort()print(gl_num_list)# 只有当需要降序排序时，才需要传递 `reverse` 参数gl_num_list.sort(reverse=True)print(gl_num_list) 指定函数的缺省参数 在参数后使用赋值语句，可以指定参数的缺省值 1234567def print_info(name, gender=True): gender_text = "男生" if not gender: gender_text = "女生" print("%s 是 %s" % (name, gender_text)) 提示 缺省参数，需要使用 最常见的值 作为默认值！ 如果一个参数的值 不能确定，则不应该设置默认值，具体的数值在调用函数时，由外界传递！ 缺省参数的注意事项1) 缺省参数的定义位置 必须保证 带有默认值的缺省参数 在参数列表末尾 所以，以下定义是错误的！ 1def print_info(name, gender=True, title): 2) 调用带有多个缺省参数的函数 在 调用函数时，如果有 多个缺省参数，需要指定参数名，这样解释器才能够知道参数的对应关系！ 1234567891011121314151617181920def print_info(name, title="", gender=True): """ :param title: 职位 :param name: 班上同学的姓名 :param gender: True 男生 False 女生 """ gender_text = "男生" if not gender: gender_text = "女生" print("%s%s 是 %s" % (title, name, gender_text))# 提示：在指定缺省参数的默认值时，应该使用最常见的值作为默认值！print_info("小明")print_info("老王", title="班长")print_info("小美", gender=False) 3.3 多值参数（知道）定义支持多值参数的函数 有时可能需要 一个函数 能够处理的参数 个数 是不确定的，这个时候，就可以使用 多值参数 python 中有 两种 多值参数： 参数名前增加 一个 * 可以接收 元组 参数名前增加 两个 * 可以接收 字典 一般在给多值参数命名时，习惯使用以下两个名字 *args —— 存放 元组 参数，前面有一个 * **kwargs —— 存放 字典 参数，前面有两个 * args 是 arguments 的缩写，有变量的含义 kw 是 keyword 的缩写，kwargs 可以记忆 键值对参数 12345678def demo(num, *args, **kwargs): print(num) print(args) print(kwargs)demo(1, 2, 3, 4, 5, name="小明", age=18, gender=True) 提示：多值参数 的应用会经常出现在网络上一些大牛开发的框架中，知道多值参数，有利于我们能够读懂大牛的代码 多值参数案例 —— 计算任意多个数字的和需求 定义一个函数 sum_numbers，可以接收的 任意多个整数 功能要求：将传递的 所有数字累加 并且返回累加结果 12345678910def sum_numbers(*args): num = 0 # 遍历 args 元组顺序求和 for n in args: num += n return numprint(sum_numbers(1, 2, 3)) 元组和字典的拆包（知道） 在调用带有多值参数的函数时，如果希望： 将一个 元组变量，直接传递给 args 将一个 字典变量，直接传递给 kwargs 就可以使用 拆包，简化参数的传递，拆包 的方式是： 在 元组变量前，增加 一个 * 在 字典变量前，增加 两个 * 12345678910111213def demo(*args, **kwargs): print(args) print(kwargs)# 需要将一个元组变量/字典变量传递给函数对应的参数gl_nums = (1, 2, 3)gl_xiaoming = &#123;"name": "小明", "age": 18&#125;# 会把 num_tuple 和 xiaoming 作为元组传递个 args# demo(gl_nums, gl_xiaoming)demo(*gl_nums, **gl_xiaoming) 04. 函数的递归 函数调用自身的 编程技巧 称为递归 4.1 递归函数的特点特点 一个函数 内部 调用自己 函数内部可以调用其他函数，当然在函数内部也可以调用自己 代码特点 函数内部的 代码 是相同的，只是针对 参数 不同，处理的结果不同 当 参数满足一个条件 时，函数不再执行 这个非常重要，通常被称为递归的出口，否则 会出现死循环！ 示例代码 1234567891011def sum_numbers(num): print(num) # 递归的出口很重要，否则会出现死循环 if num == 1: return sum_numbers(num - 1) sum_numbers(3) 4.2 递归案例 —— 计算数字累加需求 定义一个函数 sum_numbers 能够接收一个 num 的整数参数 计算 1 + 2 + … num 的结果 123456789101112def sum_numbers(num): if num == 1: return 1 # 假设 sum_numbers 能够完成 num - 1 的累加 temp = sum_numbers(num - 1) # 函数内部的核心算法就是 两个数字的相加 return num + tempprint(sum_numbers(2)) 递归在处理 不确定的循环条件时，格外的有用，例如：遍历整个文件目录的结构]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python金融量化]]></title>
    <url>%2F2018%2F12%2F21%2Fpython_03_%E9%87%91%E8%9E%8D%E9%87%8F%E5%8C%96%2F</url>
    <content type="text"><![CDATA[量化策略1.量化策略通过一套固定的逻辑来分析，判断和决策，自动化地进行股票交易。 2.核心内容 选股 择时 仓位管理 止盈止损 3.策略的周期 产生想法/学习知识 实现策略：Python 检验策略：回测/模拟交易 实盘交易 优化策略 123456789101112131415161718graph TB 行情数据--&gt;选股 止盈止损--&gt;买入信号 subgraph 输出 买入信号---卖出信号 卖出信号---交易费用 交易费用---收益 end subgraph 策略 选股--&gt;择时 择时--&gt;仓位管理 仓位管理--&gt;止盈止损 end subgraph 输入 行情数据---财务数据 财务数据---自定义数据 自定义数据---投资经验 end 量化投资与Python 常用分析工具 Excel，SAS/SPSS，R语言 量化投资第三方模块 NumPy：数值计算 Pandas：数据分析 Matplotlib：图表绘制 使用Python进行量化投资 自己编写 在线平台：聚宽，优矿，米筐，Quantopian 开源框架：RQAlpha，QUANTAXIS NumPyNumPy是Python中科学计算的基础软件包。它是一个提供多了维数组对象，多种派生对象（如：掩码数组、矩阵）以及用于快速操作数组的函数及API，它包括数学、逻辑、数组形状变换、排序、选择、I/O 、离散傅立叶变换、基本线性代数、基本统计运算、随机模拟等等。 NumPy包的核心是ndarray对象。 NumPy数组 和 标准Python Array（数组） 之间有几个重要的区别： NumPy数组在创建时具有固定的大小，与Python的原生数组对象（可以动态增长）不同。 更改ndarray的大小将创建一个新数组并删除原来的数组。 NumPy数组中的元素都需要具有相同的数据类型，因此在内存中的大小相同。 例外情况：Python的原生数组里包含了NumPy的对象的时候，这种情况下就允许不同大小元素的数组。 NumPy数组有助于对大量数据进行高级数学和其他类型的操作。 通常，这些操作的执行效率更高，比使用Python原生数组的代码更少。 越来越多的基于Python的科学和数学软件包使用NumPy数组; 虽然这些工具通常都支持Python的原生数组作为参数，但它们在处理之前会还是会将输入的数组转换为NumPy的数组，而且也通常输出为NumPy数组。 换句话说，为了高效地使用当今科学/数学基于Python的工具（大部分的科学计算工具），你只知道如何使用Python的原生数组类型是不够的 - 还需要知道如何使用NumPy数组。 NumPy 中的数组NumPy提供的最重要的数据结构是一个称为NumPy数组的强大对象。 123456import numpy as npimport sysmy_array = np.array(range(100))my_list = list(range(100))print (sys.getsizeof(my_array))print (sys.getsizeof(my_list)) 切片操作1234my_array = np.array([[4, 5], [6, 1]])print my_array[0][1]my_array_column_2 = my_array[:, 1] #取第二列print my_array_column_2]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux Shebang符号]]></title>
    <url>%2F2018%2F12%2F20%2FLinux_03_shebang%E7%AC%A6%E5%8F%B7%2F</url>
    <content type="text"><![CDATA[LINUX Shebang 符号(#!) #!这个符号叫做 Shebang 或者 Sha-bang Shebang 通常在 Unix 系统脚本的中 第一行开头 使用 指明 执行这个脚本文件 的 解释程序 使用 Shebang 的步骤 使用 which 查询 python3 解释器所在路径 1$ which python3 修改要运行的 主 python 文件，在第一行增加以下内容 1#! /usr/bin/python3 修改 主 python 文件 的文件权限，增加执行权限 1$ chmod +x cards_main.py 在需要时执行程序即可 1./cards_main.py]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Linux - 学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux系统目录]]></title>
    <url>%2F2018%2F12%2F20%2Flinux_02_%E7%B3%BB%E7%BB%9F%E7%9B%AE%E5%BD%95%2F</url>
    <content type="text"><![CDATA[Linux文件和目录01. 单用户操作系统和多用户操作系统 单用户操作系统：指一台计算机在同一时间 只能由一个用户 使用，一个用户独自享用系统的全部硬件和软件资源 Windows XP 之前的版本都是单用户操作系统 多用户操作系统：指一台计算机在同一时间可以由 多个用户 使用，多个用户共同享用系统的全部硬件和软件资源 Unix 和 Linux 的设计初衷就是多用户操作系统 02. Windows 和 Linux 文件系统区别2.1 Windows 下的文件系统 在 Windows 下，打开 “计算机”，我们看到的是一个个的驱动器盘符： 每个驱动器都有自己的根目录结构，这样形成了多个树并列的情形，如图所示： 2.2 Linux 下的文件系统 在 Linux 下，我们是看不到这些驱动器盘符，我们看到的是文件夹（目录）： Ubuntu 没有盘符这个概念，只有一个根目录 /，所有文件都在它下面 2.3 用户目录位于 /home/user，称之为用户工作目录或家目录，表示方式： 12/home/user~ 2.4 Linux 主要目录速查表 /：根目录，一般根目录下只存放目录，在 linux 下有且只有一个根目录，所有的东西都是从这里开始 当在终端里输入 /home，其实是在告诉电脑，先从 /（根目录）开始，再进入到 home 目录 /bin、/usr/bin：可执行二进制文件的目录，如常用的命令 ls、tar、mv、cat 等 /boot：放置 linux 系统启动时用到的一些文件，如 linux 的内核文件：/boot/vmlinuz，系统引导管理器：/boot/grub /dev：存放linux系统下的设备文件，访问该目录下某个文件，相当于访问某个设备，常用的是挂载光驱mount /dev/cdrom /mnt /etc：系统配置文件存放的目录，不建议在此目录下存放可执行文件，重要的配置文件有 /etc/inittab /etc/fstab /etc/init.d /etc/X11 /etc/sysconfig /etc/xinetd.d /home：系统默认的用户家目录，新增用户账号时，用户的家目录都存放在此目录下 ~ 表示当前用户的家目录 ~edu 表示用户 edu 的家目录 /lib、/usr/lib、/usr/local/lib：系统使用的函数库的目录，程序在执行过程中，需要调用一些额外的参数时需要函数库的协助 /lost+fount：系统异常产生错误时，会将一些遗失的片段放置于此目录下 /mnt: /media：光盘默认挂载点，通常光盘挂载于 /mnt/cdrom 下，也不一定，可以选择任意位置进行挂载 /opt：给主机额外安装软件所摆放的目录 /proc：此目录的数据都在内存中，如系统核心，外部设备，网络状态，由于数据都存放于内存中，所以不占用磁盘空间，比较重要的文件有：/proc/cpuinfo、/proc/interrupts、/proc/dma、/proc/ioports、/proc/net/* 等 /root：系统管理员root的家目录 /sbin、/usr/sbin、/usr/local/sbin：放置系统管理员使用的可执行命令，如 fdisk、shutdown、mount 等。与 /bin 不同的是，这几个目录是给系统管理员 root 使用的命令，一般用户只能”查看”而不能设置和使用 /tmp：一般用户或正在执行的程序临时存放文件的目录，任何人都可以访问，重要数据不可放置在此目录下 /srv：服务启动之后需要访问的数据目录，如 www 服务需要访问的网页数据存放在 /srv/www 内 /usr：应用程序存放目录 /usr/bin：存放应用程序 /usr/share：存放共享数据 /usr/lib：存放不能直接运行的，却是许多程序运行所必需的一些函数库文件 /usr/local：存放软件升级包 /usr/share/doc：系统说明文件存放目录 /usr/share/man：程序说明文件存放目录 /var：放置系统执行过程中经常变化的文件 /var/log：随时更改的日志文件 /var/spool/mail：邮件存放的目录 /var/run：程序或服务启动后，其 PID 存放在该目录下]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Linux - 学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python字符串常用方法]]></title>
    <url>%2F2018%2F12%2F19%2Fpython_02_%E5%AD%97%E7%AC%A6%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[1.字符串的常用操作1) 判断类型 - 9 方法 说明 string.isspace() 如果 string 中只包含空格，则返回 True string.isalnum() 如果 string 至少有一个字符并且所有字符都是字母或数字则返回 True string.isalpha() 如果 string 至少有一个字符并且所有字符都是字母则返回 True string.isdecimal() 如果 string 只包含数字则返回 True，全角数字，（常用） string.isdigit() 如果 string 只包含数字则返回 True，全角数字、⑴、\u00b2 string.isnumeric() 如果 string 只包含数字则返回 True，全角数字，汉字数字 string.istitle() 如果 string 是标题化的(每个单词的首字母大写)则返回 True string.islower() 如果 string 中包含至少一个区分大小写的字符，并且所有这些(区分大小写的)字符都是小写，则返回 True string.isupper() 如果 string 中包含至少一个区分大小写的字符，并且所有这些(区分大小写的)字符都是大写，则返回 True 2) 查找和替换 - 7 方法 说明 string.startswith(str) 检查字符串是否是以 str 开头，是则返回 True string.endswith(str) 检查字符串是否是以 str 结束，是则返回 True string.find(str, start=0, end=len(string)) 检测 str 是否包含在 string 中，如果 start 和 end 指定范围，则检查是否包含在指定范围内，如果是返回开始的索引值，否则返回 -1 string.rfind(str, start=0, end=len(string)) 类似于 find()，不过是从右边开始查找 string.index(str, start=0, end=len(string)) 跟 find() 方法类似，不过如果 str 不在 string 会报错 string.rindex(str, start=0, end=len(string)) 类似于 index()，不过是从右边开始 string.replace(old_str, new_str, num=string.count(old)) 把 string 中的 old_str 替换成 new_str，如果 num 指定，则替换不超过 num 次 3) 大小写转换 - 5 方法 说明 string.capitalize() 把字符串的第一个字符大写 string.title() 把字符串的每个单词首字母大写 string.lower() 转换 string 中所有大写字符为小写 string.upper() 转换 string 中的小写字母为大写 string.swapcase() 翻转 string 中的大小写 4) 文本对齐 - 3 方法 说明 string.ljust(width) 返回一个原字符串左对齐，并使用空格填充至长度 width 的新字符串 string.rjust(width) 返回一个原字符串右对齐，并使用空格填充至长度 width 的新字符串 string.center(width) 返回一个原字符串居中，并使用空格填充至长度 width 的新字符串 5) 去除空白字符 - 3 方法 说明 string.lstrip() 截掉 string 左边（开始）的空白字符 string.rstrip() 截掉 string 右边（末尾）的空白字符 string.strip() 截掉 string 左右两边的空白字符 6) 拆分和连接 - 5 方法 说明 string.partition(str) 把字符串 string 分成一个 3 元素的元组 (str前面, str, str后面) string.rpartition(str) 类似于 partition() 方法，不过是从右边开始查找 string.split(str=””, num) 以 str 为分隔符拆分 string，如果 num 有指定值，则仅分隔 num + 1 个子字符串，str 默认包含 ‘\r’, ‘\t’, ‘\n’ 和空格 string.splitlines() 按照行(‘\r’, ‘\n’, ‘\r\n’)分隔，返回一个包含各行作为元素的列表 string.join(seq) 以 string 作为分隔符，将 seq 中所有的元素（的字符串表示）合并为一个新的字符串 2.字符串的切片 切片 方法适用于 字符串、列表、元组 切片 使用 索引值 来限定范围，从一个大的 字符串 中 切出 小的 字符串 列表 和 元组 都是 有序 的集合，都能够 通过索引值 获取到对应的数据 字典 是一个 无序 的集合，是使用 键值对 保存数据 1字符串[开始索引:结束索引:步长] 注意： 指定的区间属于 左闭右开 型 [开始索引, 结束索引) =&gt; 开始索引 &gt;= 范围 &lt; 结束索引 从 起始 位开始，到 结束位的前一位 结束（不包含结束位本身) 从头开始，开始索引 数字可以省略，冒号不能省略 到末尾结束，结束索引 数字可以省略，冒号不能省略 步长默认为 1，如果连续切片，数字和冒号都可以省略 索引的顺序和倒序 在 Python 中不仅支持 顺序索引，同时还支持 倒序索引 所谓倒序索引就是 从右向左 计算索引 最右边的索引值是 -1，依次递减 演练需求 截取从 2 ~ 5 位置 的字符串 截取从 2 ~ 末尾 的字符串 截取从 开始 ~ 5 位置 的字符串 截取完整的字符串 从开始位置，每隔一个字符截取字符串 从索引 1 开始，每隔一个取一个 截取从 2 ~ 末尾 - 1 的字符串 截取字符串末尾两个字符 字符串的逆序（面试题） 答案 1234567891011121314151617181920212223242526272829303132num_str = &quot;0123456789&quot;# 1. 截取从 2 ~ 5 位置 的字符串print(num_str[2:6])# 2. 截取从 2 ~ `末尾` 的字符串print(num_str[2:])# 3. 截取从 `开始` ~ 5 位置 的字符串print(num_str[:6])# 4. 截取完整的字符串print(num_str[:])# 5. 从开始位置，每隔一个字符截取字符串print(num_str[::2])# 6. 从索引 1 开始，每隔一个取一个print(num_str[1::2])# 倒序切片# -1 表示倒数第一个字符print(num_str[-1])# 7. 截取从 2 ~ `末尾 - 1` 的字符串print(num_str[2:-1])# 8. 截取字符串末尾两个字符print(num_str[-2:])# 9. 字符串的逆序（面试题）print(num_str[::-1]) 公共方法1.Python 内置函数Python 包含了以下内置函数： 函数 描述 备注 len(item) 计算容器中元素个数 del(item) 删除变量 del 有两种方式 max(item) 返回容器中元素最大值 如果是字典，只针对 key 比较 min(item) 返回容器中元素最小值 如果是字典，只针对 key 比较 cmp(item1, item2) 比较两个值，-1 小于/0 相等/1 大于 Python 3.x 取消了 cmp 函数 注意 字符串 比较符合以下规则： “0” &lt; “A” &lt; “a” 2.切片 描述 Python 表达式 结果 支持的数据类型 切片 “0123456789”[::-2] “97531” 字符串、列表、元组 切片 使用 索引值 来限定范围，从一个大的 字符串 中 切出 小的 字符串 列表 和 元组 都是 有序 的集合，都能够 通过索引值 获取到对应的数据 字典 是一个 无序 的集合，是使用 键值对 保存数据 3.运算符 运算符 Python 表达式 结果 描述 支持的数据类型 + [1, 2] + [3, 4] [1, 2, 3, 4] 合并 字符串、列表、元组 * [“Hi!”] * 4 [‘Hi!’, ‘Hi!’, ‘Hi!’, ‘Hi!’] 重复 字符串、列表、元组 in 3 in (1, 2, 3) True 元素是否存在 字符串、列表、元组、字典 not in 4 not in (1, 2, 3) True 元素是否不存在 字符串、列表、元组、字典 &gt; &gt;= == &lt; &lt;= (1, 2, 3) &lt; (2, 2, 3) True 元素比较 字符串、列表、元组 注意 in 在对 字典 操作时，判断的是 字典的键 in 和 not in 被称为 成员运算符 成员运算符成员运算符用于 测试 序列中是否包含指定的 成员 运算符 描述 实例 in 如果在指定的序列中找到值返回 True，否则返回 False 3 in (1, 2, 3) 返回 True not in 如果在指定的序列中没有找到值返回 True，否则返回 False 3 not in (1, 2, 3) 返回 False 注意：在对 字典 操作时，判断的是 字典的键 4.完整的 for 循环语法 在 Python 中完整的 for 循环 的语法如下： 12345for 变量 in 集合: 循环体代码else: 没有通过 break 退出循环，循环结束后，会执行的代码 应用场景 在 迭代遍历 嵌套的数据类型时，例如 一个列表包含了多个字典 需求：要判断 某一个字典中 是否存在 指定的 值 如果 存在，提示并且退出循环 如果 不存在，在 循环整体结束 后，希望 得到一个统一的提示 123456789101112131415161718192021222324252627282930students = [ &#123;"name": "阿土", "age": 20, "gender": True, "height": 1.7, "weight": 75.0&#125;, &#123;"name": "小美", "age": 19, "gender": False, "height": 1.6, "weight": 45.0&#125;,]find_name = "阿土"for stu_dict in students: print(stu_dict) # 判断当前遍历的字典中姓名是否为find_name if stu_dict["name"] == find_name: print("找到了") # 如果已经找到，直接退出循环，就不需要再对后续的数据进行比较 breakelse: print("没有找到")print("循环结束")]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo Next主题美化]]></title>
    <url>%2F2018%2F12%2F19%2Fhexo%2F</url>
    <content type="text"><![CDATA[Hexo Next主题美化Hexo支持很多自定义主题和插件，本人使用的是Next主题，也涉及很多美化，为此记录一下。 添加页脚访客人数和总访问量使用的是不蒜子来进行统计,不蒜子是一款记录访客和访问量的插件. 1.安装脚本要使用不蒜子必须在页面中引入busuanzi.js，在themes/next/layout/_partial/footer.swig中添加脚本，代码如下 1&lt;script async src=&quot;//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js&quot;&gt;&lt;/script&gt; 2.安装标签要显示站点总访问量，复制以下代码添加到你需要显示的位置。有两种算法可选： 算法a：pv的方式，单个用户连续点击n篇文章，记录n次访问量。 123&lt;span id=&quot;busuanzi_container_site_pv&quot;&gt; 本站总访问量&lt;span id=&quot;busuanzi_value_site_pv&quot;&gt;&lt;/span&gt;次&lt;/span&gt; 算法b：uv的方式，单个用户连续点击n篇文章，只记录1次访客数。123&lt;span id=&quot;busuanzi_container_site_uv&quot;&gt; 本站访客数&lt;span id=&quot;busuanzi_value_site_uv&quot;&gt;&lt;/span&gt;人次&lt;/span&gt; 3.安装步骤一般显示站点访问量在页脚，所以在footer.swig中添加标签，在themes/next/_config.yml中加入以下配置： 12# visitors count counter: true 在themes/next/layout/_partial/footer.swig中添加以下代码： 123456&#123;% if theme.footer.counter %&#125; &lt;script async src=&quot;//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js&quot;&gt;&lt;/script&gt; &lt;span id=&quot;busuanzi_container_site_pv&quot;&gt;本站总访问量&lt;span id=&quot;busuanzi_value_site_pv&quot;&gt;&lt;/span&gt;次&lt;/span&gt; &lt;span class=&quot;post-meta-divider&quot;&gt;|&lt;/span&gt; &lt;span id=&quot;busuanzi_container_site_uv&quot;&gt;本站访客数&lt;span id=&quot;busuanzi_value_site_uv&quot;&gt;&lt;/span&gt;人&lt;/span&gt;&#123;% endif %&#125; 这样便可以在底部显示访问量了。之后使用hexo clean清空缓存，使用hexo generate重新生成站点文件，使用hexo deploy部署，就能看到效果了。 设置Menu菜单栏会显示可以跳转的页面。 如果还要添加，编辑themes/next/_config.yml： 12345678menu: home: / || home //首页 about: /about/ || user //关于 tags: /tags/ || tags //标签 categories: /categories/ || th //分类 archives: /archives/ || archive //归档 schedule: /schedule/ || calendar //日程表 sitemap: /sitemap.xml || sitemap //站点地图 将需要的Menu前面#号去掉。 设置动态背景主题配置文件中找到canvas_nest，设置成ture 12# Canvas-nestcanvas_nest: ture 修改底部标签样式 修改Blog\themes\next\layout\_macro\post.swig中文件，搜索rel=&quot;tag&quot;&gt;#，将#替换成&lt;i class=&quot;fa fa-tag&quot;&gt;&lt;/i&gt;。 侧边栏社交图标设置 打开主题配置文件_config.yml，搜索Social，社交账号前面的#号去掉。 12345678910111213#social: GitHub: https://github.com/yourname || github 简书: https://www.jianshu.com/u/63445e24e8bf || heartbeat 掘金: https://juejin.im/user/5a371ae551882512d0607108 || spinner #E-Mail: mailto:yourname@gmail.com || envelope #Google: https://plus.google.com/yourname || google #Twitter: https://twitter.com/yourname || twitter #FB Page: https://www.facebook.com/yourname || facebook #VK Group: https://vk.com/yourname || vk #StackOverflow: https://stackoverflow.com/yourname || stack-overflow #YouTube: https://youtube.com/yourname || youtube #Instagram: https://instagram.com/yourname || instagram #Skype: skype:yourname?call|chat || skype 添加网页顶部进度加载条 编辑主题配置文件，搜索pace，将其值改为ture就可以了，选择一款你喜欢的样式。 12345678910111213141516171819# Progress bar in the top during page loading.pace: ture# Themes list:#pace-theme-big-counter#pace-theme-bounce#pace-theme-barber-shop#pace-theme-center-atom#pace-theme-center-circle#pace-theme-center-radar#pace-theme-center-simple#pace-theme-corner-indicator#pace-theme-fill-left#pace-theme-flash#pace-theme-loading-bar#pace-theme-mac-osx#pace-theme-minimal# For example# pace_theme: pace-theme-center-simplepace_theme: pace-theme-minimal 添加点击爱心效果 在/themes/next/source/js/src下新建文件 clicklove.js ，接着把代码拷贝粘贴到 clicklove.js 文件中。 1!function(e,t,a)&#123;function n()&#123;c(&quot;.heart&#123;width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);&#125;.heart:after,.heart:before&#123;content: &apos;&apos;;width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 50%;-moz-border-radius: 50%;position: fixed;&#125;.heart:after&#123;top: -5px;&#125;.heart:before&#123;left: -5px;&#125;&quot;),o(),r()&#125;function r()&#123;for(var e=0;e&lt;d.length;e++)d[e].alpha&lt;=0?(t.body.removeChild(d[e].el),d.splice(e,1)):(d[e].y--,d[e].scale+=.004,d[e].alpha-=.013,d[e].el.style.cssText=&quot;left:&quot;+d[e].x+&quot;px;top:&quot;+d[e].y+&quot;px;opacity:&quot;+d[e].alpha+&quot;;transform:scale(&quot;+d[e].scale+&quot;,&quot;+d[e].scale+&quot;) rotate(45deg);background:&quot;+d[e].color+&quot;;z-index:99999&quot;);requestAnimationFrame(r)&#125;function o()&#123;var t=&quot;function&quot;==typeof e.onclick&amp;&amp;e.onclick;e.onclick=function(e)&#123;t&amp;&amp;t(),i(e)&#125;&#125;function i(e)&#123;var a=t.createElement(&quot;div&quot;);a.className=&quot;heart&quot;,d.push(&#123;el:a,x:e.clientX-5,y:e.clientY-5,scale:1,alpha:1,color:s()&#125;),t.body.appendChild(a)&#125;function c(e)&#123;var a=t.createElement(&quot;style&quot;);a.type=&quot;text/css&quot;;try&#123;a.appendChild(t.createTextNode(e))&#125;catch(t)&#123;a.styleSheet.cssText=e&#125;t.getElementsByTagName(&quot;head&quot;)[0].appendChild(a)&#125;function s()&#123;return&quot;rgb(&quot;+~~(255*Math.random())+&quot;,&quot;+~~(255*Math.random())+&quot;,&quot;+~~(255*Math.random())+&quot;)&quot;&#125;var d=[];e.requestAnimationFrame=function()&#123;return e.requestAnimationFrame||e.webkitRequestAnimationFrame||e.mozRequestAnimationFrame||e.oRequestAnimationFrame||e.msRequestAnimationFrame||function(e)&#123;setTimeout(e,1e3/60)&#125;&#125;(),n()&#125;(window,document); 在\themes\next\layout\_layout.swig文件末尾添加： 1&lt;script type=&quot;text/javascript&quot; src=&quot;/js/src/clicklove.js&quot;&gt;&lt;/script&gt; 背景图片设置打开theme/next/source/css/_custom/custom.styl，添加以下代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364// Custom styles.//背景图片相关@media screen and (min-width:1200px) &#123; body &#123; background-image:url(/images/bg1.jpg); background-repeat: no-repeat; background-attachment:fixed; background-position:50% 50%; background-size: cover &#125; #footer a &#123; color:#eee; &#125; //改变背景色和透明度 .main-inner &#123; background: #fff; opacity: 0.9; &#125; // 文章标题动态效果 .posts-expand .post-title-link::before &#123; background-image: linear-gradient(90deg, #a166ab 0%, #ef4e7b 25%, #f37055 50%, #ef4e7b 75%, #a166ab 100%); &#125; code &#123; color: #ff7600; background: #fbf7f8; margin: 2px; &#125; // 大代码块的自定义样式 .highlight, pre &#123; margin: 5px 0; padding: 5px; border-radius: 3px; &#125; .highlight, code, pre &#123; border: 1px solid #d6d6d6; &#125;&#125; .site-title &#123; font-size: 24px; font-weight: 400; font-family: &apos;Damion&apos;,&quot;PingFang SC&quot;,&quot;Microsoft YaHei&quot;,sans-serif; &#125; // 自定义页脚跳动的心样式@keyframes heartAnimate &#123; 0%,100%&#123;transform:scale(1);&#125; 10%,30%&#123;transform:scale(0.9);&#125; 20%,40%,60%,80%&#123;transform:scale(1.1);&#125; 50%,70%&#123;transform:scale(1.1);&#125;&#125;#heart &#123; animation: heartAnimate 1.33s ease-in-out infinite;&#125;.with-love &#123; color: rgb(255, 113, 168);&#125; 文章添加阴影、透明效果123456789// 主页文章添加阴影效果.post &#123; margin-top: 60px; margin-bottom: 60px; padding: 25px; background:rgba(255,255,255,0.9) none repeat scroll !important; -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5); -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5);&#125; 文章末尾添加版权声明查找主题配置文件themes/next/_config.yml中的creative_commons 12345creative_commons: license: by-nc-sa sidebar: false post: true # 将false改为true即可显示版权信息 language: 文字背景以及半透明的设置打开theme/next/source/css/_custom/custom.styl，添加以下代码： 12345.content &#123; border-radius: 20px; //文章背景设置圆角 padding: 30px 60px 30px 60px; background:rgba(255, 255, 255, 0.8) none repeat scroll !important;&#125;]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gandiva Introspective Cluster Scheduling for Deep Learning]]></title>
    <url>%2F2018%2F12%2F07%2Fpaper_01_Gandiva%2F</url>
    <content type="text"><![CDATA[Gandiva: Introspective Cluster Scheduling for Deep Learning论文发表在OSDI’18会议上，是系统设计/实现方面的顶级会议。作者是微软的研究员们。 Abstract 深度学习的一个关键特征是反馈驱动探索，其中用户经常运行一组作业（或多作业）以搜索特定任务的最佳结果，并使用准确率等早期反馈来动态地优先化或结束一部分作业; 同时的早期反馈对整个多工作任务的进行至关重要。 第二个特征是深度学习工作在资源使用方面的异构性，难以实现最佳拟合。 Gandiva利用深度学习的第三个关键特征来解决这两个挑战：作业内可预测性，因为深度学习任务执行需要大量小批量重复迭代。 Gandiva利用作业内可预测性在多个作业中有效地对GPU进行时间分片，提供低延迟性。此可预测性还用于评估作业性能和动态迁移作业以更好地适应GPU，从而提高集群效率。 通过原型实现和微基准测试表明，Gandiva可以在深度学习期间将超参数搜索加速一个数量级，并通过透明迁移和时间切片从而实现更好的作业-资源匹配。实验表明，在180个GPU的集群中运行的实际工作负载中，Gandiva将聚合集群利用率提高了26％，表明这是一种管理大型GPU集群以进行深度学习的新方法。 1 Introduction深度学习是计算密集型的，严重依赖功能强大但价格昂贵的GPU;云中的GPU VM价格是普通VM的10倍。 云运营商和大公司依靠集群调度器来确保GPU的有效利用。 尽管高效调度深度学习训练（DLT）工作非常重要，但今天的常见做法是使用传统的集群调度程序，如Kubernetes或YARN这些用于处理大数据 MapReduce的工具; DLT作业被简单地视为大数据作业，在启动时分配一组GPU，并保持对其GPU的独占访问，直到完成为止。 DLT工作的一个关键特征是反馈驱动的探索（第2节）。由于深度学习实验固有的反复试验方法，用户通常会尝试几种任务的配置（多任务），并使用这些任务的早期反馈来决定是否优先考虑或结束它们的某些子集。这种称为超参数搜索的条件探索可以是手动的也可以是自动的。传统的调度程序在排队时运行一部分作业子集;这种模式不适合多任务，需要同时对多任务中的所有工作进行早期反馈。此外，与多任务一起，其他DLT作业已经确定了正确的超参数并运行了几个小时到几天，导致线头阻塞（长时间运行的作业可以独立访问GPU直到完成），而依赖在早期反馈的多任务仍排队等待。长队列时间迫使用户使用保留的GPU，或者要求群集过度配置，从而降低群集效率。 与任何其他群集工作负载一样，DLT作业是异构的，因为它们所针对的应用程序域不同。作业在内存使用，GPU核心利用率，带宽敏感度和其他作业的干扰性方面存在很大差异。例如，某些多GPU DLT作业可能对关联的GPU执行得更好，而其他作业可能对关联性不敏感（第3节）。将作业视为黑盒的传统调度程序因此将实现次优的集群效率。 为了解决高延迟和低效率这两个问题，Gandiva利用了DLT作业的强大属性：作业内可预测性（第3节）。一项任务由数百万个类似的，分开的小批量迭代组成。Gandiva利用这种循环可预测性来实现有效的应用感知时间切片; 它重新定义了从作业到自动划分的微任务的调度原子。这使集群能够超额预订DLT任务，并通过时间切片为所有DLT任务提供早期反馈（包括作为多任务一部分的所有作业）。 Gandiva还使用可预测性来执行简介驱动的内省。它使用小批量不断反省其决策，以提高集群效率（第4节）。例如，它只在内存和GPU利用率较低时才在同一GPU上打包多个作业; 它动态地将通信密集型作业迁移到更加接近的GPU上; 它还机会性地“增长”工作的并行度以利用备用资源，并在备用资源消失时缩减工作量。我们目前实施的内省策略是一种有状态的反复试验策略，由于我们考虑的可预测性和有限的选择状态空间，这是可行的。 除了本文评估的特定内省和调度策略之外，Gandiva框架还提供以下API，任何DLT调度策略都可以利用这些API：（a）有效的暂停 - 恢复或时间切片，（b）低延迟迁移，（c）细粒度分析，（d）动态的工作内弹性，以及（e）动态优先级。使这些原语高效和实用的关键是Gandiva的协同设计方法，跨越调度程序层和DLT工具包层，如Tensorflow或PyTorch。传统的调度程序，有充分的理由将工作视为一个黑盒子。 然而，通过利用GPU集群的专用特性，Gandiva将调度程序定制为深度学习的特定工作负载，从而为调度程序提供更多的可见性和对作业的控制，同时实现对任意DLT作业的通用性。 通过修改两个流行的框架PyTorch和Tensorflow来实现Gandiva，为调度程序提供必要的新原语，并在Kubernetes和Docker容器之上实现初始调度策略管理器（第5节）。 2 Background 反馈驱动的探索。实现高精度的一个先决条件是模型选择，像ResNet或Inception这样的模型通常是反复实验处理的过程，尽管自动化的方法是一个活跃的研究领域。除了模型结构之外，还有许多超参数需要指定为DLT作业的一部分。超参数包括模型中的层数/权重，批量大小，学习速率等。这些通常由用户根据领域知识和反复试验选择，有时甚至可能导致早期训练失败。 因此，DLT工作的早期反馈至关重要，特别是在训练的初始阶段。 多作业。 一旦用户识别出要进一步探索的特定模型，用户通常执行超参数搜索以提高任务准确性。这可以在超参数的空间上使用各种搜索技术来完成; 也就是说，用户生成多个DLT作业或多个作业，每个作业使用一组超参数或配置执行训练。由于用户通常会探索数百种此类配置，因此此过程的计算成本非常高。超参数搜索方法，如Hyper-Opt和Hyperband。Hyperband可能最初产生128个DLT作业，并且在每一轮（例如，100个小批量迭代）中，以最低精度结束一半的作业。对于这些算法，对工作的早期反馈至关重要，因为否则他们将无法做出有效的训练决策。 3 DLT Job Characteristics3.1 Sensitivity to locality多GPU DLT作业的性能取决于分配的GPU的亲和性。不同的DLT作业对GPU间亲和力表现出不同的灵敏度。即使对于同一台机器上的GPU，由于非对称架构，我们观察到不同级别的GPU间亲和性：两个GPU可能位于不同的CPU插槽中（表示为DiffSocket），位于同一CPU插槽中，但位于不同的PCIe交换机上（表示如同SameSocket），或在同一个PCIe交换机上（表示为SamePCIeSw）。 图1显示了VGG16和ResNet-50对服务器内局部性的不同敏感性。当使用Tensorflow对两个P100 GPU进行训练时，VGG16受到严重影响。当两个GPU位于不同的CPU插槽中时，VGG16仅实现最佳位置配置的60％，其中两个GPU放置在同一PCIe交换机下。另一方面，ResNet-50在此设置中不受GPU位置的影响。这是因为VGG16是一个比ResNet-50更大的神经模型，因此每个小批量的模型同步会在底层PCIe总线上产生更高的通信负载。 我们在分布式设置中观察到类似的趋势。显示了不同服务器间位置，训练ResNet-50和InceptionV3模型的4-GPU Tensorflow作业的性能。即使与40G InfiniBand网络互连，当作业分配到4个GPU时，也可以清楚地看到性能差异，它们均匀分散在4个服务器（表示为4 1-GPU），2个服务器（表示为2 2） -GPU），以及所有在一个服务器（表示为本地4-GPU），尽管两个模型的局部性的敏感性是不同的。因此，DLT调度程序在分配GPU时必须考虑作业对位置的敏感性。 3.2 Sensitivity to interference在共享执行环境中运行时，由于资源争用，DLT作业可能会相互干扰。我们再次观察到不同的DLT作业表现出不同程度的干扰。 对于单GPU作业也存在干扰。 将语言模型作业（标记为LM）与另一个作业放在同一PCI-e交换机下时，显示了由于服务器内干扰导致的性能下降。当两个LM一起运行时，两个工作都会减速19％。 但是，ResNet-50不会受到与LM共存的GPU的影响。 神经机器翻译（GNMT）表现出对LM的适度干扰。 显示了与40G InfiniBand网络连接的两台4 GPU服务器之间的服务器间干扰。 当运行多个2-GPU作业时，每个GPU放置在不同的服务器上，ResNet-50显示减速高达47％，InceptionV3显示减速30％，而DeepSpeech仅显示5％减速。 3.3 Intra-job predictabilityDLT作业包含许多小批量迭代。图5（a）中显示了在四个K80 GPU上使用ResNet-50模型时，在20秒的ImageNet数据训练期间使用的总GPU内存。所使用的GPU存储器明显遵循循环模式。这些循环中的每一个对应于单个小批量（约1.5s）的处理，其中存储器在正向传播期间增加并且在反向传播期间减小。使用的最大和最小GPU内存分别为23GB和0.3GB，为77倍。该比例与小批量大小成比例（通常在16到256之间;在这种情况下为128）。 在图5（b）中显示了在一个K80 GPU上使用GNMT模型时，在WMT’14 English German language数据集训练期间使用的总GPU内存。虽然小批量迭代在ImageNet示例中彼此不相同（由于不同的句子长度和PyTorch中动态图形的使用），图形具有类似的循环性质。最大值和最小值之间的差异较小（3x）主要是由于较大型号（0.4GB）和较小的小批量（本例中为16）。 除了此处显示的图像和语言模型之外，其他训练领域，如语音，GAN和变分自动编码器都遵循类似的循环模式（由于空间限制而未显示），因为训练的核心都是梯度下降算法执行许多小批量迭代。 利用可预测性。这种特征在Gandiva中以多种方式被利用。 首先，DLT作业可以自动拆分为小批量迭代，并且超过60秒的这些迭代的集合（微任务），形成调度间隔。其次，通过在存储器周期的最小值处执行挂起操作，可以显着减少要从GPU复制以保存在CPU中的存储量，从而使挂起/恢复和迁移能够比天真的实施更高效一个数量级。第三，可以对小批量进步率进行分析并将其用作代理，以评估应用包装或迁移等机制的有效性。 4 Design 由于DLT作业被分配了一组固定的GPU（图6），因此集群出现高延迟和低利用率。 对GPU的独占访问会导致行头阻塞；阻止早期反馈；导致传入作业的高排队时间。 当作业无法完全利用其分配的GPU时，对固定GPU的独占访问也会导致GPU利用率降低。 4.1 Mechanisms在Gandiva中，我们通过三种方式消除GPU对DLT作业的排他性和固定分配来解决这些低效问题（图6） Suspend-Resume and Packing。暂停 - 恢复是Gandiva用于删除一组GPU对DLT作业排他性的一种机制。现代操作系统支持CPU进程的高效挂起 - 恢复的时间切片。Gandiva利用这种机制并为GPU时间切片添加了自定义支持。如图5（a）所示，DLT作业对GPU内存的使用具有循环模式，最小和最大内存使用之间的差异高达77倍。 Gandiva的关键思想是利用这种循环行为，并在GPU内存使用率最低时采取暂停-恢复DLT作业。因此，当发出挂起调用时，DLT工具包会等待内存使用周期的最小值，将存储在GPU中的对象复制到CPU，释放所有GPU内存分配（包括缓存），然后调用经典CPU暂停机制。稍后，当CPU恢复作业时，DLT框架首先分配适当的GPU内存，将存储的对象复制回GPU，然后恢复作业。暂停 - 恢复还可以在同一服务器内改变GPU（例如，在六个1-GPU作业分时4-GPU的情况下）。 虽然更换GPU很昂贵，但我们会将这种延迟隐藏在关键路径之外。正如我们在评估（第6.1节）中所示，对于典型的图像分类工作，可以在100ms内完成暂停 - 恢复，而对于大型语言翻译工作，暂停 - 恢复可能需要1s。 给定1分钟的时间片间隔，这相当于2％或更少的开销。请注意，Gandiva中的暂停可能会延迟最多一个DLT作业的小批量间隔（通常为几秒或更短），但我们认为这是值得的权衡，因为它可以显着减少开销。 降低了GPU-CPU复制成本，减少了CPU中使用的内存。 此外，在此延迟期间完成了有用的工作。调度程序跟踪此延迟并相应地调整时间切片间隔以确保公平性。暂停 - 恢复时间切片的替代方法是同时在GPU上运行多个DLT作业，让GPU共享作业。我们称之为包装。 只有当打包作业不超过GPU资源（核心，内存）并且不会相互产生负面影响时，GPU中的打包才有效。 如果工作干扰，包装可能比暂停 - 恢复更糟糕（第6.1节）。 我们使用分析来监视DLT作业具有独占访问权限时的资源和进度。 如果两个工作被确定为包装的候选人，我们将它们打包在一起并继续监控它们。 如果给定的包装对工作效率产生不利影响，我们会拆开这些工作并返回暂停 - 恢复。 Migration。 迁移是Gandiva用于更改分配给DLT作业的GPU集合的机制。 迁移在以下几种情况下非常有用：i）将时间切片的作业移动到群集中腾出的任何位置的GPU;ii）将干扰工作相互迁移开;iii）群集的碎片化，以便传入的作业获得具有良好局部性的GPU。我们评估了两种解决DLT流程状态迁移的方法。（1）在第一种方法中，我们利用通用的流程迁移机制，如CRIU。因为CRIU本身不支持使用GPU设备的进程迁移，所以我们首先对GPU对象创建检查点并在调用CRIU之前从进程中删除所有GPU状态。 由于CRIU检查点并恢复整个进程内存，因此使用PyTorch检查点的大小为GB数量级。因此，对于单GPU作业，所产生的迁移开销约为8-10s，对于多GPU作业，则更高。（2）的第二种方法是使用支持检查点的DLT作业。诸如Tensorflow之类的DLT框架已经支持创建自动检查点和模型恢复的API（例如，tensorflow.train.saver）。此API现在用于确保不必因服务器故障而重新运行长时间运行的作业。我们扩展框架以支持此类工作的迁移。通过在迁移之前”预热“目的地并且仅迁移必要的训练状态，我们可以将迁移率减少到一秒或两秒（第6.1节）。无论采用哪种方法，我们都发现服务器间迁移的开销与其提供的更高整体GPU利用率相比是值得的。 Grow-Shrink。 Gandiva用于消除GPU对DLT作业的排他性的第三种机制是成长-缩减。该机制主要针对群集可能无法充分利用的情况，例如深夜时。基本思想是在空闲时机会性地增加可用于工作的GPU的数量，并且相应地减少负载增加时可用的GPU的数量。许多DLT作业（尤其是图像域中的作业）随着GPU数量的增加而看到线性性能缩放。Gandiva仅将这种机制应用于那些明确表明其足够自适应以利用这些增长机会的DLT工作。当多个DLT作业符合此标准时，Gandiva使用下面讨论的分析信息来估计每个作业的进度，然后相应地分配GPU。 Profiling。与任何调度程序一样，Gandiva监视资源使用情况，例如CPU和GPU利用率，CPU / GPU内存等。然而，Gandiva的独特之处在于它还以应用程序感知的方式内省DLT作业估计其进度。 这种内省利用了DLT作业（第3节）展示的规则模式，并使用周期性来估计其进度。Gandiva估计DLT作业的小批处理时间，即对一批输入数据进行一次前向/后向传递的时间，作为GPU内存使用周期的两个最小值之间所花费的时间（图5（a））。 由于DLT作业通常在其生命周期中执行数百万个这样的小批量操作，因此调度程序在调度决策之前和之后比较DLT的小批量时间以确定其有效性。例如，考虑在前面描述的GPU中打包两个DLT作业的示例。 通过比较包装前后两个DLT作业中每个作业的小批量时间，Gandiva可以决定包装是否有效。 如果没有这样的分析，为了做出包装决定，人们不仅要模拟两个DLT作业在各种GPU上的性能，还要模拟它们可能相互干扰的各种方式（例如，高速缓存，内存带宽等）。 。），这是一项非常重要的任务，我们在第6.1节中看到了不同的包装性能。 7 Related Work略 8 Conclusion略]]></content>
      <categories>
        <category>科研</category>
      </categories>
      <tags>
        <tag>深度学习任务调度 - 论文阅读 - 科研</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pycharm常用知识]]></title>
    <url>%2F2018%2F12%2F05%2Fpython_01_pycharm%2F</url>
    <content type="text"><![CDATA[PyCharm 的初始设置目标 恢复 PyCharm 的初始设置 第一次启动 PyCharm 新建一个 Python 项目 设置 PyCharm 的字体显示 PyCharm 的升级以及其他 PyCharm 的官方网站地址是：https://www.jetbrains.com/pycharm/ 01. 恢复 PyCharm 的初始设置PyCharm 的 配置信息 是保存在 用户家目录下 的 .PyCharmxxxx.x 目录下的，xxxx.x 表示当前使用的 PyCharm 的版本号 如果要恢复 PyCharm 的初始设置，可以按照以下步骤进行： 关闭正在运行的 PyCharm 在终端中执行以下终端命令，删除 PyCharm 的配置信息目录： 1$ rm -r ~/.PyCharm2016.3 重新启动 PyCharm 02. 设置 PyCharm 的字体显示 03. PyCharm 的升级以及其他 PyCharm 提供了对 学生和教师免费使用的版本 教育版下载地址：https://www.jetbrains.com/pycharm-edu/download/#section=linux 专业版下载地址：https://www.jetbrains.com/pycharm/download/#section=linux 3.1 安装和启动步骤 执行以下终端命令，解压缩下载后的安装包 1$ tar -zxvf pycharm-professional-2017.1.3.tar.gz 将解压缩后的目录移动到 /opt 目录下，可以方便其他用户使用 /opt 目录用户存放给主机额外安装的软件 1$ sudo mv pycharm-2017.1.3/ /opt/ 切换工作目录 1$ cd /opt/pycharm-2017.1.3/bin 启动 PyCharm 1$ ./pycharm.sh 3.2 设置专业版启动图标 在专业版中，选择菜单 Tools / Create Desktop Entry… 可以设置任务栏启动图标 注意：设置图标时，需要勾选 Create the entry for all users 3.3 卸载之前版本的 PyCharm1) 程序安装 程序文件目录 将安装包解压缩，并且移动到 /opt 目录下 所有的相关文件都保存在解压缩的目录中 配置文件目录 启动 PyCharm 后，会在用户家目录下建立一个 .PyCharmxxx 的隐藏目录 保存 PyCharm 相关的配置信息 快捷方式文件 /usr/share/applications/jetbrains-pycharm.desktop 在 ubuntu 中，应用程序启动的快捷方式通常都保存在 /usr/share/applications 目录下 2) 程序卸载 要卸载 PyCharm 只需要做以下两步工作： 删除解压缩目录 1$ sudo rm -r /opt/pycharm-2016.3.1/ 删除家目录下用于保存配置信息的隐藏目录 1$ rm -r ~/.PyCharm2016.3/ 如果不再使用 PyCharm 还需要将 /usr/share/applications/ 下的 jetbrains-pycharm.desktop 删掉]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Python - 学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux常用命令]]></title>
    <url>%2F2018%2F12%2F04%2Flinux_01_%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux终端命令的重要性 Linux 刚面世时并没有图形界面，所有的操作全靠命令完成，如 磁盘操作、文件存取、目录操作、进程管理、文件权限 设定等 在职场中，大量的 服务器维护工作 都是在 远程 通过 SSH 客户端 来完成的，并没有图形界面，所有的维护工作都需要通过命令来完成 在职场中，作为后端程序员，必须要或多或少的掌握一些 Linux 常用的终端命令 Linux 发行版本的命令大概有 200 多个，但是常用的命令只有 10 多个而已 学习终端命令的技巧： 不需要死记硬背，对于常用命令，用的多了，自然就记住了 不要尝试一次学会所有的命令，有些命令是非常不常用的，临时遇到，临时百度就可以 常用 Linux 命令的基本使用 序号 命令 含义 作用 01 ls list 查看当前文件夹下的内容 02 pwd print wrok directory 查看当前所在文件夹 03 cd [目录名] change directory 切换文件夹 04 touch [文件名] touch 如果文件不存在，新建文件 05 mkdir [目录名] make directory 创建目录 06 rm [文件名] remove 删除指定的文件名 07 clear clear 清屏 小技巧 ctrl + shift + = 放大终端窗口的字体显示 ctrl + - 缩小终端窗口的字体显示 自动补全 在敲出 文件／目录／命令 的前几个字母之后，按下 tab 键 如果输入的没有歧义，系统会自动补全 如果还存在其他 文件／目录／命令，再按一下 tab 键，系统会提示可能存在的命令 小技巧 按 上／下 光标键可以在曾经使用过的命令之间来回切换 如果想要退出选择，并且不想执行当前选中的命令，可以按 ctrl + c]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux - 学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NLP1]]></title>
    <url>%2F2018%2F11%2F29%2FNLP_01%2F</url>
    <content type="text"><![CDATA[CS224N自然语言处理自然语言处理的目标是让计算机处理或说“理解”自然语言，以完成有意义的任务，比如订机票购物或QA等。完全理解和表达语言是极其困难的，完美的语言理解等效于实现人工智能。 作为输入一共有两个来源，语音与文本。所以第一级是语音识别和OCR或分词。形态分析（Morphological）是分析该词的构造形式（主要针对英语而言，例如，uninterested = un(前缀）+ interest(词干) + ed(后缀)）。句法分析是确定句子的语法结构句子中词汇之间的依存关系。本课程着重讲解句法分析和语义表示。 自然语言处理的应用 拼写检查、关键词检索…… 文本挖掘（产品价格、日期、时间、地点、人名、公司名） 文本分类 机器翻译 客服系统 复杂对话系统 在工业界从搜索到广告投放、自动\辅助翻译、情感舆情分析、语音识别、聊天机器人等。 人类语言的特殊之处与信号处理、数据挖掘不同，自然语言的随机性小而目的性强；语言是用来传输有意义的信息的，这种传输连小孩子都能很快学会。人类语言是离散的、明确的符号系统。但又允许出现各种变种，比如颜文字，随意的错误拼写“I loooove it”。这种自由性可能是因为语言的可靠性（赘余性）。所以说语言文字绝对不是形式逻辑或传统AI的产物。语言符号有多种形式（声音、手势、书写），在这些不同的形式中，其意义保持不变。虽然人类语言是明确的符号系统，但符号传输到大脑的过程是通过连续的声学光学信号，大脑编码似乎是连续的激活值上的模式。另外巨大的词表也导致数据稀疏，不利于机器学习。这构成一种动机，是不是应该用连续的信号而不是离散的符号去处理语言。 因为NVDIA官网即使是科学上网也经常崩，所以把百度网盘连接分享到文件里，需要的可以自取，密码ia9l 安装过程只要要三步： （1）下载并安装cuda9.1 （2）下载并安装cudnn7.1 (3) 下载并安装annaconda3-5.1.0 注意：1.查看cuda能否安装成功：在cmd(win+r)中输入：nvcc -V 2.安装cudnn7.0详细方法： 将cudnn压缩包中所有文件放入1C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0 目录下对应目录中，同时将1C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64\cupti64_91.dll 拷贝到1C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\bin CUDA环境测试CMD中输入1nvcc -V 如果成功出现下图，则说明CUDA和Cudnn已经配置成功 安装tensorflow打开Anaconda Prompt，创建tensorflow虚拟环境1conda create -n tensorflow python=3.5 然后启用虚拟环境1activate tensorflow 最后安装tensorflow1pip install tensorflow-gpu 如果安装速度较慢，可以使用清华大学开源软件镜像站的TensorFlow 镜像。 测试tensorflow安装情况在刚才的Anaconda Prompt中输入1Python 在Python的交互界面中输入12345import tensorflow as tfhello=tf.constant(&apos;Hello tensorflow!&apos;)sess=tf.Session()sess.run(hello)sess.close() 然后激动人心的时刻，我们可以使用TF了。 可能出现的问题 找不到cudart64_90.dll: ImportError: DLL loaded failed: 找不到指定模块出现上述问题是显卡驱动没有更新，手动到NVDIA对应网站下载对应显卡最新驱动安装，即可。 额外内容为了方便之后的开发，我们可以安装Spyder这款十分强大的科学计算IDE。首先添加清华大学镜像源12conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --set show_channel_urls yes 然后1conda install spyder 记得输入Yes，这样进行深度学习的环境就配置好了。 To be continue。。。]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>NLP - 学习 - 笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客正式上线]]></title>
    <url>%2F2018%2F09%2F20%2Ffirst_blog%2F</url>
    <content type="text"><![CDATA[博客正式上线想了好久的博客现在终于用上了，准备记录一下自己研究生期间的所学和所思所想吧。也把个人博客作为展示自己的一个平台，为之后工作、科研做些积累。 A Good Programmer’s abilityA fool can write code that a computer can understand.Good programmers write code that humans can understand. Hexo 指令Quick startCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow内核学习]]></title>
    <url>%2F2018%2F09%2F20%2Ftensor_01_TF%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Tensorflow内核探究1研究生期间要做的课题是深度学习inference任务的加速和调度问题，因为已经有很多不错的开源深度学习框架（Tensorflow，Pytorch2，Caffe2。。。），所以想在框架的基础上来做调度器和加速。然后Google大法确实厉害，有很多充足的文档、资料和论文实现，所以决定以Tensorflow入手，最近在学习Tensorflow的相关实现和原理，想在这篇博客里总结一下所学。 Tensorflow GPU版本安装要安装进行train，inference加速，我们需要一块好的GPU。如果你有NVDIA 1080 Ti或者NVDIA TitanX，那加速效果可能达到10——20倍，效果是很直观的。其他Nvdia显卡也可以，只是性能没有这么好。可以在NVDIA官网查看市面上常用显卡的计算性（使用Tensorflow GPU版本需要大于等于3.0以上的显卡）Nvdia显卡计算性 安装包准备安装的Tensorflow为V1.8版本，需要CUDA9.0和Cudnn7.1，推荐使用Anaconda来使用Tensorflow。anaconda3-5.1.0-windows10cuda-9.1-windows10cudnn-7.1-windows10关于Tensorflow和CUDA，Cudnn的版本对应关系可以参考下图。 Tensorflow版本 CUDA版本 Cudnn版本 Python版本 1.1-1.2 8.0 v5.1 3.5 1.3 8.0 v6，V6.1 3.5，3.6 1.4 8.0 V6.1 3.5，3.6 1.5-1.8 9.0 V7.0 3.5，3.6 因为NVDIA官网即使是科学上网也经常崩，所以把百度网盘连接分享到文件里，需要的可以自取，密码ia9l 安装过程只要要三步： （1）下载并安装cuda9.1 （2）下载并安装cudnn7.1 (3) 下载并安装annaconda3-5.1.0 注意：1.查看cuda能否安装成功：在cmd(win+r)中输入：nvcc -V 2.安装cudnn7.0详细方法： 将cudnn压缩包中所有文件放入1C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0 目录下对应目录中，同时将1C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64\cupti64_91.dll 拷贝到1C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\bin CUDA环境测试CMD中输入1nvcc -V 如果成功出现下图，则说明CUDA和Cudnn已经配置成功 安装tensorflow打开Anaconda Prompt，创建tensorflow虚拟环境1conda create -n tensorflow python=3.5 然后启用虚拟环境1activate tensorflow 最后安装tensorflow1pip install tensorflow-gpu 如果安装速度较慢，可以使用清华大学开源软件镜像站的TensorFlow 镜像。 测试tensorflow安装情况在刚才的Anaconda Prompt中输入1Python 在Python的交互界面中输入12345import tensorflow as tfhello=tf.constant(&apos;Hello tensorflow!&apos;)sess=tf.Session()sess.run(hello)sess.close() 然后激动人心的时刻，我们可以使用TF了。 可能出现的问题 找不到cudart64_90.dll: ImportError: DLL loaded failed: 找不到指定模块出现上述问题是显卡驱动没有更新，手动到NVDIA对应网站下载对应显卡最新驱动安装，即可。 额外内容为了方便之后的开发，我们可以安装Spyder这款十分强大的科学计算IDE。首先添加清华大学镜像源12conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --set show_channel_urls yes 然后1conda install spyder 记得输入Yes，这样进行深度学习的环境就配置好了。 To be continue。。。]]></content>
      <categories>
        <category>Tensorflow</category>
      </categories>
      <tags>
        <tag>Deep learning</tag>
        <tag>科研 - 学习</tag>
      </tags>
  </entry>
</search>
